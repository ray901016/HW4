2024-12-09 13:46:42,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 13:46:42,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 13:46:42,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 13:46:42,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 13:47:45,327:INFO:PyCaret ClassificationExperiment
2024-12-09 13:47:45,328:INFO:Logging name: clf-default-name
2024-12-09 13:47:45,328:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-09 13:47:45,328:INFO:version 3.2.0
2024-12-09 13:47:45,328:INFO:Initializing setup()
2024-12-09 13:47:45,328:INFO:self.USI: 6e5b
2024-12-09 13:47:45,328:INFO:self._variable_keys: {'fix_imbalance', 'log_plots_param', '_available_plots', 'X', 'seed', 'idx', 'gpu_param', '_ml_usecase', 'fold_generator', 'exp_name_log', 'y', 'is_multiclass', 'fold_shuffle_param', 'X_test', 'target_param', 'exp_id', 'logging_param', 'X_train', 'html_param', 'memory', 'fold_groups_param', 'y_train', 'n_jobs_param', 'data', 'gpu_n_jobs_param', 'USI', 'pipeline', 'y_test'}
2024-12-09 13:47:45,328:INFO:Checking environment
2024-12-09 13:47:45,328:INFO:python_version: 3.8.20
2024-12-09 13:47:45,328:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2024-12-09 13:47:45,329:INFO:machine: AMD64
2024-12-09 13:47:45,329:INFO:platform: Windows-10-10.0.19041-SP0
2024-12-09 13:47:45,332:INFO:Memory: svmem(total=17054896128, available=5263859712, percent=69.1, used=11791036416, free=5263859712)
2024-12-09 13:47:45,332:INFO:Physical Core: 6
2024-12-09 13:47:45,332:INFO:Logical Core: 6
2024-12-09 13:47:45,332:INFO:Checking libraries
2024-12-09 13:47:45,333:INFO:System:
2024-12-09 13:47:45,333:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2024-12-09 13:47:45,333:INFO:executable: c:\Users\EE715\anaconda3\envs\gym-env\python.exe
2024-12-09 13:47:45,333:INFO:   machine: Windows-10-10.0.19041-SP0
2024-12-09 13:47:45,333:INFO:PyCaret required dependencies:
2024-12-09 13:47:45,370:INFO:                 pip: 24.2
2024-12-09 13:47:45,370:INFO:          setuptools: 75.1.0
2024-12-09 13:47:45,370:INFO:             pycaret: 3.2.0
2024-12-09 13:47:45,371:INFO:             IPython: 8.12.3
2024-12-09 13:47:45,371:INFO:          ipywidgets: 8.1.5
2024-12-09 13:47:45,371:INFO:                tqdm: 4.67.1
2024-12-09 13:47:45,371:INFO:               numpy: 1.24.4
2024-12-09 13:47:45,371:INFO:              pandas: 1.5.3
2024-12-09 13:47:45,371:INFO:              jinja2: 3.1.4
2024-12-09 13:47:45,371:INFO:               scipy: 1.10.1
2024-12-09 13:47:45,371:INFO:              joblib: 1.2.0
2024-12-09 13:47:45,371:INFO:             sklearn: 1.2.2
2024-12-09 13:47:45,371:INFO:                pyod: 2.0.2
2024-12-09 13:47:45,371:INFO:            imblearn: 0.12.4
2024-12-09 13:47:45,371:INFO:   category_encoders: 2.6.4
2024-12-09 13:47:45,372:INFO:            lightgbm: 4.5.0
2024-12-09 13:47:45,372:INFO:               numba: 0.58.1
2024-12-09 13:47:45,372:INFO:            requests: 2.32.3
2024-12-09 13:47:45,372:INFO:          matplotlib: 3.6.0
2024-12-09 13:47:45,372:INFO:          scikitplot: 0.3.7
2024-12-09 13:47:45,372:INFO:         yellowbrick: 1.5
2024-12-09 13:47:45,372:INFO:              plotly: 5.24.1
2024-12-09 13:47:45,372:INFO:    plotly-resampler: Not installed
2024-12-09 13:47:45,372:INFO:             kaleido: 0.2.1
2024-12-09 13:47:45,372:INFO:           schemdraw: 0.15
2024-12-09 13:47:45,372:INFO:         statsmodels: 0.14.1
2024-12-09 13:47:45,372:INFO:              sktime: 0.21.1
2024-12-09 13:47:45,372:INFO:               tbats: 1.1.3
2024-12-09 13:47:45,372:INFO:            pmdarima: 2.0.4
2024-12-09 13:47:45,372:INFO:              psutil: 6.1.0
2024-12-09 13:47:45,372:INFO:          markupsafe: 2.1.5
2024-12-09 13:47:45,372:INFO:             pickle5: Not installed
2024-12-09 13:47:45,373:INFO:         cloudpickle: 3.1.0
2024-12-09 13:47:45,373:INFO:         deprecation: 2.1.0
2024-12-09 13:47:45,373:INFO:              xxhash: 3.5.0
2024-12-09 13:47:45,373:INFO:           wurlitzer: Not installed
2024-12-09 13:47:45,373:INFO:PyCaret optional dependencies:
2024-12-09 13:47:45,389:INFO:                shap: Not installed
2024-12-09 13:47:45,389:INFO:           interpret: Not installed
2024-12-09 13:47:45,389:INFO:                umap: Not installed
2024-12-09 13:47:45,389:INFO:     ydata_profiling: Not installed
2024-12-09 13:47:45,389:INFO:  explainerdashboard: Not installed
2024-12-09 13:47:45,390:INFO:             autoviz: Not installed
2024-12-09 13:47:45,390:INFO:           fairlearn: Not installed
2024-12-09 13:47:45,390:INFO:          deepchecks: Not installed
2024-12-09 13:47:45,390:INFO:             xgboost: Not installed
2024-12-09 13:47:45,390:INFO:            catboost: Not installed
2024-12-09 13:47:45,390:INFO:              kmodes: Not installed
2024-12-09 13:47:45,390:INFO:             mlxtend: Not installed
2024-12-09 13:47:45,390:INFO:       statsforecast: Not installed
2024-12-09 13:47:45,390:INFO:        tune_sklearn: Not installed
2024-12-09 13:47:45,390:INFO:                 ray: Not installed
2024-12-09 13:47:45,390:INFO:            hyperopt: Not installed
2024-12-09 13:47:45,390:INFO:              optuna: 4.1.0
2024-12-09 13:47:45,390:INFO:               skopt: Not installed
2024-12-09 13:47:45,390:INFO:              mlflow: Not installed
2024-12-09 13:47:45,390:INFO:              gradio: Not installed
2024-12-09 13:47:45,390:INFO:             fastapi: Not installed
2024-12-09 13:47:45,390:INFO:             uvicorn: Not installed
2024-12-09 13:47:45,390:INFO:              m2cgen: Not installed
2024-12-09 13:47:45,390:INFO:           evidently: Not installed
2024-12-09 13:47:45,390:INFO:               fugue: Not installed
2024-12-09 13:47:45,390:INFO:           streamlit: Not installed
2024-12-09 13:47:45,391:INFO:             prophet: Not installed
2024-12-09 13:47:45,391:INFO:None
2024-12-09 13:47:45,391:INFO:Set up data.
2024-12-09 13:47:45,401:INFO:Set up folding strategy.
2024-12-09 13:47:45,401:INFO:Set up train/test split.
2024-12-09 13:47:45,408:INFO:Set up index.
2024-12-09 13:47:45,408:INFO:Assigning column types.
2024-12-09 13:47:45,414:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-09 13:47:45,464:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 13:47:45,466:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:47:45,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:47:45,545:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:47:45,617:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 13:47:45,618:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:47:45,644:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:47:45,644:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:47:45,645:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-09 13:47:45,693:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:47:45,725:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:47:45,726:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:47:45,779:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:47:45,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:47:45,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:47:45,808:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-09 13:47:45,882:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:47:45,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:47:45,953:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:47:45,953:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:47:45,955:INFO:Preparing preprocessing pipeline...
2024-12-09 13:47:45,956:INFO:Set up simple imputation.
2024-12-09 13:47:45,958:INFO:Set up encoding of ordinal features.
2024-12-09 13:47:45,960:INFO:Set up encoding of categorical features.
2024-12-09 13:47:46,034:INFO:Finished creating preprocessing pipeline.
2024-12-09 13:47:46,054:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\EE715\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categ...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-12-09 13:47:46,054:INFO:Creating final display dataframe.
2024-12-09 13:47:46,272:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (623, 10)
6    Transformed test set shape         (268, 10)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              6e5b
2024-12-09 13:47:46,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:47:46,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:47:46,452:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:47:46,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:47:46,453:INFO:setup() successfully completed in 1.13s...............
2024-12-09 13:47:46,453:INFO:Initializing compare_models()
2024-12-09 13:47:46,453:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-12-09 13:47:46,453:INFO:Checking exceptions
2024-12-09 13:47:46,457:INFO:Preparing display monitor
2024-12-09 13:47:46,486:INFO:Initializing Logistic Regression
2024-12-09 13:47:46,486:INFO:Total runtime is 0.0 minutes
2024-12-09 13:47:46,492:INFO:SubProcess create_model() called ==================================
2024-12-09 13:47:46,493:INFO:Initializing create_model()
2024-12-09 13:47:46,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32D91EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:47:46,493:INFO:Checking exceptions
2024-12-09 13:47:46,493:INFO:Importing libraries
2024-12-09 13:47:46,493:INFO:Copying training dataset
2024-12-09 13:47:46,498:INFO:Defining folds
2024-12-09 13:47:46,498:INFO:Declaring metric variables
2024-12-09 13:47:46,505:INFO:Importing untrained model
2024-12-09 13:47:46,511:INFO:Logistic Regression Imported successfully
2024-12-09 13:47:46,520:INFO:Starting cross validation
2024-12-09 13:47:46,521:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:47:51,572:INFO:Calculating mean and std
2024-12-09 13:47:51,574:INFO:Creating metrics dataframe
2024-12-09 13:47:51,582:INFO:Uploading results into container
2024-12-09 13:47:51,582:INFO:Uploading model into container now
2024-12-09 13:47:51,583:INFO:_master_model_container: 1
2024-12-09 13:47:51,583:INFO:_display_container: 2
2024-12-09 13:47:51,583:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 13:47:51,583:INFO:create_model() successfully completed......................................
2024-12-09 13:47:51,661:INFO:SubProcess create_model() end ==================================
2024-12-09 13:47:51,661:INFO:Creating metrics dataframe
2024-12-09 13:47:51,669:INFO:Initializing K Neighbors Classifier
2024-12-09 13:47:51,669:INFO:Total runtime is 0.08637448151906331 minutes
2024-12-09 13:47:51,672:INFO:SubProcess create_model() called ==================================
2024-12-09 13:47:51,673:INFO:Initializing create_model()
2024-12-09 13:47:51,673:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32D91EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:47:51,673:INFO:Checking exceptions
2024-12-09 13:47:51,674:INFO:Importing libraries
2024-12-09 13:47:51,674:INFO:Copying training dataset
2024-12-09 13:47:51,678:INFO:Defining folds
2024-12-09 13:47:51,678:INFO:Declaring metric variables
2024-12-09 13:47:51,682:INFO:Importing untrained model
2024-12-09 13:47:51,687:INFO:K Neighbors Classifier Imported successfully
2024-12-09 13:47:51,697:INFO:Starting cross validation
2024-12-09 13:47:51,699:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:47:51,975:INFO:Calculating mean and std
2024-12-09 13:47:51,977:INFO:Creating metrics dataframe
2024-12-09 13:47:51,981:INFO:Uploading results into container
2024-12-09 13:47:51,981:INFO:Uploading model into container now
2024-12-09 13:47:51,982:INFO:_master_model_container: 2
2024-12-09 13:47:51,982:INFO:_display_container: 2
2024-12-09 13:47:51,982:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 13:47:51,983:INFO:create_model() successfully completed......................................
2024-12-09 13:47:52,051:INFO:SubProcess create_model() end ==================================
2024-12-09 13:47:52,052:INFO:Creating metrics dataframe
2024-12-09 13:47:52,062:INFO:Initializing Naive Bayes
2024-12-09 13:47:52,062:INFO:Total runtime is 0.09293136994043985 minutes
2024-12-09 13:47:52,065:INFO:SubProcess create_model() called ==================================
2024-12-09 13:47:52,066:INFO:Initializing create_model()
2024-12-09 13:47:52,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32D91EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:47:52,066:INFO:Checking exceptions
2024-12-09 13:47:52,066:INFO:Importing libraries
2024-12-09 13:47:52,066:INFO:Copying training dataset
2024-12-09 13:47:52,070:INFO:Defining folds
2024-12-09 13:47:52,070:INFO:Declaring metric variables
2024-12-09 13:47:52,073:INFO:Importing untrained model
2024-12-09 13:47:52,077:INFO:Naive Bayes Imported successfully
2024-12-09 13:47:52,087:INFO:Starting cross validation
2024-12-09 13:47:52,089:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:47:52,321:INFO:Calculating mean and std
2024-12-09 13:47:52,321:INFO:Creating metrics dataframe
2024-12-09 13:47:52,325:INFO:Uploading results into container
2024-12-09 13:47:52,326:INFO:Uploading model into container now
2024-12-09 13:47:52,326:INFO:_master_model_container: 3
2024-12-09 13:47:52,326:INFO:_display_container: 2
2024-12-09 13:47:52,327:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 13:47:52,327:INFO:create_model() successfully completed......................................
2024-12-09 13:47:52,396:INFO:SubProcess create_model() end ==================================
2024-12-09 13:47:52,396:INFO:Creating metrics dataframe
2024-12-09 13:47:52,406:INFO:Initializing Decision Tree Classifier
2024-12-09 13:47:52,407:INFO:Total runtime is 0.09867290258407592 minutes
2024-12-09 13:47:52,409:INFO:SubProcess create_model() called ==================================
2024-12-09 13:47:52,410:INFO:Initializing create_model()
2024-12-09 13:47:52,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32D91EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:47:52,411:INFO:Checking exceptions
2024-12-09 13:47:52,411:INFO:Importing libraries
2024-12-09 13:47:52,412:INFO:Copying training dataset
2024-12-09 13:47:52,415:INFO:Defining folds
2024-12-09 13:47:52,415:INFO:Declaring metric variables
2024-12-09 13:47:52,418:INFO:Importing untrained model
2024-12-09 13:47:52,421:INFO:Decision Tree Classifier Imported successfully
2024-12-09 13:47:52,431:INFO:Starting cross validation
2024-12-09 13:47:52,432:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:47:52,696:INFO:Calculating mean and std
2024-12-09 13:47:52,697:INFO:Creating metrics dataframe
2024-12-09 13:47:52,701:INFO:Uploading results into container
2024-12-09 13:47:52,701:INFO:Uploading model into container now
2024-12-09 13:47:52,702:INFO:_master_model_container: 4
2024-12-09 13:47:52,702:INFO:_display_container: 2
2024-12-09 13:47:52,702:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 13:47:52,702:INFO:create_model() successfully completed......................................
2024-12-09 13:47:52,776:INFO:SubProcess create_model() end ==================================
2024-12-09 13:47:52,776:INFO:Creating metrics dataframe
2024-12-09 13:47:52,787:INFO:Initializing SVM - Linear Kernel
2024-12-09 13:47:52,787:INFO:Total runtime is 0.10501370032628377 minutes
2024-12-09 13:47:52,790:INFO:SubProcess create_model() called ==================================
2024-12-09 13:47:52,790:INFO:Initializing create_model()
2024-12-09 13:47:52,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32D91EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:47:52,790:INFO:Checking exceptions
2024-12-09 13:47:52,790:INFO:Importing libraries
2024-12-09 13:47:52,791:INFO:Copying training dataset
2024-12-09 13:47:52,795:INFO:Defining folds
2024-12-09 13:47:52,795:INFO:Declaring metric variables
2024-12-09 13:47:52,798:INFO:Importing untrained model
2024-12-09 13:47:52,802:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 13:47:52,815:INFO:Starting cross validation
2024-12-09 13:47:52,817:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:47:52,935:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:47:52,937:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:47:52,938:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:47:52,938:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:47:52,948:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:47:52,956:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:47:52,959:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:47:53,033:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:47:53,034:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:47:53,036:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:47:53,038:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:47:53,041:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:47:53,049:INFO:Calculating mean and std
2024-12-09 13:47:53,050:INFO:Creating metrics dataframe
2024-12-09 13:47:53,053:INFO:Uploading results into container
2024-12-09 13:47:53,054:INFO:Uploading model into container now
2024-12-09 13:47:53,054:INFO:_master_model_container: 5
2024-12-09 13:47:53,054:INFO:_display_container: 2
2024-12-09 13:47:53,055:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 13:47:53,055:INFO:create_model() successfully completed......................................
2024-12-09 13:47:53,127:INFO:SubProcess create_model() end ==================================
2024-12-09 13:47:53,128:INFO:Creating metrics dataframe
2024-12-09 13:47:53,138:INFO:Initializing Ridge Classifier
2024-12-09 13:47:53,138:INFO:Total runtime is 0.11086505254109699 minutes
2024-12-09 13:47:53,141:INFO:SubProcess create_model() called ==================================
2024-12-09 13:47:53,141:INFO:Initializing create_model()
2024-12-09 13:47:53,142:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32D91EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:47:53,142:INFO:Checking exceptions
2024-12-09 13:47:53,142:INFO:Importing libraries
2024-12-09 13:47:53,142:INFO:Copying training dataset
2024-12-09 13:47:53,146:INFO:Defining folds
2024-12-09 13:47:53,146:INFO:Declaring metric variables
2024-12-09 13:47:53,149:INFO:Importing untrained model
2024-12-09 13:47:53,153:INFO:Ridge Classifier Imported successfully
2024-12-09 13:47:53,164:INFO:Starting cross validation
2024-12-09 13:47:53,166:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:47:53,288:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:47:53,291:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:47:53,291:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:47:53,292:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:47:53,302:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:47:53,305:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:47:53,383:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:47:53,384:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:47:53,384:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:47:53,388:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:47:53,396:INFO:Calculating mean and std
2024-12-09 13:47:53,396:INFO:Creating metrics dataframe
2024-12-09 13:47:53,400:INFO:Uploading results into container
2024-12-09 13:47:53,401:INFO:Uploading model into container now
2024-12-09 13:47:53,401:INFO:_master_model_container: 6
2024-12-09 13:47:53,401:INFO:_display_container: 2
2024-12-09 13:47:53,401:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 13:47:53,402:INFO:create_model() successfully completed......................................
2024-12-09 13:47:53,472:INFO:SubProcess create_model() end ==================================
2024-12-09 13:47:53,472:INFO:Creating metrics dataframe
2024-12-09 13:47:53,484:INFO:Initializing Random Forest Classifier
2024-12-09 13:47:53,484:INFO:Total runtime is 0.11662431955337522 minutes
2024-12-09 13:47:53,487:INFO:SubProcess create_model() called ==================================
2024-12-09 13:47:53,488:INFO:Initializing create_model()
2024-12-09 13:47:53,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32D91EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:47:53,488:INFO:Checking exceptions
2024-12-09 13:47:53,488:INFO:Importing libraries
2024-12-09 13:47:53,488:INFO:Copying training dataset
2024-12-09 13:47:53,492:INFO:Defining folds
2024-12-09 13:47:53,492:INFO:Declaring metric variables
2024-12-09 13:47:53,495:INFO:Importing untrained model
2024-12-09 13:47:53,499:INFO:Random Forest Classifier Imported successfully
2024-12-09 13:47:53,507:INFO:Starting cross validation
2024-12-09 13:47:53,509:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:47:54,351:INFO:Calculating mean and std
2024-12-09 13:47:54,353:INFO:Creating metrics dataframe
2024-12-09 13:47:54,356:INFO:Uploading results into container
2024-12-09 13:47:54,357:INFO:Uploading model into container now
2024-12-09 13:47:54,357:INFO:_master_model_container: 7
2024-12-09 13:47:54,357:INFO:_display_container: 2
2024-12-09 13:47:54,358:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 13:47:54,358:INFO:create_model() successfully completed......................................
2024-12-09 13:47:54,437:INFO:SubProcess create_model() end ==================================
2024-12-09 13:47:54,437:INFO:Creating metrics dataframe
2024-12-09 13:47:54,449:INFO:Initializing Quadratic Discriminant Analysis
2024-12-09 13:47:54,449:INFO:Total runtime is 0.13270967006683348 minutes
2024-12-09 13:47:54,453:INFO:SubProcess create_model() called ==================================
2024-12-09 13:47:54,453:INFO:Initializing create_model()
2024-12-09 13:47:54,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32D91EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:47:54,454:INFO:Checking exceptions
2024-12-09 13:47:54,454:INFO:Importing libraries
2024-12-09 13:47:54,454:INFO:Copying training dataset
2024-12-09 13:47:54,458:INFO:Defining folds
2024-12-09 13:47:54,459:INFO:Declaring metric variables
2024-12-09 13:47:54,463:INFO:Importing untrained model
2024-12-09 13:47:54,468:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 13:47:54,476:INFO:Starting cross validation
2024-12-09 13:47:54,477:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:47:54,569:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:47:54,571:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:47:54,575:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:47:54,588:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:47:54,599:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:47:54,672:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:47:54,681:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:47:54,690:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:47:54,691:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:47:54,730:INFO:Calculating mean and std
2024-12-09 13:47:54,731:INFO:Creating metrics dataframe
2024-12-09 13:47:54,735:INFO:Uploading results into container
2024-12-09 13:47:54,735:INFO:Uploading model into container now
2024-12-09 13:47:54,736:INFO:_master_model_container: 8
2024-12-09 13:47:54,736:INFO:_display_container: 2
2024-12-09 13:47:54,736:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 13:47:54,736:INFO:create_model() successfully completed......................................
2024-12-09 13:47:54,813:INFO:SubProcess create_model() end ==================================
2024-12-09 13:47:54,814:INFO:Creating metrics dataframe
2024-12-09 13:47:54,826:INFO:Initializing Ada Boost Classifier
2024-12-09 13:47:54,826:INFO:Total runtime is 0.13899856011072795 minutes
2024-12-09 13:47:54,831:INFO:SubProcess create_model() called ==================================
2024-12-09 13:47:54,831:INFO:Initializing create_model()
2024-12-09 13:47:54,831:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32D91EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:47:54,831:INFO:Checking exceptions
2024-12-09 13:47:54,832:INFO:Importing libraries
2024-12-09 13:47:54,832:INFO:Copying training dataset
2024-12-09 13:47:54,843:INFO:Defining folds
2024-12-09 13:47:54,845:INFO:Declaring metric variables
2024-12-09 13:47:54,857:INFO:Importing untrained model
2024-12-09 13:47:54,868:INFO:Ada Boost Classifier Imported successfully
2024-12-09 13:47:54,883:INFO:Starting cross validation
2024-12-09 13:47:54,885:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:47:55,328:INFO:Calculating mean and std
2024-12-09 13:47:55,330:INFO:Creating metrics dataframe
2024-12-09 13:47:55,333:INFO:Uploading results into container
2024-12-09 13:47:55,334:INFO:Uploading model into container now
2024-12-09 13:47:55,334:INFO:_master_model_container: 9
2024-12-09 13:47:55,334:INFO:_display_container: 2
2024-12-09 13:47:55,335:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 13:47:55,335:INFO:create_model() successfully completed......................................
2024-12-09 13:47:55,403:INFO:SubProcess create_model() end ==================================
2024-12-09 13:47:55,404:INFO:Creating metrics dataframe
2024-12-09 13:47:55,416:INFO:Initializing Gradient Boosting Classifier
2024-12-09 13:47:55,417:INFO:Total runtime is 0.1488474448521932 minutes
2024-12-09 13:47:55,420:INFO:SubProcess create_model() called ==================================
2024-12-09 13:47:55,420:INFO:Initializing create_model()
2024-12-09 13:47:55,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32D91EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:47:55,421:INFO:Checking exceptions
2024-12-09 13:47:55,421:INFO:Importing libraries
2024-12-09 13:47:55,421:INFO:Copying training dataset
2024-12-09 13:47:55,424:INFO:Defining folds
2024-12-09 13:47:55,425:INFO:Declaring metric variables
2024-12-09 13:47:55,428:INFO:Importing untrained model
2024-12-09 13:47:55,432:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 13:47:55,441:INFO:Starting cross validation
2024-12-09 13:47:55,443:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:47:55,887:INFO:Calculating mean and std
2024-12-09 13:47:55,888:INFO:Creating metrics dataframe
2024-12-09 13:47:55,892:INFO:Uploading results into container
2024-12-09 13:47:55,892:INFO:Uploading model into container now
2024-12-09 13:47:55,893:INFO:_master_model_container: 10
2024-12-09 13:47:55,893:INFO:_display_container: 2
2024-12-09 13:47:55,893:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 13:47:55,894:INFO:create_model() successfully completed......................................
2024-12-09 13:47:55,970:INFO:SubProcess create_model() end ==================================
2024-12-09 13:47:55,970:INFO:Creating metrics dataframe
2024-12-09 13:47:55,983:INFO:Initializing Linear Discriminant Analysis
2024-12-09 13:47:55,984:INFO:Total runtime is 0.15829186042149862 minutes
2024-12-09 13:47:55,987:INFO:SubProcess create_model() called ==================================
2024-12-09 13:47:55,988:INFO:Initializing create_model()
2024-12-09 13:47:55,988:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32D91EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:47:55,988:INFO:Checking exceptions
2024-12-09 13:47:55,988:INFO:Importing libraries
2024-12-09 13:47:55,988:INFO:Copying training dataset
2024-12-09 13:47:55,992:INFO:Defining folds
2024-12-09 13:47:55,992:INFO:Declaring metric variables
2024-12-09 13:47:55,995:INFO:Importing untrained model
2024-12-09 13:47:56,002:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 13:47:56,012:INFO:Starting cross validation
2024-12-09 13:47:56,014:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:47:56,274:INFO:Calculating mean and std
2024-12-09 13:47:56,274:INFO:Creating metrics dataframe
2024-12-09 13:47:56,278:INFO:Uploading results into container
2024-12-09 13:47:56,279:INFO:Uploading model into container now
2024-12-09 13:47:56,279:INFO:_master_model_container: 11
2024-12-09 13:47:56,279:INFO:_display_container: 2
2024-12-09 13:47:56,279:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 13:47:56,280:INFO:create_model() successfully completed......................................
2024-12-09 13:47:56,352:INFO:SubProcess create_model() end ==================================
2024-12-09 13:47:56,352:INFO:Creating metrics dataframe
2024-12-09 13:47:56,364:INFO:Initializing Extra Trees Classifier
2024-12-09 13:47:56,364:INFO:Total runtime is 0.16462289492289225 minutes
2024-12-09 13:47:56,368:INFO:SubProcess create_model() called ==================================
2024-12-09 13:47:56,369:INFO:Initializing create_model()
2024-12-09 13:47:56,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32D91EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:47:56,369:INFO:Checking exceptions
2024-12-09 13:47:56,369:INFO:Importing libraries
2024-12-09 13:47:56,369:INFO:Copying training dataset
2024-12-09 13:47:56,373:INFO:Defining folds
2024-12-09 13:47:56,373:INFO:Declaring metric variables
2024-12-09 13:47:56,376:INFO:Importing untrained model
2024-12-09 13:47:56,380:INFO:Extra Trees Classifier Imported successfully
2024-12-09 13:47:56,401:INFO:Starting cross validation
2024-12-09 13:47:56,402:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:47:57,140:INFO:Calculating mean and std
2024-12-09 13:47:57,140:INFO:Creating metrics dataframe
2024-12-09 13:47:57,144:INFO:Uploading results into container
2024-12-09 13:47:57,145:INFO:Uploading model into container now
2024-12-09 13:47:57,145:INFO:_master_model_container: 12
2024-12-09 13:47:57,145:INFO:_display_container: 2
2024-12-09 13:47:57,146:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 13:47:57,146:INFO:create_model() successfully completed......................................
2024-12-09 13:47:57,222:INFO:SubProcess create_model() end ==================================
2024-12-09 13:47:57,222:INFO:Creating metrics dataframe
2024-12-09 13:47:57,236:INFO:Initializing Light Gradient Boosting Machine
2024-12-09 13:47:57,236:INFO:Total runtime is 0.17916505734125773 minutes
2024-12-09 13:47:57,239:INFO:SubProcess create_model() called ==================================
2024-12-09 13:47:57,240:INFO:Initializing create_model()
2024-12-09 13:47:57,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32D91EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:47:57,240:INFO:Checking exceptions
2024-12-09 13:47:57,240:INFO:Importing libraries
2024-12-09 13:47:57,241:INFO:Copying training dataset
2024-12-09 13:47:57,244:INFO:Defining folds
2024-12-09 13:47:57,245:INFO:Declaring metric variables
2024-12-09 13:47:57,249:INFO:Importing untrained model
2024-12-09 13:47:57,254:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:47:57,264:INFO:Starting cross validation
2024-12-09 13:47:57,267:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:47:58,218:INFO:Calculating mean and std
2024-12-09 13:47:58,219:INFO:Creating metrics dataframe
2024-12-09 13:47:58,223:INFO:Uploading results into container
2024-12-09 13:47:58,224:INFO:Uploading model into container now
2024-12-09 13:47:58,225:INFO:_master_model_container: 13
2024-12-09 13:47:58,226:INFO:_display_container: 2
2024-12-09 13:47:58,227:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:47:58,227:INFO:create_model() successfully completed......................................
2024-12-09 13:47:58,308:INFO:SubProcess create_model() end ==================================
2024-12-09 13:47:58,308:INFO:Creating metrics dataframe
2024-12-09 13:47:58,325:INFO:Initializing Dummy Classifier
2024-12-09 13:47:58,325:INFO:Total runtime is 0.1973142147064209 minutes
2024-12-09 13:47:58,328:INFO:SubProcess create_model() called ==================================
2024-12-09 13:47:58,329:INFO:Initializing create_model()
2024-12-09 13:47:58,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32D91EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:47:58,329:INFO:Checking exceptions
2024-12-09 13:47:58,329:INFO:Importing libraries
2024-12-09 13:47:58,329:INFO:Copying training dataset
2024-12-09 13:47:58,336:INFO:Defining folds
2024-12-09 13:47:58,336:INFO:Declaring metric variables
2024-12-09 13:47:58,340:INFO:Importing untrained model
2024-12-09 13:47:58,345:INFO:Dummy Classifier Imported successfully
2024-12-09 13:47:58,356:INFO:Starting cross validation
2024-12-09 13:47:58,358:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:47:58,478:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:47:58,510:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:47:58,522:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:47:58,539:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:47:58,542:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:47:58,549:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:47:58,606:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:47:58,631:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:47:58,631:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:47:58,642:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:47:58,647:INFO:Calculating mean and std
2024-12-09 13:47:58,648:INFO:Creating metrics dataframe
2024-12-09 13:47:58,652:INFO:Uploading results into container
2024-12-09 13:47:58,653:INFO:Uploading model into container now
2024-12-09 13:47:58,654:INFO:_master_model_container: 14
2024-12-09 13:47:58,654:INFO:_display_container: 2
2024-12-09 13:47:58,654:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-12-09 13:47:58,654:INFO:create_model() successfully completed......................................
2024-12-09 13:47:58,730:INFO:SubProcess create_model() end ==================================
2024-12-09 13:47:58,730:INFO:Creating metrics dataframe
2024-12-09 13:47:58,759:INFO:Initializing create_model()
2024-12-09 13:47:58,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:47:58,759:INFO:Checking exceptions
2024-12-09 13:47:58,761:INFO:Importing libraries
2024-12-09 13:47:58,761:INFO:Copying training dataset
2024-12-09 13:47:58,765:INFO:Defining folds
2024-12-09 13:47:58,765:INFO:Declaring metric variables
2024-12-09 13:47:58,765:INFO:Importing untrained model
2024-12-09 13:47:58,765:INFO:Declaring custom model
2024-12-09 13:47:58,766:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:47:58,767:INFO:Cross validation set to False
2024-12-09 13:47:58,768:INFO:Fitting Model
2024-12-09 13:47:58,827:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 13:47:58,828:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.
2024-12-09 13:47:58,828:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 13:47:58,828:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 13:47:58,828:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 13:47:58,828:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 13:47:58,829:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 13:47:58,829:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 13:47:58,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:58,872:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:47:58,872:INFO:create_model() successfully completed......................................
2024-12-09 13:47:59,024:INFO:_master_model_container: 14
2024-12-09 13:47:59,024:INFO:_display_container: 2
2024-12-09 13:47:59,024:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:47:59,025:INFO:compare_models() successfully completed......................................
2024-12-09 13:47:59,025:INFO:Initializing finalize_model()
2024-12-09 13:47:59,031:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-09 13:47:59,032:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:47:59,040:INFO:Initializing create_model()
2024-12-09 13:47:59,040:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:47:59,040:INFO:Checking exceptions
2024-12-09 13:47:59,042:INFO:Importing libraries
2024-12-09 13:47:59,042:INFO:Copying training dataset
2024-12-09 13:47:59,042:INFO:Defining folds
2024-12-09 13:47:59,043:INFO:Declaring metric variables
2024-12-09 13:47:59,043:INFO:Importing untrained model
2024-12-09 13:47:59,043:INFO:Declaring custom model
2024-12-09 13:47:59,044:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:47:59,045:INFO:Cross validation set to False
2024-12-09 13:47:59,045:INFO:Fitting Model
2024-12-09 13:47:59,097:INFO:[LightGBM] [Info] Number of positive: 342, number of negative: 549
2024-12-09 13:47:59,097:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.
2024-12-09 13:47:59,097:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 13:47:59,097:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 13:47:59,097:INFO:[LightGBM] [Info] Total Bins 224
2024-12-09 13:47:59,097:INFO:[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 9
2024-12-09 13:47:59,097:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288
2024-12-09 13:47:59,097:INFO:[LightGBM] [Info] Start training from score -0.473288
2024-12-09 13:47:59,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:47:59,153:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-09 13:47:59,153:INFO:create_model() successfully completed......................................
2024-12-09 13:47:59,222:INFO:_master_model_container: 14
2024-12-09 13:47:59,223:INFO:_display_container: 2
2024-12-09 13:47:59,242:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-09 13:47:59,243:INFO:finalize_model() successfully completed......................................
2024-12-09 13:47:59,335:INFO:Initializing predict_model()
2024-12-09 13:47:59,335:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E32BE6340>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025E32316550>)
2024-12-09 13:47:59,335:INFO:Checking exceptions
2024-12-09 13:47:59,335:INFO:Preloading libraries
2024-12-09 13:47:59,337:INFO:Set up data.
2024-12-09 13:47:59,341:INFO:Set up index.
2024-12-09 13:48:29,796:INFO:PyCaret ClassificationExperiment
2024-12-09 13:48:29,796:INFO:Logging name: clf-default-name
2024-12-09 13:48:29,797:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-09 13:48:29,797:INFO:version 3.2.0
2024-12-09 13:48:29,797:INFO:Initializing setup()
2024-12-09 13:48:29,797:INFO:self.USI: afec
2024-12-09 13:48:29,797:INFO:self._variable_keys: {'fix_imbalance', 'log_plots_param', '_available_plots', 'X', 'seed', 'idx', 'gpu_param', '_ml_usecase', 'fold_generator', 'exp_name_log', 'y', 'is_multiclass', 'fold_shuffle_param', 'X_test', 'target_param', 'exp_id', 'logging_param', 'X_train', 'html_param', 'memory', 'fold_groups_param', 'y_train', 'n_jobs_param', 'data', 'gpu_n_jobs_param', 'USI', 'pipeline', 'y_test'}
2024-12-09 13:48:29,797:INFO:Checking environment
2024-12-09 13:48:29,797:INFO:python_version: 3.8.20
2024-12-09 13:48:29,797:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2024-12-09 13:48:29,797:INFO:machine: AMD64
2024-12-09 13:48:29,797:INFO:platform: Windows-10-10.0.19041-SP0
2024-12-09 13:48:29,802:INFO:Memory: svmem(total=17054896128, available=4516663296, percent=73.5, used=12538232832, free=4516663296)
2024-12-09 13:48:29,802:INFO:Physical Core: 6
2024-12-09 13:48:29,802:INFO:Logical Core: 6
2024-12-09 13:48:29,802:INFO:Checking libraries
2024-12-09 13:48:29,802:INFO:System:
2024-12-09 13:48:29,802:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2024-12-09 13:48:29,803:INFO:executable: c:\Users\EE715\anaconda3\envs\gym-env\python.exe
2024-12-09 13:48:29,803:INFO:   machine: Windows-10-10.0.19041-SP0
2024-12-09 13:48:29,803:INFO:PyCaret required dependencies:
2024-12-09 13:48:29,803:INFO:                 pip: 24.2
2024-12-09 13:48:29,803:INFO:          setuptools: 75.1.0
2024-12-09 13:48:29,803:INFO:             pycaret: 3.2.0
2024-12-09 13:48:29,803:INFO:             IPython: 8.12.3
2024-12-09 13:48:29,803:INFO:          ipywidgets: 8.1.5
2024-12-09 13:48:29,803:INFO:                tqdm: 4.67.1
2024-12-09 13:48:29,803:INFO:               numpy: 1.24.4
2024-12-09 13:48:29,803:INFO:              pandas: 1.5.3
2024-12-09 13:48:29,803:INFO:              jinja2: 3.1.4
2024-12-09 13:48:29,803:INFO:               scipy: 1.10.1
2024-12-09 13:48:29,803:INFO:              joblib: 1.2.0
2024-12-09 13:48:29,803:INFO:             sklearn: 1.2.2
2024-12-09 13:48:29,803:INFO:                pyod: 2.0.2
2024-12-09 13:48:29,803:INFO:            imblearn: 0.12.4
2024-12-09 13:48:29,804:INFO:   category_encoders: 2.6.4
2024-12-09 13:48:29,804:INFO:            lightgbm: 4.5.0
2024-12-09 13:48:29,804:INFO:               numba: 0.58.1
2024-12-09 13:48:29,804:INFO:            requests: 2.32.3
2024-12-09 13:48:29,804:INFO:          matplotlib: 3.6.0
2024-12-09 13:48:29,804:INFO:          scikitplot: 0.3.7
2024-12-09 13:48:29,804:INFO:         yellowbrick: 1.5
2024-12-09 13:48:29,804:INFO:              plotly: 5.24.1
2024-12-09 13:48:29,804:INFO:    plotly-resampler: Not installed
2024-12-09 13:48:29,804:INFO:             kaleido: 0.2.1
2024-12-09 13:48:29,804:INFO:           schemdraw: 0.15
2024-12-09 13:48:29,804:INFO:         statsmodels: 0.14.1
2024-12-09 13:48:29,804:INFO:              sktime: 0.21.1
2024-12-09 13:48:29,804:INFO:               tbats: 1.1.3
2024-12-09 13:48:29,804:INFO:            pmdarima: 2.0.4
2024-12-09 13:48:29,804:INFO:              psutil: 6.1.0
2024-12-09 13:48:29,804:INFO:          markupsafe: 2.1.5
2024-12-09 13:48:29,804:INFO:             pickle5: Not installed
2024-12-09 13:48:29,805:INFO:         cloudpickle: 3.1.0
2024-12-09 13:48:29,805:INFO:         deprecation: 2.1.0
2024-12-09 13:48:29,805:INFO:              xxhash: 3.5.0
2024-12-09 13:48:29,805:INFO:           wurlitzer: Not installed
2024-12-09 13:48:29,805:INFO:PyCaret optional dependencies:
2024-12-09 13:48:29,805:INFO:                shap: Not installed
2024-12-09 13:48:29,805:INFO:           interpret: Not installed
2024-12-09 13:48:29,805:INFO:                umap: Not installed
2024-12-09 13:48:29,805:INFO:     ydata_profiling: Not installed
2024-12-09 13:48:29,805:INFO:  explainerdashboard: Not installed
2024-12-09 13:48:29,805:INFO:             autoviz: Not installed
2024-12-09 13:48:29,805:INFO:           fairlearn: Not installed
2024-12-09 13:48:29,805:INFO:          deepchecks: Not installed
2024-12-09 13:48:29,805:INFO:             xgboost: Not installed
2024-12-09 13:48:29,805:INFO:            catboost: Not installed
2024-12-09 13:48:29,805:INFO:              kmodes: Not installed
2024-12-09 13:48:29,805:INFO:             mlxtend: Not installed
2024-12-09 13:48:29,805:INFO:       statsforecast: Not installed
2024-12-09 13:48:29,805:INFO:        tune_sklearn: Not installed
2024-12-09 13:48:29,805:INFO:                 ray: Not installed
2024-12-09 13:48:29,806:INFO:            hyperopt: Not installed
2024-12-09 13:48:29,806:INFO:              optuna: 4.1.0
2024-12-09 13:48:29,806:INFO:               skopt: Not installed
2024-12-09 13:48:29,806:INFO:              mlflow: Not installed
2024-12-09 13:48:29,806:INFO:              gradio: Not installed
2024-12-09 13:48:29,806:INFO:             fastapi: Not installed
2024-12-09 13:48:29,806:INFO:             uvicorn: Not installed
2024-12-09 13:48:29,806:INFO:              m2cgen: Not installed
2024-12-09 13:48:29,806:INFO:           evidently: Not installed
2024-12-09 13:48:29,806:INFO:               fugue: Not installed
2024-12-09 13:48:29,806:INFO:           streamlit: Not installed
2024-12-09 13:48:29,806:INFO:             prophet: Not installed
2024-12-09 13:48:29,806:INFO:None
2024-12-09 13:48:29,806:INFO:Set up data.
2024-12-09 13:48:29,818:INFO:Set up folding strategy.
2024-12-09 13:48:29,818:INFO:Set up train/test split.
2024-12-09 13:48:29,823:INFO:Set up index.
2024-12-09 13:48:29,823:INFO:Assigning column types.
2024-12-09 13:48:29,826:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-09 13:48:29,874:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 13:48:29,875:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:48:29,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:48:29,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:48:29,950:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 13:48:29,951:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:48:29,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:48:29,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:48:29,979:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-09 13:48:30,023:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:48:30,051:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:48:30,052:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:48:30,100:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:48:30,129:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:48:30,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:48:30,130:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-09 13:48:30,204:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:48:30,204:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:48:30,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:48:30,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:48:30,277:INFO:Preparing preprocessing pipeline...
2024-12-09 13:48:30,278:INFO:Set up simple imputation.
2024-12-09 13:48:30,281:INFO:Set up encoding of ordinal features.
2024-12-09 13:48:30,283:INFO:Set up encoding of categorical features.
2024-12-09 13:48:30,354:INFO:Finished creating preprocessing pipeline.
2024-12-09 13:48:30,372:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\EE715\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categ...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-12-09 13:48:30,372:INFO:Creating final display dataframe.
2024-12-09 13:48:30,581:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (623, 10)
6    Transformed test set shape         (268, 10)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              afec
2024-12-09 13:48:30,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:48:30,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:48:30,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:48:30,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:48:30,734:INFO:setup() successfully completed in 0.94s...............
2024-12-09 13:48:30,736:INFO:Initializing compare_models()
2024-12-09 13:48:30,736:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-12-09 13:48:30,736:INFO:Checking exceptions
2024-12-09 13:48:30,739:INFO:Preparing display monitor
2024-12-09 13:48:30,763:INFO:Initializing Logistic Regression
2024-12-09 13:48:30,763:INFO:Total runtime is 0.0 minutes
2024-12-09 13:48:30,769:INFO:SubProcess create_model() called ==================================
2024-12-09 13:48:30,769:INFO:Initializing create_model()
2024-12-09 13:48:30,770:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E16887CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:48:30,770:INFO:Checking exceptions
2024-12-09 13:48:30,770:INFO:Importing libraries
2024-12-09 13:48:30,770:INFO:Copying training dataset
2024-12-09 13:48:30,775:INFO:Defining folds
2024-12-09 13:48:30,775:INFO:Declaring metric variables
2024-12-09 13:48:30,780:INFO:Importing untrained model
2024-12-09 13:48:30,785:INFO:Logistic Regression Imported successfully
2024-12-09 13:48:30,793:INFO:Starting cross validation
2024-12-09 13:48:30,795:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:48:31,182:INFO:Calculating mean and std
2024-12-09 13:48:31,184:INFO:Creating metrics dataframe
2024-12-09 13:48:31,189:INFO:Uploading results into container
2024-12-09 13:48:31,191:INFO:Uploading model into container now
2024-12-09 13:48:31,191:INFO:_master_model_container: 1
2024-12-09 13:48:31,191:INFO:_display_container: 2
2024-12-09 13:48:31,191:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 13:48:31,192:INFO:create_model() successfully completed......................................
2024-12-09 13:48:31,305:INFO:SubProcess create_model() end ==================================
2024-12-09 13:48:31,305:INFO:Creating metrics dataframe
2024-12-09 13:48:31,314:INFO:Initializing K Neighbors Classifier
2024-12-09 13:48:31,314:INFO:Total runtime is 0.00917520523071289 minutes
2024-12-09 13:48:31,319:INFO:SubProcess create_model() called ==================================
2024-12-09 13:48:31,320:INFO:Initializing create_model()
2024-12-09 13:48:31,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E16887CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:48:31,320:INFO:Checking exceptions
2024-12-09 13:48:31,320:INFO:Importing libraries
2024-12-09 13:48:31,320:INFO:Copying training dataset
2024-12-09 13:48:31,324:INFO:Defining folds
2024-12-09 13:48:31,324:INFO:Declaring metric variables
2024-12-09 13:48:31,327:INFO:Importing untrained model
2024-12-09 13:48:31,331:INFO:K Neighbors Classifier Imported successfully
2024-12-09 13:48:31,342:INFO:Starting cross validation
2024-12-09 13:48:31,344:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:48:31,686:INFO:Calculating mean and std
2024-12-09 13:48:31,687:INFO:Creating metrics dataframe
2024-12-09 13:48:31,690:INFO:Uploading results into container
2024-12-09 13:48:31,690:INFO:Uploading model into container now
2024-12-09 13:48:31,691:INFO:_master_model_container: 2
2024-12-09 13:48:31,691:INFO:_display_container: 2
2024-12-09 13:48:31,691:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 13:48:31,691:INFO:create_model() successfully completed......................................
2024-12-09 13:48:31,779:INFO:SubProcess create_model() end ==================================
2024-12-09 13:48:31,780:INFO:Creating metrics dataframe
2024-12-09 13:48:31,789:INFO:Initializing Naive Bayes
2024-12-09 13:48:31,790:INFO:Total runtime is 0.017105376720428465 minutes
2024-12-09 13:48:31,793:INFO:SubProcess create_model() called ==================================
2024-12-09 13:48:31,793:INFO:Initializing create_model()
2024-12-09 13:48:31,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E16887CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:48:31,794:INFO:Checking exceptions
2024-12-09 13:48:31,794:INFO:Importing libraries
2024-12-09 13:48:31,794:INFO:Copying training dataset
2024-12-09 13:48:31,798:INFO:Defining folds
2024-12-09 13:48:31,798:INFO:Declaring metric variables
2024-12-09 13:48:31,803:INFO:Importing untrained model
2024-12-09 13:48:31,807:INFO:Naive Bayes Imported successfully
2024-12-09 13:48:31,814:INFO:Starting cross validation
2024-12-09 13:48:31,819:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:48:32,082:INFO:Calculating mean and std
2024-12-09 13:48:32,085:INFO:Creating metrics dataframe
2024-12-09 13:48:32,089:INFO:Uploading results into container
2024-12-09 13:48:32,090:INFO:Uploading model into container now
2024-12-09 13:48:32,090:INFO:_master_model_container: 3
2024-12-09 13:48:32,090:INFO:_display_container: 2
2024-12-09 13:48:32,090:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 13:48:32,091:INFO:create_model() successfully completed......................................
2024-12-09 13:48:32,182:INFO:SubProcess create_model() end ==================================
2024-12-09 13:48:32,183:INFO:Creating metrics dataframe
2024-12-09 13:48:32,193:INFO:Initializing Decision Tree Classifier
2024-12-09 13:48:32,193:INFO:Total runtime is 0.023827699820200603 minutes
2024-12-09 13:48:32,195:INFO:SubProcess create_model() called ==================================
2024-12-09 13:48:32,196:INFO:Initializing create_model()
2024-12-09 13:48:32,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E16887CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:48:32,196:INFO:Checking exceptions
2024-12-09 13:48:32,196:INFO:Importing libraries
2024-12-09 13:48:32,196:INFO:Copying training dataset
2024-12-09 13:48:32,201:INFO:Defining folds
2024-12-09 13:48:32,202:INFO:Declaring metric variables
2024-12-09 13:48:32,206:INFO:Importing untrained model
2024-12-09 13:48:32,211:INFO:Decision Tree Classifier Imported successfully
2024-12-09 13:48:32,219:INFO:Starting cross validation
2024-12-09 13:48:32,221:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:48:32,485:INFO:Calculating mean and std
2024-12-09 13:48:32,486:INFO:Creating metrics dataframe
2024-12-09 13:48:32,489:INFO:Uploading results into container
2024-12-09 13:48:32,490:INFO:Uploading model into container now
2024-12-09 13:48:32,491:INFO:_master_model_container: 4
2024-12-09 13:48:32,491:INFO:_display_container: 2
2024-12-09 13:48:32,491:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 13:48:32,491:INFO:create_model() successfully completed......................................
2024-12-09 13:48:32,594:INFO:SubProcess create_model() end ==================================
2024-12-09 13:48:32,594:INFO:Creating metrics dataframe
2024-12-09 13:48:32,604:INFO:Initializing SVM - Linear Kernel
2024-12-09 13:48:32,605:INFO:Total runtime is 0.030695319175720215 minutes
2024-12-09 13:48:32,608:INFO:SubProcess create_model() called ==================================
2024-12-09 13:48:32,608:INFO:Initializing create_model()
2024-12-09 13:48:32,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E16887CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:48:32,609:INFO:Checking exceptions
2024-12-09 13:48:32,609:INFO:Importing libraries
2024-12-09 13:48:32,609:INFO:Copying training dataset
2024-12-09 13:48:32,613:INFO:Defining folds
2024-12-09 13:48:32,613:INFO:Declaring metric variables
2024-12-09 13:48:32,618:INFO:Importing untrained model
2024-12-09 13:48:32,623:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 13:48:32,631:INFO:Starting cross validation
2024-12-09 13:48:32,633:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:48:32,750:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:48:32,752:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:48:32,753:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:48:32,754:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:48:32,757:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:48:32,756:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:48:32,771:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:48:32,844:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:48:32,846:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:48:32,847:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:48:32,850:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:48:32,851:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:48:32,858:INFO:Calculating mean and std
2024-12-09 13:48:32,860:INFO:Creating metrics dataframe
2024-12-09 13:48:32,863:INFO:Uploading results into container
2024-12-09 13:48:32,864:INFO:Uploading model into container now
2024-12-09 13:48:32,864:INFO:_master_model_container: 5
2024-12-09 13:48:32,865:INFO:_display_container: 2
2024-12-09 13:48:32,865:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 13:48:32,865:INFO:create_model() successfully completed......................................
2024-12-09 13:48:32,954:INFO:SubProcess create_model() end ==================================
2024-12-09 13:48:32,954:INFO:Creating metrics dataframe
2024-12-09 13:48:32,966:INFO:Initializing Ridge Classifier
2024-12-09 13:48:32,966:INFO:Total runtime is 0.03670382499694824 minutes
2024-12-09 13:48:32,969:INFO:SubProcess create_model() called ==================================
2024-12-09 13:48:32,970:INFO:Initializing create_model()
2024-12-09 13:48:32,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E16887CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:48:32,970:INFO:Checking exceptions
2024-12-09 13:48:32,970:INFO:Importing libraries
2024-12-09 13:48:32,970:INFO:Copying training dataset
2024-12-09 13:48:32,975:INFO:Defining folds
2024-12-09 13:48:32,975:INFO:Declaring metric variables
2024-12-09 13:48:32,978:INFO:Importing untrained model
2024-12-09 13:48:32,983:INFO:Ridge Classifier Imported successfully
2024-12-09 13:48:32,992:INFO:Starting cross validation
2024-12-09 13:48:32,993:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:48:33,111:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:48:33,112:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:48:33,113:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:48:33,115:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:48:33,115:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:48:33,143:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:48:33,203:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:48:33,203:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:48:33,207:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:48:33,209:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:48:33,217:INFO:Calculating mean and std
2024-12-09 13:48:33,218:INFO:Creating metrics dataframe
2024-12-09 13:48:33,223:INFO:Uploading results into container
2024-12-09 13:48:33,224:INFO:Uploading model into container now
2024-12-09 13:48:33,224:INFO:_master_model_container: 6
2024-12-09 13:48:33,224:INFO:_display_container: 2
2024-12-09 13:48:33,224:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 13:48:33,225:INFO:create_model() successfully completed......................................
2024-12-09 13:48:33,314:INFO:SubProcess create_model() end ==================================
2024-12-09 13:48:33,314:INFO:Creating metrics dataframe
2024-12-09 13:48:33,326:INFO:Initializing Random Forest Classifier
2024-12-09 13:48:33,326:INFO:Total runtime is 0.042706247170766196 minutes
2024-12-09 13:48:33,329:INFO:SubProcess create_model() called ==================================
2024-12-09 13:48:33,330:INFO:Initializing create_model()
2024-12-09 13:48:33,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E16887CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:48:33,330:INFO:Checking exceptions
2024-12-09 13:48:33,330:INFO:Importing libraries
2024-12-09 13:48:33,330:INFO:Copying training dataset
2024-12-09 13:48:33,334:INFO:Defining folds
2024-12-09 13:48:33,335:INFO:Declaring metric variables
2024-12-09 13:48:33,339:INFO:Importing untrained model
2024-12-09 13:48:33,344:INFO:Random Forest Classifier Imported successfully
2024-12-09 13:48:33,352:INFO:Starting cross validation
2024-12-09 13:48:33,354:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:48:34,355:INFO:Calculating mean and std
2024-12-09 13:48:34,356:INFO:Creating metrics dataframe
2024-12-09 13:48:34,359:INFO:Uploading results into container
2024-12-09 13:48:34,360:INFO:Uploading model into container now
2024-12-09 13:48:34,360:INFO:_master_model_container: 7
2024-12-09 13:48:34,360:INFO:_display_container: 2
2024-12-09 13:48:34,361:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 13:48:34,361:INFO:create_model() successfully completed......................................
2024-12-09 13:48:34,465:INFO:SubProcess create_model() end ==================================
2024-12-09 13:48:34,465:INFO:Creating metrics dataframe
2024-12-09 13:48:34,478:INFO:Initializing Quadratic Discriminant Analysis
2024-12-09 13:48:34,478:INFO:Total runtime is 0.06190686623255412 minutes
2024-12-09 13:48:34,481:INFO:SubProcess create_model() called ==================================
2024-12-09 13:48:34,482:INFO:Initializing create_model()
2024-12-09 13:48:34,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E16887CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:48:34,482:INFO:Checking exceptions
2024-12-09 13:48:34,482:INFO:Importing libraries
2024-12-09 13:48:34,482:INFO:Copying training dataset
2024-12-09 13:48:34,488:INFO:Defining folds
2024-12-09 13:48:34,489:INFO:Declaring metric variables
2024-12-09 13:48:34,492:INFO:Importing untrained model
2024-12-09 13:48:34,496:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 13:48:34,506:INFO:Starting cross validation
2024-12-09 13:48:34,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:48:34,581:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:48:34,583:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:48:34,593:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:48:34,612:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:48:34,647:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:48:34,655:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:48:34,689:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:48:34,699:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:48:34,732:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:48:34,766:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:48:34,807:INFO:Calculating mean and std
2024-12-09 13:48:34,808:INFO:Creating metrics dataframe
2024-12-09 13:48:34,814:INFO:Uploading results into container
2024-12-09 13:48:34,814:INFO:Uploading model into container now
2024-12-09 13:48:34,815:INFO:_master_model_container: 8
2024-12-09 13:48:34,815:INFO:_display_container: 2
2024-12-09 13:48:34,815:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 13:48:34,815:INFO:create_model() successfully completed......................................
2024-12-09 13:48:34,917:INFO:SubProcess create_model() end ==================================
2024-12-09 13:48:34,917:INFO:Creating metrics dataframe
2024-12-09 13:48:34,930:INFO:Initializing Ada Boost Classifier
2024-12-09 13:48:34,930:INFO:Total runtime is 0.06944413185119629 minutes
2024-12-09 13:48:34,933:INFO:SubProcess create_model() called ==================================
2024-12-09 13:48:34,933:INFO:Initializing create_model()
2024-12-09 13:48:34,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E16887CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:48:34,934:INFO:Checking exceptions
2024-12-09 13:48:34,934:INFO:Importing libraries
2024-12-09 13:48:34,934:INFO:Copying training dataset
2024-12-09 13:48:34,941:INFO:Defining folds
2024-12-09 13:48:34,941:INFO:Declaring metric variables
2024-12-09 13:48:34,944:INFO:Importing untrained model
2024-12-09 13:48:34,949:INFO:Ada Boost Classifier Imported successfully
2024-12-09 13:48:34,961:INFO:Starting cross validation
2024-12-09 13:48:34,963:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:48:35,428:INFO:Calculating mean and std
2024-12-09 13:48:35,429:INFO:Creating metrics dataframe
2024-12-09 13:48:35,432:INFO:Uploading results into container
2024-12-09 13:48:35,433:INFO:Uploading model into container now
2024-12-09 13:48:35,433:INFO:_master_model_container: 9
2024-12-09 13:48:35,434:INFO:_display_container: 2
2024-12-09 13:48:35,434:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 13:48:35,434:INFO:create_model() successfully completed......................................
2024-12-09 13:48:35,535:INFO:SubProcess create_model() end ==================================
2024-12-09 13:48:35,535:INFO:Creating metrics dataframe
2024-12-09 13:48:35,548:INFO:Initializing Gradient Boosting Classifier
2024-12-09 13:48:35,548:INFO:Total runtime is 0.07973711887995402 minutes
2024-12-09 13:48:35,552:INFO:SubProcess create_model() called ==================================
2024-12-09 13:48:35,552:INFO:Initializing create_model()
2024-12-09 13:48:35,553:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E16887CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:48:35,553:INFO:Checking exceptions
2024-12-09 13:48:35,553:INFO:Importing libraries
2024-12-09 13:48:35,553:INFO:Copying training dataset
2024-12-09 13:48:35,558:INFO:Defining folds
2024-12-09 13:48:35,558:INFO:Declaring metric variables
2024-12-09 13:48:35,574:INFO:Importing untrained model
2024-12-09 13:48:35,595:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 13:48:35,614:INFO:Starting cross validation
2024-12-09 13:48:35,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:48:36,179:INFO:Calculating mean and std
2024-12-09 13:48:36,180:INFO:Creating metrics dataframe
2024-12-09 13:48:36,184:INFO:Uploading results into container
2024-12-09 13:48:36,185:INFO:Uploading model into container now
2024-12-09 13:48:36,187:INFO:_master_model_container: 10
2024-12-09 13:48:36,187:INFO:_display_container: 2
2024-12-09 13:48:36,187:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 13:48:36,188:INFO:create_model() successfully completed......................................
2024-12-09 13:48:36,294:INFO:SubProcess create_model() end ==================================
2024-12-09 13:48:36,294:INFO:Creating metrics dataframe
2024-12-09 13:48:36,307:INFO:Initializing Linear Discriminant Analysis
2024-12-09 13:48:36,307:INFO:Total runtime is 0.09238865375518798 minutes
2024-12-09 13:48:36,311:INFO:SubProcess create_model() called ==================================
2024-12-09 13:48:36,311:INFO:Initializing create_model()
2024-12-09 13:48:36,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E16887CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:48:36,311:INFO:Checking exceptions
2024-12-09 13:48:36,312:INFO:Importing libraries
2024-12-09 13:48:36,312:INFO:Copying training dataset
2024-12-09 13:48:36,316:INFO:Defining folds
2024-12-09 13:48:36,317:INFO:Declaring metric variables
2024-12-09 13:48:36,321:INFO:Importing untrained model
2024-12-09 13:48:36,329:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 13:48:36,339:INFO:Starting cross validation
2024-12-09 13:48:36,341:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:48:36,604:INFO:Calculating mean and std
2024-12-09 13:48:36,606:INFO:Creating metrics dataframe
2024-12-09 13:48:36,609:INFO:Uploading results into container
2024-12-09 13:48:36,610:INFO:Uploading model into container now
2024-12-09 13:48:36,611:INFO:_master_model_container: 11
2024-12-09 13:48:36,611:INFO:_display_container: 2
2024-12-09 13:48:36,611:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 13:48:36,612:INFO:create_model() successfully completed......................................
2024-12-09 13:48:36,706:INFO:SubProcess create_model() end ==================================
2024-12-09 13:48:36,706:INFO:Creating metrics dataframe
2024-12-09 13:48:36,718:INFO:Initializing Extra Trees Classifier
2024-12-09 13:48:36,718:INFO:Total runtime is 0.09924737612406412 minutes
2024-12-09 13:48:36,722:INFO:SubProcess create_model() called ==================================
2024-12-09 13:48:36,723:INFO:Initializing create_model()
2024-12-09 13:48:36,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E16887CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:48:36,723:INFO:Checking exceptions
2024-12-09 13:48:36,723:INFO:Importing libraries
2024-12-09 13:48:36,723:INFO:Copying training dataset
2024-12-09 13:48:36,728:INFO:Defining folds
2024-12-09 13:48:36,728:INFO:Declaring metric variables
2024-12-09 13:48:36,731:INFO:Importing untrained model
2024-12-09 13:48:36,736:INFO:Extra Trees Classifier Imported successfully
2024-12-09 13:48:36,750:INFO:Starting cross validation
2024-12-09 13:48:36,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:48:37,721:INFO:Calculating mean and std
2024-12-09 13:48:37,723:INFO:Creating metrics dataframe
2024-12-09 13:48:37,729:INFO:Uploading results into container
2024-12-09 13:48:37,730:INFO:Uploading model into container now
2024-12-09 13:48:37,730:INFO:_master_model_container: 12
2024-12-09 13:48:37,730:INFO:_display_container: 2
2024-12-09 13:48:37,730:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 13:48:37,730:INFO:create_model() successfully completed......................................
2024-12-09 13:48:37,826:INFO:SubProcess create_model() end ==================================
2024-12-09 13:48:37,826:INFO:Creating metrics dataframe
2024-12-09 13:48:37,839:INFO:Initializing Light Gradient Boosting Machine
2024-12-09 13:48:37,840:INFO:Total runtime is 0.11795014937718709 minutes
2024-12-09 13:48:37,843:INFO:SubProcess create_model() called ==================================
2024-12-09 13:48:37,843:INFO:Initializing create_model()
2024-12-09 13:48:37,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E16887CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:48:37,843:INFO:Checking exceptions
2024-12-09 13:48:37,843:INFO:Importing libraries
2024-12-09 13:48:37,843:INFO:Copying training dataset
2024-12-09 13:48:37,849:INFO:Defining folds
2024-12-09 13:48:37,849:INFO:Declaring metric variables
2024-12-09 13:48:37,852:INFO:Importing untrained model
2024-12-09 13:48:37,860:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:48:37,867:INFO:Starting cross validation
2024-12-09 13:48:37,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:48:38,984:INFO:Calculating mean and std
2024-12-09 13:48:38,985:INFO:Creating metrics dataframe
2024-12-09 13:48:38,988:INFO:Uploading results into container
2024-12-09 13:48:38,989:INFO:Uploading model into container now
2024-12-09 13:48:38,991:INFO:_master_model_container: 13
2024-12-09 13:48:38,991:INFO:_display_container: 2
2024-12-09 13:48:38,992:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:48:38,992:INFO:create_model() successfully completed......................................
2024-12-09 13:48:39,096:INFO:SubProcess create_model() end ==================================
2024-12-09 13:48:39,097:INFO:Creating metrics dataframe
2024-12-09 13:48:39,110:INFO:Initializing Dummy Classifier
2024-12-09 13:48:39,110:INFO:Total runtime is 0.13910846710205077 minutes
2024-12-09 13:48:39,114:INFO:SubProcess create_model() called ==================================
2024-12-09 13:48:39,114:INFO:Initializing create_model()
2024-12-09 13:48:39,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E16887CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:48:39,115:INFO:Checking exceptions
2024-12-09 13:48:39,115:INFO:Importing libraries
2024-12-09 13:48:39,115:INFO:Copying training dataset
2024-12-09 13:48:39,119:INFO:Defining folds
2024-12-09 13:48:39,120:INFO:Declaring metric variables
2024-12-09 13:48:39,125:INFO:Importing untrained model
2024-12-09 13:48:39,130:INFO:Dummy Classifier Imported successfully
2024-12-09 13:48:39,138:INFO:Starting cross validation
2024-12-09 13:48:39,145:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:48:39,252:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:48:39,294:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:48:39,326:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:48:39,331:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:48:39,345:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:48:39,349:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:48:39,367:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:48:39,423:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:48:39,441:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:48:39,446:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:48:39,451:INFO:Calculating mean and std
2024-12-09 13:48:39,452:INFO:Creating metrics dataframe
2024-12-09 13:48:39,457:INFO:Uploading results into container
2024-12-09 13:48:39,458:INFO:Uploading model into container now
2024-12-09 13:48:39,459:INFO:_master_model_container: 14
2024-12-09 13:48:39,459:INFO:_display_container: 2
2024-12-09 13:48:39,459:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-12-09 13:48:39,459:INFO:create_model() successfully completed......................................
2024-12-09 13:48:39,611:INFO:SubProcess create_model() end ==================================
2024-12-09 13:48:39,612:INFO:Creating metrics dataframe
2024-12-09 13:48:39,639:INFO:Initializing create_model()
2024-12-09 13:48:39,639:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:48:39,640:INFO:Checking exceptions
2024-12-09 13:48:39,644:INFO:Importing libraries
2024-12-09 13:48:39,644:INFO:Copying training dataset
2024-12-09 13:48:39,648:INFO:Defining folds
2024-12-09 13:48:39,648:INFO:Declaring metric variables
2024-12-09 13:48:39,648:INFO:Importing untrained model
2024-12-09 13:48:39,648:INFO:Declaring custom model
2024-12-09 13:48:39,649:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:48:39,650:INFO:Cross validation set to False
2024-12-09 13:48:39,650:INFO:Fitting Model
2024-12-09 13:48:39,711:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 13:48:39,712:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.
2024-12-09 13:48:39,712:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 13:48:39,712:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 13:48:39,712:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 13:48:39,712:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 13:48:39,712:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 13:48:39,712:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 13:48:39,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:39,772:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:48:39,772:INFO:create_model() successfully completed......................................
2024-12-09 13:48:39,926:INFO:_master_model_container: 14
2024-12-09 13:48:39,926:INFO:_display_container: 2
2024-12-09 13:48:39,927:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:48:39,927:INFO:compare_models() successfully completed......................................
2024-12-09 13:48:39,929:INFO:Initializing finalize_model()
2024-12-09 13:48:39,929:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-09 13:48:39,929:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:48:39,933:INFO:Initializing create_model()
2024-12-09 13:48:39,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:48:39,933:INFO:Checking exceptions
2024-12-09 13:48:39,935:INFO:Importing libraries
2024-12-09 13:48:39,935:INFO:Copying training dataset
2024-12-09 13:48:39,935:INFO:Defining folds
2024-12-09 13:48:39,935:INFO:Declaring metric variables
2024-12-09 13:48:39,936:INFO:Importing untrained model
2024-12-09 13:48:39,936:INFO:Declaring custom model
2024-12-09 13:48:39,936:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:48:39,937:INFO:Cross validation set to False
2024-12-09 13:48:39,937:INFO:Fitting Model
2024-12-09 13:48:39,998:INFO:[LightGBM] [Info] Number of positive: 342, number of negative: 549
2024-12-09 13:48:39,998:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.
2024-12-09 13:48:39,998:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 13:48:39,998:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 13:48:39,998:INFO:[LightGBM] [Info] Total Bins 224
2024-12-09 13:48:39,998:INFO:[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 9
2024-12-09 13:48:39,999:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288
2024-12-09 13:48:39,999:INFO:[LightGBM] [Info] Start training from score -0.473288
2024-12-09 13:48:40,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:48:40,076:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-09 13:48:40,076:INFO:create_model() successfully completed......................................
2024-12-09 13:48:40,170:INFO:_master_model_container: 14
2024-12-09 13:48:40,170:INFO:_display_container: 2
2024-12-09 13:48:40,189:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-09 13:48:40,189:INFO:finalize_model() successfully completed......................................
2024-12-09 13:48:40,309:INFO:Initializing predict_model()
2024-12-09 13:48:40,309:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887850>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025E338FF310>)
2024-12-09 13:48:40,309:INFO:Checking exceptions
2024-12-09 13:48:40,309:INFO:Preloading libraries
2024-12-09 13:48:40,311:INFO:Set up data.
2024-12-09 13:48:40,316:INFO:Set up index.
2024-12-09 13:51:39,000:INFO:PyCaret ClassificationExperiment
2024-12-09 13:51:39,000:INFO:Logging name: clf-default-name
2024-12-09 13:51:39,000:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-09 13:51:39,000:INFO:version 3.2.0
2024-12-09 13:51:39,000:INFO:Initializing setup()
2024-12-09 13:51:39,000:INFO:self.USI: fabe
2024-12-09 13:51:39,000:INFO:self._variable_keys: {'fix_imbalance', 'log_plots_param', '_available_plots', 'X', 'seed', 'idx', 'gpu_param', '_ml_usecase', 'fold_generator', 'exp_name_log', 'y', 'is_multiclass', 'fold_shuffle_param', 'X_test', 'target_param', 'exp_id', 'logging_param', 'X_train', 'html_param', 'memory', 'fold_groups_param', 'y_train', 'n_jobs_param', 'data', 'gpu_n_jobs_param', 'USI', 'pipeline', 'y_test'}
2024-12-09 13:51:39,000:INFO:Checking environment
2024-12-09 13:51:39,001:INFO:python_version: 3.8.20
2024-12-09 13:51:39,001:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2024-12-09 13:51:39,001:INFO:machine: AMD64
2024-12-09 13:51:39,001:INFO:platform: Windows-10-10.0.19041-SP0
2024-12-09 13:51:39,004:INFO:Memory: svmem(total=17054896128, available=4488871936, percent=73.7, used=12566024192, free=4488871936)
2024-12-09 13:51:39,004:INFO:Physical Core: 6
2024-12-09 13:51:39,004:INFO:Logical Core: 6
2024-12-09 13:51:39,004:INFO:Checking libraries
2024-12-09 13:51:39,004:INFO:System:
2024-12-09 13:51:39,004:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2024-12-09 13:51:39,004:INFO:executable: c:\Users\EE715\anaconda3\envs\gym-env\python.exe
2024-12-09 13:51:39,004:INFO:   machine: Windows-10-10.0.19041-SP0
2024-12-09 13:51:39,004:INFO:PyCaret required dependencies:
2024-12-09 13:51:39,004:INFO:                 pip: 24.2
2024-12-09 13:51:39,004:INFO:          setuptools: 75.1.0
2024-12-09 13:51:39,004:INFO:             pycaret: 3.2.0
2024-12-09 13:51:39,004:INFO:             IPython: 8.12.3
2024-12-09 13:51:39,004:INFO:          ipywidgets: 8.1.5
2024-12-09 13:51:39,004:INFO:                tqdm: 4.67.1
2024-12-09 13:51:39,004:INFO:               numpy: 1.24.4
2024-12-09 13:51:39,005:INFO:              pandas: 1.5.3
2024-12-09 13:51:39,005:INFO:              jinja2: 3.1.4
2024-12-09 13:51:39,005:INFO:               scipy: 1.10.1
2024-12-09 13:51:39,005:INFO:              joblib: 1.2.0
2024-12-09 13:51:39,005:INFO:             sklearn: 1.2.2
2024-12-09 13:51:39,005:INFO:                pyod: 2.0.2
2024-12-09 13:51:39,005:INFO:            imblearn: 0.12.4
2024-12-09 13:51:39,005:INFO:   category_encoders: 2.6.4
2024-12-09 13:51:39,005:INFO:            lightgbm: 4.5.0
2024-12-09 13:51:39,005:INFO:               numba: 0.58.1
2024-12-09 13:51:39,005:INFO:            requests: 2.32.3
2024-12-09 13:51:39,005:INFO:          matplotlib: 3.6.0
2024-12-09 13:51:39,005:INFO:          scikitplot: 0.3.7
2024-12-09 13:51:39,005:INFO:         yellowbrick: 1.5
2024-12-09 13:51:39,005:INFO:              plotly: 5.24.1
2024-12-09 13:51:39,005:INFO:    plotly-resampler: Not installed
2024-12-09 13:51:39,005:INFO:             kaleido: 0.2.1
2024-12-09 13:51:39,005:INFO:           schemdraw: 0.15
2024-12-09 13:51:39,005:INFO:         statsmodels: 0.14.1
2024-12-09 13:51:39,005:INFO:              sktime: 0.21.1
2024-12-09 13:51:39,005:INFO:               tbats: 1.1.3
2024-12-09 13:51:39,006:INFO:            pmdarima: 2.0.4
2024-12-09 13:51:39,006:INFO:              psutil: 6.1.0
2024-12-09 13:51:39,006:INFO:          markupsafe: 2.1.5
2024-12-09 13:51:39,006:INFO:             pickle5: Not installed
2024-12-09 13:51:39,006:INFO:         cloudpickle: 3.1.0
2024-12-09 13:51:39,006:INFO:         deprecation: 2.1.0
2024-12-09 13:51:39,006:INFO:              xxhash: 3.5.0
2024-12-09 13:51:39,006:INFO:           wurlitzer: Not installed
2024-12-09 13:51:39,006:INFO:PyCaret optional dependencies:
2024-12-09 13:51:39,006:INFO:                shap: Not installed
2024-12-09 13:51:39,006:INFO:           interpret: Not installed
2024-12-09 13:51:39,006:INFO:                umap: Not installed
2024-12-09 13:51:39,006:INFO:     ydata_profiling: Not installed
2024-12-09 13:51:39,006:INFO:  explainerdashboard: Not installed
2024-12-09 13:51:39,006:INFO:             autoviz: Not installed
2024-12-09 13:51:39,006:INFO:           fairlearn: Not installed
2024-12-09 13:51:39,006:INFO:          deepchecks: Not installed
2024-12-09 13:51:39,006:INFO:             xgboost: Not installed
2024-12-09 13:51:39,006:INFO:            catboost: Not installed
2024-12-09 13:51:39,006:INFO:              kmodes: Not installed
2024-12-09 13:51:39,006:INFO:             mlxtend: Not installed
2024-12-09 13:51:39,006:INFO:       statsforecast: Not installed
2024-12-09 13:51:39,007:INFO:        tune_sklearn: Not installed
2024-12-09 13:51:39,007:INFO:                 ray: Not installed
2024-12-09 13:51:39,007:INFO:            hyperopt: Not installed
2024-12-09 13:51:39,007:INFO:              optuna: 4.1.0
2024-12-09 13:51:39,007:INFO:               skopt: Not installed
2024-12-09 13:51:39,007:INFO:              mlflow: Not installed
2024-12-09 13:51:39,007:INFO:              gradio: Not installed
2024-12-09 13:51:39,007:INFO:             fastapi: Not installed
2024-12-09 13:51:39,007:INFO:             uvicorn: Not installed
2024-12-09 13:51:39,007:INFO:              m2cgen: Not installed
2024-12-09 13:51:39,007:INFO:           evidently: Not installed
2024-12-09 13:51:39,007:INFO:               fugue: Not installed
2024-12-09 13:51:39,007:INFO:           streamlit: Not installed
2024-12-09 13:51:39,007:INFO:             prophet: Not installed
2024-12-09 13:51:39,007:INFO:None
2024-12-09 13:51:39,007:INFO:Set up data.
2024-12-09 13:51:39,014:INFO:Set up folding strategy.
2024-12-09 13:51:39,014:INFO:Set up train/test split.
2024-12-09 13:51:39,019:INFO:Set up index.
2024-12-09 13:51:39,019:INFO:Assigning column types.
2024-12-09 13:51:39,023:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-09 13:51:39,077:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 13:51:39,078:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:51:39,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:51:39,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:51:39,150:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 13:51:39,150:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:51:39,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:51:39,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:51:39,180:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-09 13:51:39,225:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:51:39,252:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:51:39,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:51:39,299:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:51:39,327:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:51:39,327:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:51:39,328:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-09 13:51:39,408:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:51:39,408:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:51:39,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:51:39,486:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:51:39,488:INFO:Preparing preprocessing pipeline...
2024-12-09 13:51:39,489:INFO:Set up simple imputation.
2024-12-09 13:51:39,492:INFO:Set up encoding of ordinal features.
2024-12-09 13:51:39,493:INFO:Set up encoding of categorical features.
2024-12-09 13:51:39,558:INFO:Finished creating preprocessing pipeline.
2024-12-09 13:51:39,575:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\EE715\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categ...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-12-09 13:51:39,576:INFO:Creating final display dataframe.
2024-12-09 13:51:39,780:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (623, 10)
6    Transformed test set shape         (268, 10)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              fabe
2024-12-09 13:51:39,858:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:51:39,859:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:51:39,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:51:39,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:51:39,932:INFO:setup() successfully completed in 0.93s...............
2024-12-09 13:51:39,933:INFO:Initializing compare_models()
2024-12-09 13:51:39,933:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-12-09 13:51:39,933:INFO:Checking exceptions
2024-12-09 13:51:39,936:INFO:Preparing display monitor
2024-12-09 13:51:39,964:INFO:Initializing Logistic Regression
2024-12-09 13:51:39,964:INFO:Total runtime is 0.0 minutes
2024-12-09 13:51:39,969:INFO:SubProcess create_model() called ==================================
2024-12-09 13:51:39,970:INFO:Initializing create_model()
2024-12-09 13:51:39,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32BE6370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:39,971:INFO:Checking exceptions
2024-12-09 13:51:39,971:INFO:Importing libraries
2024-12-09 13:51:39,971:INFO:Copying training dataset
2024-12-09 13:51:39,977:INFO:Defining folds
2024-12-09 13:51:39,977:INFO:Declaring metric variables
2024-12-09 13:51:39,983:INFO:Importing untrained model
2024-12-09 13:51:39,988:INFO:Logistic Regression Imported successfully
2024-12-09 13:51:39,997:INFO:Starting cross validation
2024-12-09 13:51:39,998:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:51:40,327:INFO:Calculating mean and std
2024-12-09 13:51:40,328:INFO:Creating metrics dataframe
2024-12-09 13:51:40,331:INFO:Uploading results into container
2024-12-09 13:51:40,332:INFO:Uploading model into container now
2024-12-09 13:51:40,332:INFO:_master_model_container: 1
2024-12-09 13:51:40,332:INFO:_display_container: 2
2024-12-09 13:51:40,332:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 13:51:40,332:INFO:create_model() successfully completed......................................
2024-12-09 13:51:40,444:INFO:SubProcess create_model() end ==================================
2024-12-09 13:51:40,444:INFO:Creating metrics dataframe
2024-12-09 13:51:40,453:INFO:Initializing K Neighbors Classifier
2024-12-09 13:51:40,453:INFO:Total runtime is 0.008151658376057943 minutes
2024-12-09 13:51:40,459:INFO:SubProcess create_model() called ==================================
2024-12-09 13:51:40,459:INFO:Initializing create_model()
2024-12-09 13:51:40,460:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32BE6370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:40,460:INFO:Checking exceptions
2024-12-09 13:51:40,460:INFO:Importing libraries
2024-12-09 13:51:40,460:INFO:Copying training dataset
2024-12-09 13:51:40,463:INFO:Defining folds
2024-12-09 13:51:40,464:INFO:Declaring metric variables
2024-12-09 13:51:40,467:INFO:Importing untrained model
2024-12-09 13:51:40,473:INFO:K Neighbors Classifier Imported successfully
2024-12-09 13:51:40,484:INFO:Starting cross validation
2024-12-09 13:51:40,486:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:51:40,819:INFO:Calculating mean and std
2024-12-09 13:51:40,819:INFO:Creating metrics dataframe
2024-12-09 13:51:40,823:INFO:Uploading results into container
2024-12-09 13:51:40,824:INFO:Uploading model into container now
2024-12-09 13:51:40,824:INFO:_master_model_container: 2
2024-12-09 13:51:40,824:INFO:_display_container: 2
2024-12-09 13:51:40,825:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 13:51:40,825:INFO:create_model() successfully completed......................................
2024-12-09 13:51:40,913:INFO:SubProcess create_model() end ==================================
2024-12-09 13:51:40,913:INFO:Creating metrics dataframe
2024-12-09 13:51:40,923:INFO:Initializing Naive Bayes
2024-12-09 13:51:40,923:INFO:Total runtime is 0.015977394580841065 minutes
2024-12-09 13:51:40,926:INFO:SubProcess create_model() called ==================================
2024-12-09 13:51:40,927:INFO:Initializing create_model()
2024-12-09 13:51:40,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32BE6370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:40,927:INFO:Checking exceptions
2024-12-09 13:51:40,927:INFO:Importing libraries
2024-12-09 13:51:40,927:INFO:Copying training dataset
2024-12-09 13:51:40,931:INFO:Defining folds
2024-12-09 13:51:40,931:INFO:Declaring metric variables
2024-12-09 13:51:40,934:INFO:Importing untrained model
2024-12-09 13:51:40,937:INFO:Naive Bayes Imported successfully
2024-12-09 13:51:40,947:INFO:Starting cross validation
2024-12-09 13:51:40,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:51:41,273:INFO:Calculating mean and std
2024-12-09 13:51:41,275:INFO:Creating metrics dataframe
2024-12-09 13:51:41,279:INFO:Uploading results into container
2024-12-09 13:51:41,280:INFO:Uploading model into container now
2024-12-09 13:51:41,280:INFO:_master_model_container: 3
2024-12-09 13:51:41,280:INFO:_display_container: 2
2024-12-09 13:51:41,280:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 13:51:41,281:INFO:create_model() successfully completed......................................
2024-12-09 13:51:41,380:INFO:SubProcess create_model() end ==================================
2024-12-09 13:51:41,380:INFO:Creating metrics dataframe
2024-12-09 13:51:41,391:INFO:Initializing Decision Tree Classifier
2024-12-09 13:51:41,391:INFO:Total runtime is 0.0237749973932902 minutes
2024-12-09 13:51:41,395:INFO:SubProcess create_model() called ==================================
2024-12-09 13:51:41,395:INFO:Initializing create_model()
2024-12-09 13:51:41,396:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32BE6370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:41,396:INFO:Checking exceptions
2024-12-09 13:51:41,396:INFO:Importing libraries
2024-12-09 13:51:41,396:INFO:Copying training dataset
2024-12-09 13:51:41,400:INFO:Defining folds
2024-12-09 13:51:41,400:INFO:Declaring metric variables
2024-12-09 13:51:41,404:INFO:Importing untrained model
2024-12-09 13:51:41,412:INFO:Decision Tree Classifier Imported successfully
2024-12-09 13:51:41,420:INFO:Starting cross validation
2024-12-09 13:51:41,421:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:51:41,716:INFO:Calculating mean and std
2024-12-09 13:51:41,717:INFO:Creating metrics dataframe
2024-12-09 13:51:41,721:INFO:Uploading results into container
2024-12-09 13:51:41,722:INFO:Uploading model into container now
2024-12-09 13:51:41,725:INFO:_master_model_container: 4
2024-12-09 13:51:41,725:INFO:_display_container: 2
2024-12-09 13:51:41,726:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 13:51:41,727:INFO:create_model() successfully completed......................................
2024-12-09 13:51:41,831:INFO:SubProcess create_model() end ==================================
2024-12-09 13:51:41,831:INFO:Creating metrics dataframe
2024-12-09 13:51:41,841:INFO:Initializing SVM - Linear Kernel
2024-12-09 13:51:41,841:INFO:Total runtime is 0.03127296368281046 minutes
2024-12-09 13:51:41,844:INFO:SubProcess create_model() called ==================================
2024-12-09 13:51:41,845:INFO:Initializing create_model()
2024-12-09 13:51:41,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32BE6370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:41,845:INFO:Checking exceptions
2024-12-09 13:51:41,845:INFO:Importing libraries
2024-12-09 13:51:41,845:INFO:Copying training dataset
2024-12-09 13:51:41,850:INFO:Defining folds
2024-12-09 13:51:41,850:INFO:Declaring metric variables
2024-12-09 13:51:41,853:INFO:Importing untrained model
2024-12-09 13:51:41,858:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 13:51:41,866:INFO:Starting cross validation
2024-12-09 13:51:41,867:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:51:41,981:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:51:41,981:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:51:41,981:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:51:41,985:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:51:41,985:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:51:41,986:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:51:42,000:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:51:42,077:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:51:42,077:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:51:42,080:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:51:42,084:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:51:42,088:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:51:42,095:INFO:Calculating mean and std
2024-12-09 13:51:42,096:INFO:Creating metrics dataframe
2024-12-09 13:51:42,100:INFO:Uploading results into container
2024-12-09 13:51:42,100:INFO:Uploading model into container now
2024-12-09 13:51:42,101:INFO:_master_model_container: 5
2024-12-09 13:51:42,101:INFO:_display_container: 2
2024-12-09 13:51:42,101:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 13:51:42,101:INFO:create_model() successfully completed......................................
2024-12-09 13:51:42,191:INFO:SubProcess create_model() end ==================================
2024-12-09 13:51:42,191:INFO:Creating metrics dataframe
2024-12-09 13:51:42,201:INFO:Initializing Ridge Classifier
2024-12-09 13:51:42,201:INFO:Total runtime is 0.037272791067759194 minutes
2024-12-09 13:51:42,204:INFO:SubProcess create_model() called ==================================
2024-12-09 13:51:42,204:INFO:Initializing create_model()
2024-12-09 13:51:42,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32BE6370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:42,204:INFO:Checking exceptions
2024-12-09 13:51:42,204:INFO:Importing libraries
2024-12-09 13:51:42,204:INFO:Copying training dataset
2024-12-09 13:51:42,211:INFO:Defining folds
2024-12-09 13:51:42,211:INFO:Declaring metric variables
2024-12-09 13:51:42,214:INFO:Importing untrained model
2024-12-09 13:51:42,218:INFO:Ridge Classifier Imported successfully
2024-12-09 13:51:42,228:INFO:Starting cross validation
2024-12-09 13:51:42,230:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:51:42,345:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:51:42,348:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:51:42,351:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:51:42,358:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:51:42,374:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:51:42,382:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:51:42,443:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:51:42,446:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:51:42,448:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:51:42,458:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:51:42,465:INFO:Calculating mean and std
2024-12-09 13:51:42,466:INFO:Creating metrics dataframe
2024-12-09 13:51:42,470:INFO:Uploading results into container
2024-12-09 13:51:42,470:INFO:Uploading model into container now
2024-12-09 13:51:42,471:INFO:_master_model_container: 6
2024-12-09 13:51:42,471:INFO:_display_container: 2
2024-12-09 13:51:42,471:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 13:51:42,471:INFO:create_model() successfully completed......................................
2024-12-09 13:51:42,561:INFO:SubProcess create_model() end ==================================
2024-12-09 13:51:42,561:INFO:Creating metrics dataframe
2024-12-09 13:51:42,573:INFO:Initializing Random Forest Classifier
2024-12-09 13:51:42,574:INFO:Total runtime is 0.04350432554880778 minutes
2024-12-09 13:51:42,579:INFO:SubProcess create_model() called ==================================
2024-12-09 13:51:42,579:INFO:Initializing create_model()
2024-12-09 13:51:42,579:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32BE6370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:42,579:INFO:Checking exceptions
2024-12-09 13:51:42,580:INFO:Importing libraries
2024-12-09 13:51:42,580:INFO:Copying training dataset
2024-12-09 13:51:42,584:INFO:Defining folds
2024-12-09 13:51:42,584:INFO:Declaring metric variables
2024-12-09 13:51:42,587:INFO:Importing untrained model
2024-12-09 13:51:42,597:INFO:Random Forest Classifier Imported successfully
2024-12-09 13:51:42,605:INFO:Starting cross validation
2024-12-09 13:51:42,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:51:43,418:INFO:Calculating mean and std
2024-12-09 13:51:43,419:INFO:Creating metrics dataframe
2024-12-09 13:51:43,422:INFO:Uploading results into container
2024-12-09 13:51:43,422:INFO:Uploading model into container now
2024-12-09 13:51:43,423:INFO:_master_model_container: 7
2024-12-09 13:51:43,423:INFO:_display_container: 2
2024-12-09 13:51:43,424:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 13:51:43,424:INFO:create_model() successfully completed......................................
2024-12-09 13:51:43,510:INFO:SubProcess create_model() end ==================================
2024-12-09 13:51:43,510:INFO:Creating metrics dataframe
2024-12-09 13:51:43,521:INFO:Initializing Quadratic Discriminant Analysis
2024-12-09 13:51:43,521:INFO:Total runtime is 0.05928562879562378 minutes
2024-12-09 13:51:43,528:INFO:SubProcess create_model() called ==================================
2024-12-09 13:51:43,528:INFO:Initializing create_model()
2024-12-09 13:51:43,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32BE6370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:43,528:INFO:Checking exceptions
2024-12-09 13:51:43,528:INFO:Importing libraries
2024-12-09 13:51:43,528:INFO:Copying training dataset
2024-12-09 13:51:43,532:INFO:Defining folds
2024-12-09 13:51:43,532:INFO:Declaring metric variables
2024-12-09 13:51:43,537:INFO:Importing untrained model
2024-12-09 13:51:43,542:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 13:51:43,549:INFO:Starting cross validation
2024-12-09 13:51:43,550:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:51:43,623:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:51:43,626:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:51:43,629:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:51:43,629:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:51:43,630:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:51:43,648:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:51:43,719:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:51:43,720:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:51:43,721:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:51:43,722:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:51:43,759:INFO:Calculating mean and std
2024-12-09 13:51:43,761:INFO:Creating metrics dataframe
2024-12-09 13:51:43,764:INFO:Uploading results into container
2024-12-09 13:51:43,765:INFO:Uploading model into container now
2024-12-09 13:51:43,765:INFO:_master_model_container: 8
2024-12-09 13:51:43,765:INFO:_display_container: 2
2024-12-09 13:51:43,765:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 13:51:43,765:INFO:create_model() successfully completed......................................
2024-12-09 13:51:43,867:INFO:SubProcess create_model() end ==================================
2024-12-09 13:51:43,868:INFO:Creating metrics dataframe
2024-12-09 13:51:43,880:INFO:Initializing Ada Boost Classifier
2024-12-09 13:51:43,880:INFO:Total runtime is 0.06525524854660035 minutes
2024-12-09 13:51:43,883:INFO:SubProcess create_model() called ==================================
2024-12-09 13:51:43,883:INFO:Initializing create_model()
2024-12-09 13:51:43,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32BE6370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:43,884:INFO:Checking exceptions
2024-12-09 13:51:43,884:INFO:Importing libraries
2024-12-09 13:51:43,884:INFO:Copying training dataset
2024-12-09 13:51:43,889:INFO:Defining folds
2024-12-09 13:51:43,890:INFO:Declaring metric variables
2024-12-09 13:51:43,896:INFO:Importing untrained model
2024-12-09 13:51:43,901:INFO:Ada Boost Classifier Imported successfully
2024-12-09 13:51:43,912:INFO:Starting cross validation
2024-12-09 13:51:43,913:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:51:44,314:INFO:Calculating mean and std
2024-12-09 13:51:44,315:INFO:Creating metrics dataframe
2024-12-09 13:51:44,319:INFO:Uploading results into container
2024-12-09 13:51:44,319:INFO:Uploading model into container now
2024-12-09 13:51:44,319:INFO:_master_model_container: 9
2024-12-09 13:51:44,320:INFO:_display_container: 2
2024-12-09 13:51:44,320:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 13:51:44,320:INFO:create_model() successfully completed......................................
2024-12-09 13:51:44,410:INFO:SubProcess create_model() end ==================================
2024-12-09 13:51:44,410:INFO:Creating metrics dataframe
2024-12-09 13:51:44,421:INFO:Initializing Gradient Boosting Classifier
2024-12-09 13:51:44,421:INFO:Total runtime is 0.07428178787231446 minutes
2024-12-09 13:51:44,425:INFO:SubProcess create_model() called ==================================
2024-12-09 13:51:44,426:INFO:Initializing create_model()
2024-12-09 13:51:44,426:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32BE6370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:44,427:INFO:Checking exceptions
2024-12-09 13:51:44,427:INFO:Importing libraries
2024-12-09 13:51:44,427:INFO:Copying training dataset
2024-12-09 13:51:44,431:INFO:Defining folds
2024-12-09 13:51:44,431:INFO:Declaring metric variables
2024-12-09 13:51:44,434:INFO:Importing untrained model
2024-12-09 13:51:44,439:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 13:51:44,479:INFO:Starting cross validation
2024-12-09 13:51:44,482:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:51:45,031:INFO:Calculating mean and std
2024-12-09 13:51:45,032:INFO:Creating metrics dataframe
2024-12-09 13:51:45,035:INFO:Uploading results into container
2024-12-09 13:51:45,036:INFO:Uploading model into container now
2024-12-09 13:51:45,036:INFO:_master_model_container: 10
2024-12-09 13:51:45,036:INFO:_display_container: 2
2024-12-09 13:51:45,037:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 13:51:45,037:INFO:create_model() successfully completed......................................
2024-12-09 13:51:45,150:INFO:SubProcess create_model() end ==================================
2024-12-09 13:51:45,150:INFO:Creating metrics dataframe
2024-12-09 13:51:45,164:INFO:Initializing Linear Discriminant Analysis
2024-12-09 13:51:45,164:INFO:Total runtime is 0.08666789134343465 minutes
2024-12-09 13:51:45,168:INFO:SubProcess create_model() called ==================================
2024-12-09 13:51:45,168:INFO:Initializing create_model()
2024-12-09 13:51:45,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32BE6370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:45,168:INFO:Checking exceptions
2024-12-09 13:51:45,168:INFO:Importing libraries
2024-12-09 13:51:45,169:INFO:Copying training dataset
2024-12-09 13:51:45,173:INFO:Defining folds
2024-12-09 13:51:45,173:INFO:Declaring metric variables
2024-12-09 13:51:45,178:INFO:Importing untrained model
2024-12-09 13:51:45,183:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 13:51:45,190:INFO:Starting cross validation
2024-12-09 13:51:45,196:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:51:45,487:INFO:Calculating mean and std
2024-12-09 13:51:45,488:INFO:Creating metrics dataframe
2024-12-09 13:51:45,492:INFO:Uploading results into container
2024-12-09 13:51:45,493:INFO:Uploading model into container now
2024-12-09 13:51:45,493:INFO:_master_model_container: 11
2024-12-09 13:51:45,494:INFO:_display_container: 2
2024-12-09 13:51:45,494:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 13:51:45,494:INFO:create_model() successfully completed......................................
2024-12-09 13:51:45,582:INFO:SubProcess create_model() end ==================================
2024-12-09 13:51:45,582:INFO:Creating metrics dataframe
2024-12-09 13:51:45,595:INFO:Initializing Extra Trees Classifier
2024-12-09 13:51:45,595:INFO:Total runtime is 0.09384538332621256 minutes
2024-12-09 13:51:45,598:INFO:SubProcess create_model() called ==================================
2024-12-09 13:51:45,598:INFO:Initializing create_model()
2024-12-09 13:51:45,598:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32BE6370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:45,598:INFO:Checking exceptions
2024-12-09 13:51:45,598:INFO:Importing libraries
2024-12-09 13:51:45,598:INFO:Copying training dataset
2024-12-09 13:51:45,603:INFO:Defining folds
2024-12-09 13:51:45,604:INFO:Declaring metric variables
2024-12-09 13:51:45,607:INFO:Importing untrained model
2024-12-09 13:51:45,615:INFO:Extra Trees Classifier Imported successfully
2024-12-09 13:51:45,623:INFO:Starting cross validation
2024-12-09 13:51:45,625:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:51:46,650:INFO:Calculating mean and std
2024-12-09 13:51:46,651:INFO:Creating metrics dataframe
2024-12-09 13:51:46,654:INFO:Uploading results into container
2024-12-09 13:51:46,655:INFO:Uploading model into container now
2024-12-09 13:51:46,655:INFO:_master_model_container: 12
2024-12-09 13:51:46,656:INFO:_display_container: 2
2024-12-09 13:51:46,656:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 13:51:46,656:INFO:create_model() successfully completed......................................
2024-12-09 13:51:46,772:INFO:SubProcess create_model() end ==================================
2024-12-09 13:51:46,773:INFO:Creating metrics dataframe
2024-12-09 13:51:46,788:INFO:Initializing Light Gradient Boosting Machine
2024-12-09 13:51:46,788:INFO:Total runtime is 0.11373496055603027 minutes
2024-12-09 13:51:46,794:INFO:SubProcess create_model() called ==================================
2024-12-09 13:51:46,796:INFO:Initializing create_model()
2024-12-09 13:51:46,796:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32BE6370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:46,796:INFO:Checking exceptions
2024-12-09 13:51:46,796:INFO:Importing libraries
2024-12-09 13:51:46,796:INFO:Copying training dataset
2024-12-09 13:51:46,802:INFO:Defining folds
2024-12-09 13:51:46,802:INFO:Declaring metric variables
2024-12-09 13:51:46,806:INFO:Importing untrained model
2024-12-09 13:51:46,819:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:51:46,828:INFO:Starting cross validation
2024-12-09 13:51:46,831:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:51:48,397:INFO:Calculating mean and std
2024-12-09 13:51:48,398:INFO:Creating metrics dataframe
2024-12-09 13:51:48,401:INFO:Uploading results into container
2024-12-09 13:51:48,402:INFO:Uploading model into container now
2024-12-09 13:51:48,403:INFO:_master_model_container: 13
2024-12-09 13:51:48,403:INFO:_display_container: 2
2024-12-09 13:51:48,403:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:51:48,403:INFO:create_model() successfully completed......................................
2024-12-09 13:51:48,505:INFO:SubProcess create_model() end ==================================
2024-12-09 13:51:48,505:INFO:Creating metrics dataframe
2024-12-09 13:51:48,517:INFO:Initializing Dummy Classifier
2024-12-09 13:51:48,517:INFO:Total runtime is 0.14254475434621175 minutes
2024-12-09 13:51:48,521:INFO:SubProcess create_model() called ==================================
2024-12-09 13:51:48,522:INFO:Initializing create_model()
2024-12-09 13:51:48,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E32BE6370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:48,522:INFO:Checking exceptions
2024-12-09 13:51:48,522:INFO:Importing libraries
2024-12-09 13:51:48,522:INFO:Copying training dataset
2024-12-09 13:51:48,526:INFO:Defining folds
2024-12-09 13:51:48,527:INFO:Declaring metric variables
2024-12-09 13:51:48,531:INFO:Importing untrained model
2024-12-09 13:51:48,535:INFO:Dummy Classifier Imported successfully
2024-12-09 13:51:48,542:INFO:Starting cross validation
2024-12-09 13:51:48,544:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:51:48,639:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:51:48,648:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:51:48,654:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:51:48,689:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:51:48,693:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:51:48,710:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:51:48,726:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:51:48,731:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:51:48,791:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:51:48,802:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:51:48,821:INFO:Calculating mean and std
2024-12-09 13:51:48,822:INFO:Creating metrics dataframe
2024-12-09 13:51:48,827:INFO:Uploading results into container
2024-12-09 13:51:48,829:INFO:Uploading model into container now
2024-12-09 13:51:48,830:INFO:_master_model_container: 14
2024-12-09 13:51:48,831:INFO:_display_container: 2
2024-12-09 13:51:48,831:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-12-09 13:51:48,831:INFO:create_model() successfully completed......................................
2024-12-09 13:51:48,973:INFO:SubProcess create_model() end ==================================
2024-12-09 13:51:48,974:INFO:Creating metrics dataframe
2024-12-09 13:51:49,006:INFO:Initializing create_model()
2024-12-09 13:51:49,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:49,007:INFO:Checking exceptions
2024-12-09 13:51:49,009:INFO:Importing libraries
2024-12-09 13:51:49,009:INFO:Copying training dataset
2024-12-09 13:51:49,014:INFO:Defining folds
2024-12-09 13:51:49,014:INFO:Declaring metric variables
2024-12-09 13:51:49,014:INFO:Importing untrained model
2024-12-09 13:51:49,014:INFO:Declaring custom model
2024-12-09 13:51:49,016:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:51:49,020:INFO:Cross validation set to False
2024-12-09 13:51:49,021:INFO:Fitting Model
2024-12-09 13:51:49,083:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 13:51:49,083:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.
2024-12-09 13:51:49,084:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 13:51:49,084:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 13:51:49,084:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 13:51:49,084:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 13:51:49,084:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 13:51:49,084:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 13:51:49,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:51:49,145:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:51:49,145:INFO:create_model() successfully completed......................................
2024-12-09 13:51:49,273:INFO:Initializing create_model()
2024-12-09 13:51:49,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:49,273:INFO:Checking exceptions
2024-12-09 13:51:49,277:INFO:Importing libraries
2024-12-09 13:51:49,277:INFO:Copying training dataset
2024-12-09 13:51:49,282:INFO:Defining folds
2024-12-09 13:51:49,282:INFO:Declaring metric variables
2024-12-09 13:51:49,282:INFO:Importing untrained model
2024-12-09 13:51:49,282:INFO:Declaring custom model
2024-12-09 13:51:49,283:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 13:51:49,284:INFO:Cross validation set to False
2024-12-09 13:51:49,284:INFO:Fitting Model
2024-12-09 13:51:49,431:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 13:51:49,431:INFO:create_model() successfully completed......................................
2024-12-09 13:51:49,525:INFO:Initializing create_model()
2024-12-09 13:51:49,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:49,525:INFO:Checking exceptions
2024-12-09 13:51:49,527:INFO:Importing libraries
2024-12-09 13:51:49,527:INFO:Copying training dataset
2024-12-09 13:51:49,531:INFO:Defining folds
2024-12-09 13:51:49,531:INFO:Declaring metric variables
2024-12-09 13:51:49,531:INFO:Importing untrained model
2024-12-09 13:51:49,531:INFO:Declaring custom model
2024-12-09 13:51:49,532:INFO:Random Forest Classifier Imported successfully
2024-12-09 13:51:49,533:INFO:Cross validation set to False
2024-12-09 13:51:49,533:INFO:Fitting Model
2024-12-09 13:51:49,737:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 13:51:49,738:INFO:create_model() successfully completed......................................
2024-12-09 13:51:49,822:INFO:Initializing create_model()
2024-12-09 13:51:49,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:49,822:INFO:Checking exceptions
2024-12-09 13:51:49,824:INFO:Importing libraries
2024-12-09 13:51:49,824:INFO:Copying training dataset
2024-12-09 13:51:49,828:INFO:Defining folds
2024-12-09 13:51:49,828:INFO:Declaring metric variables
2024-12-09 13:51:49,828:INFO:Importing untrained model
2024-12-09 13:51:49,828:INFO:Declaring custom model
2024-12-09 13:51:49,828:INFO:Ada Boost Classifier Imported successfully
2024-12-09 13:51:49,829:INFO:Cross validation set to False
2024-12-09 13:51:49,829:INFO:Fitting Model
2024-12-09 13:51:49,939:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 13:51:49,939:INFO:create_model() successfully completed......................................
2024-12-09 13:51:50,025:INFO:Initializing create_model()
2024-12-09 13:51:50,026:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:50,026:INFO:Checking exceptions
2024-12-09 13:51:50,028:INFO:Importing libraries
2024-12-09 13:51:50,028:INFO:Copying training dataset
2024-12-09 13:51:50,032:INFO:Defining folds
2024-12-09 13:51:50,032:INFO:Declaring metric variables
2024-12-09 13:51:50,032:INFO:Importing untrained model
2024-12-09 13:51:50,032:INFO:Declaring custom model
2024-12-09 13:51:50,032:INFO:Logistic Regression Imported successfully
2024-12-09 13:51:50,033:INFO:Cross validation set to False
2024-12-09 13:51:50,033:INFO:Fitting Model
2024-12-09 13:51:50,113:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 13:51:50,113:INFO:create_model() successfully completed......................................
2024-12-09 13:51:50,202:INFO:Initializing create_model()
2024-12-09 13:51:50,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:50,202:INFO:Checking exceptions
2024-12-09 13:51:50,204:INFO:Importing libraries
2024-12-09 13:51:50,205:INFO:Copying training dataset
2024-12-09 13:51:50,210:INFO:Defining folds
2024-12-09 13:51:50,210:INFO:Declaring metric variables
2024-12-09 13:51:50,211:INFO:Importing untrained model
2024-12-09 13:51:50,211:INFO:Declaring custom model
2024-12-09 13:51:50,211:INFO:Extra Trees Classifier Imported successfully
2024-12-09 13:51:50,212:INFO:Cross validation set to False
2024-12-09 13:51:50,212:INFO:Fitting Model
2024-12-09 13:51:50,392:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 13:51:50,393:INFO:create_model() successfully completed......................................
2024-12-09 13:51:50,477:INFO:Initializing create_model()
2024-12-09 13:51:50,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:50,477:INFO:Checking exceptions
2024-12-09 13:51:50,479:INFO:Importing libraries
2024-12-09 13:51:50,480:INFO:Copying training dataset
2024-12-09 13:51:50,483:INFO:Defining folds
2024-12-09 13:51:50,483:INFO:Declaring metric variables
2024-12-09 13:51:50,483:INFO:Importing untrained model
2024-12-09 13:51:50,483:INFO:Declaring custom model
2024-12-09 13:51:50,484:INFO:Ridge Classifier Imported successfully
2024-12-09 13:51:50,485:INFO:Cross validation set to False
2024-12-09 13:51:50,485:INFO:Fitting Model
2024-12-09 13:51:50,526:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 13:51:50,526:INFO:create_model() successfully completed......................................
2024-12-09 13:51:50,610:INFO:Initializing create_model()
2024-12-09 13:51:50,611:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:50,611:INFO:Checking exceptions
2024-12-09 13:51:50,613:INFO:Importing libraries
2024-12-09 13:51:50,613:INFO:Copying training dataset
2024-12-09 13:51:50,616:INFO:Defining folds
2024-12-09 13:51:50,616:INFO:Declaring metric variables
2024-12-09 13:51:50,616:INFO:Importing untrained model
2024-12-09 13:51:50,616:INFO:Declaring custom model
2024-12-09 13:51:50,617:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 13:51:50,618:INFO:Cross validation set to False
2024-12-09 13:51:50,618:INFO:Fitting Model
2024-12-09 13:51:50,660:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 13:51:50,660:INFO:create_model() successfully completed......................................
2024-12-09 13:51:50,747:INFO:Initializing create_model()
2024-12-09 13:51:50,747:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:50,747:INFO:Checking exceptions
2024-12-09 13:51:50,749:INFO:Importing libraries
2024-12-09 13:51:50,749:INFO:Copying training dataset
2024-12-09 13:51:50,752:INFO:Defining folds
2024-12-09 13:51:50,753:INFO:Declaring metric variables
2024-12-09 13:51:50,753:INFO:Importing untrained model
2024-12-09 13:51:50,753:INFO:Declaring custom model
2024-12-09 13:51:50,753:INFO:Naive Bayes Imported successfully
2024-12-09 13:51:50,754:INFO:Cross validation set to False
2024-12-09 13:51:50,754:INFO:Fitting Model
2024-12-09 13:51:50,794:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 13:51:50,794:INFO:create_model() successfully completed......................................
2024-12-09 13:51:50,882:INFO:Initializing create_model()
2024-12-09 13:51:50,882:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:50,882:INFO:Checking exceptions
2024-12-09 13:51:50,883:INFO:Importing libraries
2024-12-09 13:51:50,884:INFO:Copying training dataset
2024-12-09 13:51:50,887:INFO:Defining folds
2024-12-09 13:51:50,887:INFO:Declaring metric variables
2024-12-09 13:51:50,887:INFO:Importing untrained model
2024-12-09 13:51:50,887:INFO:Declaring custom model
2024-12-09 13:51:50,888:INFO:Decision Tree Classifier Imported successfully
2024-12-09 13:51:50,889:INFO:Cross validation set to False
2024-12-09 13:51:50,889:INFO:Fitting Model
2024-12-09 13:51:50,931:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 13:51:50,931:INFO:create_model() successfully completed......................................
2024-12-09 13:51:51,029:INFO:Initializing create_model()
2024-12-09 13:51:51,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:51,029:INFO:Checking exceptions
2024-12-09 13:51:51,031:INFO:Importing libraries
2024-12-09 13:51:51,031:INFO:Copying training dataset
2024-12-09 13:51:51,036:INFO:Defining folds
2024-12-09 13:51:51,037:INFO:Declaring metric variables
2024-12-09 13:51:51,037:INFO:Importing untrained model
2024-12-09 13:51:51,037:INFO:Declaring custom model
2024-12-09 13:51:51,037:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 13:51:51,038:INFO:Cross validation set to False
2024-12-09 13:51:51,038:INFO:Fitting Model
2024-12-09 13:51:51,089:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:51:51,090:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 13:51:51,090:INFO:create_model() successfully completed......................................
2024-12-09 13:51:51,183:INFO:Initializing create_model()
2024-12-09 13:51:51,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:51,184:INFO:Checking exceptions
2024-12-09 13:51:51,186:INFO:Importing libraries
2024-12-09 13:51:51,186:INFO:Copying training dataset
2024-12-09 13:51:51,189:INFO:Defining folds
2024-12-09 13:51:51,189:INFO:Declaring metric variables
2024-12-09 13:51:51,189:INFO:Importing untrained model
2024-12-09 13:51:51,189:INFO:Declaring custom model
2024-12-09 13:51:51,190:INFO:K Neighbors Classifier Imported successfully
2024-12-09 13:51:51,191:INFO:Cross validation set to False
2024-12-09 13:51:51,191:INFO:Fitting Model
2024-12-09 13:51:51,280:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 13:51:51,280:INFO:create_model() successfully completed......................................
2024-12-09 13:51:51,379:INFO:Initializing create_model()
2024-12-09 13:51:51,379:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:51,380:INFO:Checking exceptions
2024-12-09 13:51:51,382:INFO:Importing libraries
2024-12-09 13:51:51,382:INFO:Copying training dataset
2024-12-09 13:51:51,386:INFO:Defining folds
2024-12-09 13:51:51,386:INFO:Declaring metric variables
2024-12-09 13:51:51,386:INFO:Importing untrained model
2024-12-09 13:51:51,386:INFO:Declaring custom model
2024-12-09 13:51:51,387:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 13:51:51,388:INFO:Cross validation set to False
2024-12-09 13:51:51,388:INFO:Fitting Model
2024-12-09 13:51:51,431:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 13:51:51,432:INFO:create_model() successfully completed......................................
2024-12-09 13:51:51,516:INFO:Initializing create_model()
2024-12-09 13:51:51,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:51,517:INFO:Checking exceptions
2024-12-09 13:51:51,519:INFO:Importing libraries
2024-12-09 13:51:51,519:INFO:Copying training dataset
2024-12-09 13:51:51,522:INFO:Defining folds
2024-12-09 13:51:51,522:INFO:Declaring metric variables
2024-12-09 13:51:51,523:INFO:Importing untrained model
2024-12-09 13:51:51,523:INFO:Declaring custom model
2024-12-09 13:51:51,523:INFO:Dummy Classifier Imported successfully
2024-12-09 13:51:51,524:INFO:Cross validation set to False
2024-12-09 13:51:51,524:INFO:Fitting Model
2024-12-09 13:51:51,567:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-12-09 13:51:51,567:INFO:create_model() successfully completed......................................
2024-12-09 13:51:51,678:INFO:_master_model_container: 14
2024-12-09 13:51:51,679:INFO:_display_container: 2
2024-12-09 13:51:51,682:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')]
2024-12-09 13:51:51,682:INFO:compare_models() successfully completed......................................
2024-12-09 13:51:51,686:INFO:Initializing finalize_model()
2024-12-09 13:51:51,686:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')], fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-09 13:51:51,689:INFO:Finalizing [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')]
2024-12-09 13:51:51,697:INFO:Initializing create_model()
2024-12-09 13:51:51,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16887C70>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')], fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:51:51,697:INFO:Checking exceptions
2024-12-09 13:52:21,978:INFO:PyCaret ClassificationExperiment
2024-12-09 13:52:21,978:INFO:Logging name: clf-default-name
2024-12-09 13:52:21,978:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-09 13:52:21,978:INFO:version 3.2.0
2024-12-09 13:52:21,978:INFO:Initializing setup()
2024-12-09 13:52:21,978:INFO:self.USI: 6f4e
2024-12-09 13:52:21,979:INFO:self._variable_keys: {'fix_imbalance', 'log_plots_param', '_available_plots', 'X', 'seed', 'idx', 'gpu_param', '_ml_usecase', 'fold_generator', 'exp_name_log', 'y', 'is_multiclass', 'fold_shuffle_param', 'X_test', 'target_param', 'exp_id', 'logging_param', 'X_train', 'html_param', 'memory', 'fold_groups_param', 'y_train', 'n_jobs_param', 'data', 'gpu_n_jobs_param', 'USI', 'pipeline', 'y_test'}
2024-12-09 13:52:21,979:INFO:Checking environment
2024-12-09 13:52:21,980:INFO:python_version: 3.8.20
2024-12-09 13:52:21,980:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2024-12-09 13:52:21,980:INFO:machine: AMD64
2024-12-09 13:52:21,980:INFO:platform: Windows-10-10.0.19041-SP0
2024-12-09 13:52:21,986:INFO:Memory: svmem(total=17054896128, available=4496748544, percent=73.6, used=12558147584, free=4496748544)
2024-12-09 13:52:21,986:INFO:Physical Core: 6
2024-12-09 13:52:21,986:INFO:Logical Core: 6
2024-12-09 13:52:21,986:INFO:Checking libraries
2024-12-09 13:52:21,986:INFO:System:
2024-12-09 13:52:21,987:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2024-12-09 13:52:21,987:INFO:executable: c:\Users\EE715\anaconda3\envs\gym-env\python.exe
2024-12-09 13:52:21,987:INFO:   machine: Windows-10-10.0.19041-SP0
2024-12-09 13:52:21,987:INFO:PyCaret required dependencies:
2024-12-09 13:52:21,987:INFO:                 pip: 24.2
2024-12-09 13:52:21,987:INFO:          setuptools: 75.1.0
2024-12-09 13:52:21,987:INFO:             pycaret: 3.2.0
2024-12-09 13:52:21,987:INFO:             IPython: 8.12.3
2024-12-09 13:52:21,987:INFO:          ipywidgets: 8.1.5
2024-12-09 13:52:21,987:INFO:                tqdm: 4.67.1
2024-12-09 13:52:21,987:INFO:               numpy: 1.24.4
2024-12-09 13:52:21,987:INFO:              pandas: 1.5.3
2024-12-09 13:52:21,987:INFO:              jinja2: 3.1.4
2024-12-09 13:52:21,987:INFO:               scipy: 1.10.1
2024-12-09 13:52:21,987:INFO:              joblib: 1.2.0
2024-12-09 13:52:21,987:INFO:             sklearn: 1.2.2
2024-12-09 13:52:21,987:INFO:                pyod: 2.0.2
2024-12-09 13:52:21,987:INFO:            imblearn: 0.12.4
2024-12-09 13:52:21,987:INFO:   category_encoders: 2.6.4
2024-12-09 13:52:21,987:INFO:            lightgbm: 4.5.0
2024-12-09 13:52:21,988:INFO:               numba: 0.58.1
2024-12-09 13:52:21,988:INFO:            requests: 2.32.3
2024-12-09 13:52:21,988:INFO:          matplotlib: 3.6.0
2024-12-09 13:52:21,988:INFO:          scikitplot: 0.3.7
2024-12-09 13:52:21,988:INFO:         yellowbrick: 1.5
2024-12-09 13:52:21,988:INFO:              plotly: 5.24.1
2024-12-09 13:52:21,988:INFO:    plotly-resampler: Not installed
2024-12-09 13:52:21,988:INFO:             kaleido: 0.2.1
2024-12-09 13:52:21,988:INFO:           schemdraw: 0.15
2024-12-09 13:52:21,988:INFO:         statsmodels: 0.14.1
2024-12-09 13:52:21,988:INFO:              sktime: 0.21.1
2024-12-09 13:52:21,988:INFO:               tbats: 1.1.3
2024-12-09 13:52:21,988:INFO:            pmdarima: 2.0.4
2024-12-09 13:52:21,988:INFO:              psutil: 6.1.0
2024-12-09 13:52:21,988:INFO:          markupsafe: 2.1.5
2024-12-09 13:52:21,988:INFO:             pickle5: Not installed
2024-12-09 13:52:21,988:INFO:         cloudpickle: 3.1.0
2024-12-09 13:52:21,988:INFO:         deprecation: 2.1.0
2024-12-09 13:52:21,988:INFO:              xxhash: 3.5.0
2024-12-09 13:52:21,988:INFO:           wurlitzer: Not installed
2024-12-09 13:52:21,988:INFO:PyCaret optional dependencies:
2024-12-09 13:52:21,988:INFO:                shap: Not installed
2024-12-09 13:52:21,989:INFO:           interpret: Not installed
2024-12-09 13:52:21,989:INFO:                umap: Not installed
2024-12-09 13:52:21,989:INFO:     ydata_profiling: Not installed
2024-12-09 13:52:21,989:INFO:  explainerdashboard: Not installed
2024-12-09 13:52:21,989:INFO:             autoviz: Not installed
2024-12-09 13:52:21,989:INFO:           fairlearn: Not installed
2024-12-09 13:52:21,989:INFO:          deepchecks: Not installed
2024-12-09 13:52:21,989:INFO:             xgboost: Not installed
2024-12-09 13:52:21,989:INFO:            catboost: Not installed
2024-12-09 13:52:21,989:INFO:              kmodes: Not installed
2024-12-09 13:52:21,989:INFO:             mlxtend: Not installed
2024-12-09 13:52:21,989:INFO:       statsforecast: Not installed
2024-12-09 13:52:21,989:INFO:        tune_sklearn: Not installed
2024-12-09 13:52:21,989:INFO:                 ray: Not installed
2024-12-09 13:52:21,989:INFO:            hyperopt: Not installed
2024-12-09 13:52:21,989:INFO:              optuna: 4.1.0
2024-12-09 13:52:21,989:INFO:               skopt: Not installed
2024-12-09 13:52:21,989:INFO:              mlflow: Not installed
2024-12-09 13:52:21,989:INFO:              gradio: Not installed
2024-12-09 13:52:21,989:INFO:             fastapi: Not installed
2024-12-09 13:52:21,989:INFO:             uvicorn: Not installed
2024-12-09 13:52:21,989:INFO:              m2cgen: Not installed
2024-12-09 13:52:21,990:INFO:           evidently: Not installed
2024-12-09 13:52:21,990:INFO:               fugue: Not installed
2024-12-09 13:52:21,990:INFO:           streamlit: Not installed
2024-12-09 13:52:21,990:INFO:             prophet: Not installed
2024-12-09 13:52:21,990:INFO:None
2024-12-09 13:52:21,990:INFO:Set up data.
2024-12-09 13:52:22,002:INFO:Set up folding strategy.
2024-12-09 13:52:22,002:INFO:Set up train/test split.
2024-12-09 13:52:22,010:INFO:Set up index.
2024-12-09 13:52:22,010:INFO:Assigning column types.
2024-12-09 13:52:22,018:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-09 13:52:22,071:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 13:52:22,072:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:52:22,102:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:22,102:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:22,186:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 13:52:22,187:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:52:22,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:22,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:22,227:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-09 13:52:22,277:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:52:22,306:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:22,307:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:22,354:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:52:22,384:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:22,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:22,385:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-09 13:52:22,461:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:22,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:22,535:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:22,535:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:22,536:INFO:Preparing preprocessing pipeline...
2024-12-09 13:52:22,537:INFO:Set up simple imputation.
2024-12-09 13:52:22,539:INFO:Set up encoding of ordinal features.
2024-12-09 13:52:22,540:INFO:Set up encoding of categorical features.
2024-12-09 13:52:22,606:INFO:Finished creating preprocessing pipeline.
2024-12-09 13:52:22,624:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\EE715\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categ...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-12-09 13:52:22,624:INFO:Creating final display dataframe.
2024-12-09 13:52:22,872:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (623, 10)
6    Transformed test set shape         (268, 10)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              6f4e
2024-12-09 13:52:22,957:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:22,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:23,039:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:23,039:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:23,040:INFO:setup() successfully completed in 1.06s...............
2024-12-09 13:52:23,040:INFO:Initializing compare_models()
2024-12-09 13:52:23,040:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-12-09 13:52:23,040:INFO:Checking exceptions
2024-12-09 13:52:23,043:INFO:Preparing display monitor
2024-12-09 13:52:23,076:INFO:Initializing Logistic Regression
2024-12-09 13:52:23,077:INFO:Total runtime is 1.6681353251139323e-05 minutes
2024-12-09 13:52:23,082:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:23,084:INFO:Initializing create_model()
2024-12-09 13:52:23,085:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E354F1730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:23,085:INFO:Checking exceptions
2024-12-09 13:52:23,085:INFO:Importing libraries
2024-12-09 13:52:23,085:INFO:Copying training dataset
2024-12-09 13:52:23,089:INFO:Defining folds
2024-12-09 13:52:23,089:INFO:Declaring metric variables
2024-12-09 13:52:23,094:INFO:Importing untrained model
2024-12-09 13:52:23,101:INFO:Logistic Regression Imported successfully
2024-12-09 13:52:23,111:INFO:Starting cross validation
2024-12-09 13:52:23,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:23,613:INFO:Calculating mean and std
2024-12-09 13:52:23,613:INFO:Creating metrics dataframe
2024-12-09 13:52:23,619:INFO:Uploading results into container
2024-12-09 13:52:23,620:INFO:Uploading model into container now
2024-12-09 13:52:23,620:INFO:_master_model_container: 1
2024-12-09 13:52:23,620:INFO:_display_container: 2
2024-12-09 13:52:23,620:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 13:52:23,620:INFO:create_model() successfully completed......................................
2024-12-09 13:52:23,774:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:23,774:INFO:Creating metrics dataframe
2024-12-09 13:52:23,784:INFO:Initializing K Neighbors Classifier
2024-12-09 13:52:23,785:INFO:Total runtime is 0.011813020706176758 minutes
2024-12-09 13:52:23,788:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:23,789:INFO:Initializing create_model()
2024-12-09 13:52:23,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E354F1730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:23,789:INFO:Checking exceptions
2024-12-09 13:52:23,789:INFO:Importing libraries
2024-12-09 13:52:23,789:INFO:Copying training dataset
2024-12-09 13:52:23,793:INFO:Defining folds
2024-12-09 13:52:23,793:INFO:Declaring metric variables
2024-12-09 13:52:23,797:INFO:Importing untrained model
2024-12-09 13:52:23,802:INFO:K Neighbors Classifier Imported successfully
2024-12-09 13:52:23,810:INFO:Starting cross validation
2024-12-09 13:52:23,812:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:24,107:INFO:Calculating mean and std
2024-12-09 13:52:24,108:INFO:Creating metrics dataframe
2024-12-09 13:52:24,113:INFO:Uploading results into container
2024-12-09 13:52:24,113:INFO:Uploading model into container now
2024-12-09 13:52:24,115:INFO:_master_model_container: 2
2024-12-09 13:52:24,115:INFO:_display_container: 2
2024-12-09 13:52:24,116:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 13:52:24,116:INFO:create_model() successfully completed......................................
2024-12-09 13:52:24,239:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:24,240:INFO:Creating metrics dataframe
2024-12-09 13:52:24,250:INFO:Initializing Naive Bayes
2024-12-09 13:52:24,250:INFO:Total runtime is 0.01956706444422404 minutes
2024-12-09 13:52:24,254:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:24,254:INFO:Initializing create_model()
2024-12-09 13:52:24,254:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E354F1730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:24,254:INFO:Checking exceptions
2024-12-09 13:52:24,255:INFO:Importing libraries
2024-12-09 13:52:24,255:INFO:Copying training dataset
2024-12-09 13:52:24,259:INFO:Defining folds
2024-12-09 13:52:24,259:INFO:Declaring metric variables
2024-12-09 13:52:24,262:INFO:Importing untrained model
2024-12-09 13:52:24,271:INFO:Naive Bayes Imported successfully
2024-12-09 13:52:24,279:INFO:Starting cross validation
2024-12-09 13:52:24,282:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:24,636:INFO:Calculating mean and std
2024-12-09 13:52:24,637:INFO:Creating metrics dataframe
2024-12-09 13:52:24,640:INFO:Uploading results into container
2024-12-09 13:52:24,641:INFO:Uploading model into container now
2024-12-09 13:52:24,641:INFO:_master_model_container: 3
2024-12-09 13:52:24,641:INFO:_display_container: 2
2024-12-09 13:52:24,641:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 13:52:24,642:INFO:create_model() successfully completed......................................
2024-12-09 13:52:24,774:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:24,774:INFO:Creating metrics dataframe
2024-12-09 13:52:24,785:INFO:Initializing Decision Tree Classifier
2024-12-09 13:52:24,785:INFO:Total runtime is 0.028492828210194908 minutes
2024-12-09 13:52:24,788:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:24,789:INFO:Initializing create_model()
2024-12-09 13:52:24,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E354F1730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:24,789:INFO:Checking exceptions
2024-12-09 13:52:24,789:INFO:Importing libraries
2024-12-09 13:52:24,789:INFO:Copying training dataset
2024-12-09 13:52:24,793:INFO:Defining folds
2024-12-09 13:52:24,793:INFO:Declaring metric variables
2024-12-09 13:52:24,797:INFO:Importing untrained model
2024-12-09 13:52:24,810:INFO:Decision Tree Classifier Imported successfully
2024-12-09 13:52:24,854:INFO:Starting cross validation
2024-12-09 13:52:24,856:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:25,185:INFO:Calculating mean and std
2024-12-09 13:52:25,186:INFO:Creating metrics dataframe
2024-12-09 13:52:25,191:INFO:Uploading results into container
2024-12-09 13:52:25,192:INFO:Uploading model into container now
2024-12-09 13:52:25,192:INFO:_master_model_container: 4
2024-12-09 13:52:25,192:INFO:_display_container: 2
2024-12-09 13:52:25,193:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 13:52:25,193:INFO:create_model() successfully completed......................................
2024-12-09 13:52:25,320:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:25,320:INFO:Creating metrics dataframe
2024-12-09 13:52:25,331:INFO:Initializing SVM - Linear Kernel
2024-12-09 13:52:25,331:INFO:Total runtime is 0.03758716583251953 minutes
2024-12-09 13:52:25,337:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:25,337:INFO:Initializing create_model()
2024-12-09 13:52:25,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E354F1730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:25,337:INFO:Checking exceptions
2024-12-09 13:52:25,338:INFO:Importing libraries
2024-12-09 13:52:25,338:INFO:Copying training dataset
2024-12-09 13:52:25,342:INFO:Defining folds
2024-12-09 13:52:25,342:INFO:Declaring metric variables
2024-12-09 13:52:25,346:INFO:Importing untrained model
2024-12-09 13:52:25,363:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 13:52:25,377:INFO:Starting cross validation
2024-12-09 13:52:25,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:25,508:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:25,508:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:25,508:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:25,512:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:52:25,535:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:25,543:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:25,570:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:25,623:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:25,626:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:25,626:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:25,630:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:52:25,644:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:25,654:INFO:Calculating mean and std
2024-12-09 13:52:25,656:INFO:Creating metrics dataframe
2024-12-09 13:52:25,662:INFO:Uploading results into container
2024-12-09 13:52:25,664:INFO:Uploading model into container now
2024-12-09 13:52:25,664:INFO:_master_model_container: 5
2024-12-09 13:52:25,664:INFO:_display_container: 2
2024-12-09 13:52:25,665:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 13:52:25,666:INFO:create_model() successfully completed......................................
2024-12-09 13:52:25,815:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:25,816:INFO:Creating metrics dataframe
2024-12-09 13:52:25,827:INFO:Initializing Ridge Classifier
2024-12-09 13:52:25,827:INFO:Total runtime is 0.04586186408996582 minutes
2024-12-09 13:52:25,830:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:25,831:INFO:Initializing create_model()
2024-12-09 13:52:25,831:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E354F1730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:25,831:INFO:Checking exceptions
2024-12-09 13:52:25,831:INFO:Importing libraries
2024-12-09 13:52:25,831:INFO:Copying training dataset
2024-12-09 13:52:25,838:INFO:Defining folds
2024-12-09 13:52:25,838:INFO:Declaring metric variables
2024-12-09 13:52:25,842:INFO:Importing untrained model
2024-12-09 13:52:25,845:INFO:Ridge Classifier Imported successfully
2024-12-09 13:52:25,856:INFO:Starting cross validation
2024-12-09 13:52:25,858:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:25,989:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:25,989:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:25,994:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:26,008:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:26,061:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:26,076:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:26,105:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:26,112:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:26,115:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:26,127:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:26,136:INFO:Calculating mean and std
2024-12-09 13:52:26,137:INFO:Creating metrics dataframe
2024-12-09 13:52:26,141:INFO:Uploading results into container
2024-12-09 13:52:26,141:INFO:Uploading model into container now
2024-12-09 13:52:26,142:INFO:_master_model_container: 6
2024-12-09 13:52:26,142:INFO:_display_container: 2
2024-12-09 13:52:26,143:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 13:52:26,143:INFO:create_model() successfully completed......................................
2024-12-09 13:52:26,282:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:26,282:INFO:Creating metrics dataframe
2024-12-09 13:52:26,295:INFO:Initializing Random Forest Classifier
2024-12-09 13:52:26,295:INFO:Total runtime is 0.05365200440088908 minutes
2024-12-09 13:52:26,299:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:26,299:INFO:Initializing create_model()
2024-12-09 13:52:26,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E354F1730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:26,299:INFO:Checking exceptions
2024-12-09 13:52:26,300:INFO:Importing libraries
2024-12-09 13:52:26,301:INFO:Copying training dataset
2024-12-09 13:52:26,307:INFO:Defining folds
2024-12-09 13:52:26,309:INFO:Declaring metric variables
2024-12-09 13:52:26,314:INFO:Importing untrained model
2024-12-09 13:52:26,322:INFO:Random Forest Classifier Imported successfully
2024-12-09 13:52:26,330:INFO:Starting cross validation
2024-12-09 13:52:26,332:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:27,360:INFO:Calculating mean and std
2024-12-09 13:52:27,361:INFO:Creating metrics dataframe
2024-12-09 13:52:27,366:INFO:Uploading results into container
2024-12-09 13:52:27,367:INFO:Uploading model into container now
2024-12-09 13:52:27,367:INFO:_master_model_container: 7
2024-12-09 13:52:27,369:INFO:_display_container: 2
2024-12-09 13:52:27,370:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 13:52:27,370:INFO:create_model() successfully completed......................................
2024-12-09 13:52:27,497:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:27,498:INFO:Creating metrics dataframe
2024-12-09 13:52:27,510:INFO:Initializing Quadratic Discriminant Analysis
2024-12-09 13:52:27,510:INFO:Total runtime is 0.0739116112391154 minutes
2024-12-09 13:52:27,514:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:27,514:INFO:Initializing create_model()
2024-12-09 13:52:27,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E354F1730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:27,514:INFO:Checking exceptions
2024-12-09 13:52:27,514:INFO:Importing libraries
2024-12-09 13:52:27,515:INFO:Copying training dataset
2024-12-09 13:52:27,520:INFO:Defining folds
2024-12-09 13:52:27,520:INFO:Declaring metric variables
2024-12-09 13:52:27,527:INFO:Importing untrained model
2024-12-09 13:52:27,531:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 13:52:27,545:INFO:Starting cross validation
2024-12-09 13:52:27,546:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:27,633:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:52:27,644:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:52:27,657:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:52:27,661:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:52:27,670:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:52:27,675:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:52:27,779:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:52:27,786:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:52:27,787:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:52:27,798:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:52:27,847:INFO:Calculating mean and std
2024-12-09 13:52:27,848:INFO:Creating metrics dataframe
2024-12-09 13:52:27,853:INFO:Uploading results into container
2024-12-09 13:52:27,854:INFO:Uploading model into container now
2024-12-09 13:52:27,855:INFO:_master_model_container: 8
2024-12-09 13:52:27,857:INFO:_display_container: 2
2024-12-09 13:52:27,857:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 13:52:27,857:INFO:create_model() successfully completed......................................
2024-12-09 13:52:27,997:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:27,997:INFO:Creating metrics dataframe
2024-12-09 13:52:28,012:INFO:Initializing Ada Boost Classifier
2024-12-09 13:52:28,012:INFO:Total runtime is 0.08227870066960652 minutes
2024-12-09 13:52:28,015:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:28,015:INFO:Initializing create_model()
2024-12-09 13:52:28,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E354F1730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:28,017:INFO:Checking exceptions
2024-12-09 13:52:28,017:INFO:Importing libraries
2024-12-09 13:52:28,017:INFO:Copying training dataset
2024-12-09 13:52:28,023:INFO:Defining folds
2024-12-09 13:52:28,023:INFO:Declaring metric variables
2024-12-09 13:52:28,029:INFO:Importing untrained model
2024-12-09 13:52:28,035:INFO:Ada Boost Classifier Imported successfully
2024-12-09 13:52:28,049:INFO:Starting cross validation
2024-12-09 13:52:28,051:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:28,819:INFO:Calculating mean and std
2024-12-09 13:52:28,821:INFO:Creating metrics dataframe
2024-12-09 13:52:28,824:INFO:Uploading results into container
2024-12-09 13:52:28,825:INFO:Uploading model into container now
2024-12-09 13:52:28,826:INFO:_master_model_container: 9
2024-12-09 13:52:28,826:INFO:_display_container: 2
2024-12-09 13:52:28,827:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 13:52:28,827:INFO:create_model() successfully completed......................................
2024-12-09 13:52:28,940:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:28,941:INFO:Creating metrics dataframe
2024-12-09 13:52:28,959:INFO:Initializing Gradient Boosting Classifier
2024-12-09 13:52:28,959:INFO:Total runtime is 0.09805548588434854 minutes
2024-12-09 13:52:28,963:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:28,963:INFO:Initializing create_model()
2024-12-09 13:52:28,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E354F1730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:28,964:INFO:Checking exceptions
2024-12-09 13:52:28,964:INFO:Importing libraries
2024-12-09 13:52:28,964:INFO:Copying training dataset
2024-12-09 13:52:28,971:INFO:Defining folds
2024-12-09 13:52:28,971:INFO:Declaring metric variables
2024-12-09 13:52:28,975:INFO:Importing untrained model
2024-12-09 13:52:28,982:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 13:52:29,002:INFO:Starting cross validation
2024-12-09 13:52:29,006:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:29,804:INFO:Calculating mean and std
2024-12-09 13:52:29,805:INFO:Creating metrics dataframe
2024-12-09 13:52:29,808:INFO:Uploading results into container
2024-12-09 13:52:29,809:INFO:Uploading model into container now
2024-12-09 13:52:29,809:INFO:_master_model_container: 10
2024-12-09 13:52:29,809:INFO:_display_container: 2
2024-12-09 13:52:29,810:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 13:52:29,810:INFO:create_model() successfully completed......................................
2024-12-09 13:52:29,911:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:29,911:INFO:Creating metrics dataframe
2024-12-09 13:52:29,923:INFO:Initializing Linear Discriminant Analysis
2024-12-09 13:52:29,923:INFO:Total runtime is 0.11411688327789304 minutes
2024-12-09 13:52:29,927:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:29,928:INFO:Initializing create_model()
2024-12-09 13:52:29,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E354F1730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:29,928:INFO:Checking exceptions
2024-12-09 13:52:29,928:INFO:Importing libraries
2024-12-09 13:52:29,928:INFO:Copying training dataset
2024-12-09 13:52:29,932:INFO:Defining folds
2024-12-09 13:52:29,933:INFO:Declaring metric variables
2024-12-09 13:52:29,937:INFO:Importing untrained model
2024-12-09 13:52:29,942:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 13:52:29,949:INFO:Starting cross validation
2024-12-09 13:52:29,951:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:30,214:INFO:Calculating mean and std
2024-12-09 13:52:30,215:INFO:Creating metrics dataframe
2024-12-09 13:52:30,219:INFO:Uploading results into container
2024-12-09 13:52:30,219:INFO:Uploading model into container now
2024-12-09 13:52:30,221:INFO:_master_model_container: 11
2024-12-09 13:52:30,221:INFO:_display_container: 2
2024-12-09 13:52:30,222:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 13:52:30,222:INFO:create_model() successfully completed......................................
2024-12-09 13:52:30,334:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:30,334:INFO:Creating metrics dataframe
2024-12-09 13:52:30,348:INFO:Initializing Extra Trees Classifier
2024-12-09 13:52:30,348:INFO:Total runtime is 0.12119664748509723 minutes
2024-12-09 13:52:30,352:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:30,353:INFO:Initializing create_model()
2024-12-09 13:52:30,353:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E354F1730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:30,353:INFO:Checking exceptions
2024-12-09 13:52:30,353:INFO:Importing libraries
2024-12-09 13:52:30,353:INFO:Copying training dataset
2024-12-09 13:52:30,359:INFO:Defining folds
2024-12-09 13:52:30,360:INFO:Declaring metric variables
2024-12-09 13:52:30,364:INFO:Importing untrained model
2024-12-09 13:52:30,377:INFO:Extra Trees Classifier Imported successfully
2024-12-09 13:52:30,389:INFO:Starting cross validation
2024-12-09 13:52:30,391:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:31,139:INFO:Calculating mean and std
2024-12-09 13:52:31,140:INFO:Creating metrics dataframe
2024-12-09 13:52:31,143:INFO:Uploading results into container
2024-12-09 13:52:31,144:INFO:Uploading model into container now
2024-12-09 13:52:31,144:INFO:_master_model_container: 12
2024-12-09 13:52:31,144:INFO:_display_container: 2
2024-12-09 13:52:31,145:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 13:52:31,145:INFO:create_model() successfully completed......................................
2024-12-09 13:52:31,244:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:31,244:INFO:Creating metrics dataframe
2024-12-09 13:52:31,256:INFO:Initializing Light Gradient Boosting Machine
2024-12-09 13:52:31,256:INFO:Total runtime is 0.13633596499760944 minutes
2024-12-09 13:52:31,259:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:31,259:INFO:Initializing create_model()
2024-12-09 13:52:31,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E354F1730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:31,260:INFO:Checking exceptions
2024-12-09 13:52:31,260:INFO:Importing libraries
2024-12-09 13:52:31,260:INFO:Copying training dataset
2024-12-09 13:52:31,264:INFO:Defining folds
2024-12-09 13:52:31,264:INFO:Declaring metric variables
2024-12-09 13:52:31,268:INFO:Importing untrained model
2024-12-09 13:52:31,273:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:52:31,280:INFO:Starting cross validation
2024-12-09 13:52:31,281:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:32,023:INFO:Calculating mean and std
2024-12-09 13:52:32,024:INFO:Creating metrics dataframe
2024-12-09 13:52:32,028:INFO:Uploading results into container
2024-12-09 13:52:32,029:INFO:Uploading model into container now
2024-12-09 13:52:32,029:INFO:_master_model_container: 13
2024-12-09 13:52:32,029:INFO:_display_container: 2
2024-12-09 13:52:32,030:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:52:32,031:INFO:create_model() successfully completed......................................
2024-12-09 13:52:32,139:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:32,140:INFO:Creating metrics dataframe
2024-12-09 13:52:32,153:INFO:Initializing Dummy Classifier
2024-12-09 13:52:32,153:INFO:Total runtime is 0.1512867252031962 minutes
2024-12-09 13:52:32,157:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:32,157:INFO:Initializing create_model()
2024-12-09 13:52:32,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E354F1730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:32,157:INFO:Checking exceptions
2024-12-09 13:52:32,157:INFO:Importing libraries
2024-12-09 13:52:32,157:INFO:Copying training dataset
2024-12-09 13:52:32,163:INFO:Defining folds
2024-12-09 13:52:32,163:INFO:Declaring metric variables
2024-12-09 13:52:32,166:INFO:Importing untrained model
2024-12-09 13:52:32,171:INFO:Dummy Classifier Imported successfully
2024-12-09 13:52:32,180:INFO:Starting cross validation
2024-12-09 13:52:32,182:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:32,297:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:52:32,297:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:52:32,300:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:52:32,300:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:52:32,302:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:52:32,317:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:52:32,381:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:52:32,383:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:52:32,385:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:52:32,385:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:52:32,390:INFO:Calculating mean and std
2024-12-09 13:52:32,392:INFO:Creating metrics dataframe
2024-12-09 13:52:32,395:INFO:Uploading results into container
2024-12-09 13:52:32,396:INFO:Uploading model into container now
2024-12-09 13:52:32,396:INFO:_master_model_container: 14
2024-12-09 13:52:32,396:INFO:_display_container: 2
2024-12-09 13:52:32,397:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-12-09 13:52:32,397:INFO:create_model() successfully completed......................................
2024-12-09 13:52:32,496:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:32,497:INFO:Creating metrics dataframe
2024-12-09 13:52:32,518:INFO:Initializing create_model()
2024-12-09 13:52:32,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:32,518:INFO:Checking exceptions
2024-12-09 13:52:32,520:INFO:Importing libraries
2024-12-09 13:52:32,520:INFO:Copying training dataset
2024-12-09 13:52:32,524:INFO:Defining folds
2024-12-09 13:52:32,524:INFO:Declaring metric variables
2024-12-09 13:52:32,524:INFO:Importing untrained model
2024-12-09 13:52:32,524:INFO:Declaring custom model
2024-12-09 13:52:32,525:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:52:32,528:INFO:Cross validation set to False
2024-12-09 13:52:32,528:INFO:Fitting Model
2024-12-09 13:52:32,574:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 13:52:32,575:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000214 seconds.
2024-12-09 13:52:32,575:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 13:52:32,575:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 13:52:32,575:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 13:52:32,575:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 13:52:32,575:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 13:52:32,575:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 13:52:32,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,610:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:52:32,610:INFO:create_model() successfully completed......................................
2024-12-09 13:52:32,742:INFO:_master_model_container: 14
2024-12-09 13:52:32,742:INFO:_display_container: 2
2024-12-09 13:52:32,743:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:52:32,743:INFO:compare_models() successfully completed......................................
2024-12-09 13:52:32,743:INFO:Initializing finalize_model()
2024-12-09 13:52:32,743:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-09 13:52:32,744:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:52:32,747:INFO:Initializing create_model()
2024-12-09 13:52:32,747:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:32,747:INFO:Checking exceptions
2024-12-09 13:52:32,748:INFO:Importing libraries
2024-12-09 13:52:32,748:INFO:Copying training dataset
2024-12-09 13:52:32,749:INFO:Defining folds
2024-12-09 13:52:32,749:INFO:Declaring metric variables
2024-12-09 13:52:32,749:INFO:Importing untrained model
2024-12-09 13:52:32,749:INFO:Declaring custom model
2024-12-09 13:52:32,750:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:52:32,751:INFO:Cross validation set to False
2024-12-09 13:52:32,751:INFO:Fitting Model
2024-12-09 13:52:32,806:INFO:[LightGBM] [Info] Number of positive: 342, number of negative: 549
2024-12-09 13:52:32,806:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000220 seconds.
2024-12-09 13:52:32,807:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 13:52:32,807:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 13:52:32,807:INFO:[LightGBM] [Info] Total Bins 224
2024-12-09 13:52:32,807:INFO:[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 9
2024-12-09 13:52:32,807:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288
2024-12-09 13:52:32,807:INFO:[LightGBM] [Info] Start training from score -0.473288
2024-12-09 13:52:32,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:52:32,859:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-09 13:52:32,859:INFO:create_model() successfully completed......................................
2024-12-09 13:52:33,007:INFO:_master_model_container: 14
2024-12-09 13:52:33,007:INFO:_display_container: 2
2024-12-09 13:52:33,026:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-09 13:52:33,026:INFO:finalize_model() successfully completed......................................
2024-12-09 13:52:33,154:INFO:Initializing predict_model()
2024-12-09 13:52:33,154:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899070>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025E353EEC10>)
2024-12-09 13:52:33,154:INFO:Checking exceptions
2024-12-09 13:52:33,154:INFO:Preloading libraries
2024-12-09 13:52:33,155:INFO:Set up data.
2024-12-09 13:52:33,160:INFO:Set up index.
2024-12-09 13:52:55,216:INFO:PyCaret ClassificationExperiment
2024-12-09 13:52:55,216:INFO:Logging name: clf-default-name
2024-12-09 13:52:55,216:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-09 13:52:55,216:INFO:version 3.2.0
2024-12-09 13:52:55,216:INFO:Initializing setup()
2024-12-09 13:52:55,216:INFO:self.USI: 730c
2024-12-09 13:52:55,216:INFO:self._variable_keys: {'fix_imbalance', 'log_plots_param', '_available_plots', 'X', 'seed', 'idx', 'gpu_param', '_ml_usecase', 'fold_generator', 'exp_name_log', 'y', 'is_multiclass', 'fold_shuffle_param', 'X_test', 'target_param', 'exp_id', 'logging_param', 'X_train', 'html_param', 'memory', 'fold_groups_param', 'y_train', 'n_jobs_param', 'data', 'gpu_n_jobs_param', 'USI', 'pipeline', 'y_test'}
2024-12-09 13:52:55,216:INFO:Checking environment
2024-12-09 13:52:55,216:INFO:python_version: 3.8.20
2024-12-09 13:52:55,216:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2024-12-09 13:52:55,216:INFO:machine: AMD64
2024-12-09 13:52:55,216:INFO:platform: Windows-10-10.0.19041-SP0
2024-12-09 13:52:55,222:INFO:Memory: svmem(total=17054896128, available=4506636288, percent=73.6, used=12548259840, free=4506636288)
2024-12-09 13:52:55,222:INFO:Physical Core: 6
2024-12-09 13:52:55,222:INFO:Logical Core: 6
2024-12-09 13:52:55,222:INFO:Checking libraries
2024-12-09 13:52:55,222:INFO:System:
2024-12-09 13:52:55,222:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2024-12-09 13:52:55,222:INFO:executable: c:\Users\EE715\anaconda3\envs\gym-env\python.exe
2024-12-09 13:52:55,222:INFO:   machine: Windows-10-10.0.19041-SP0
2024-12-09 13:52:55,222:INFO:PyCaret required dependencies:
2024-12-09 13:52:55,223:INFO:                 pip: 24.2
2024-12-09 13:52:55,223:INFO:          setuptools: 75.1.0
2024-12-09 13:52:55,223:INFO:             pycaret: 3.2.0
2024-12-09 13:52:55,223:INFO:             IPython: 8.12.3
2024-12-09 13:52:55,223:INFO:          ipywidgets: 8.1.5
2024-12-09 13:52:55,223:INFO:                tqdm: 4.67.1
2024-12-09 13:52:55,223:INFO:               numpy: 1.24.4
2024-12-09 13:52:55,223:INFO:              pandas: 1.5.3
2024-12-09 13:52:55,223:INFO:              jinja2: 3.1.4
2024-12-09 13:52:55,223:INFO:               scipy: 1.10.1
2024-12-09 13:52:55,223:INFO:              joblib: 1.2.0
2024-12-09 13:52:55,223:INFO:             sklearn: 1.2.2
2024-12-09 13:52:55,223:INFO:                pyod: 2.0.2
2024-12-09 13:52:55,223:INFO:            imblearn: 0.12.4
2024-12-09 13:52:55,223:INFO:   category_encoders: 2.6.4
2024-12-09 13:52:55,223:INFO:            lightgbm: 4.5.0
2024-12-09 13:52:55,223:INFO:               numba: 0.58.1
2024-12-09 13:52:55,223:INFO:            requests: 2.32.3
2024-12-09 13:52:55,223:INFO:          matplotlib: 3.6.0
2024-12-09 13:52:55,223:INFO:          scikitplot: 0.3.7
2024-12-09 13:52:55,223:INFO:         yellowbrick: 1.5
2024-12-09 13:52:55,223:INFO:              plotly: 5.24.1
2024-12-09 13:52:55,223:INFO:    plotly-resampler: Not installed
2024-12-09 13:52:55,224:INFO:             kaleido: 0.2.1
2024-12-09 13:52:55,224:INFO:           schemdraw: 0.15
2024-12-09 13:52:55,224:INFO:         statsmodels: 0.14.1
2024-12-09 13:52:55,224:INFO:              sktime: 0.21.1
2024-12-09 13:52:55,224:INFO:               tbats: 1.1.3
2024-12-09 13:52:55,224:INFO:            pmdarima: 2.0.4
2024-12-09 13:52:55,224:INFO:              psutil: 6.1.0
2024-12-09 13:52:55,224:INFO:          markupsafe: 2.1.5
2024-12-09 13:52:55,224:INFO:             pickle5: Not installed
2024-12-09 13:52:55,224:INFO:         cloudpickle: 3.1.0
2024-12-09 13:52:55,224:INFO:         deprecation: 2.1.0
2024-12-09 13:52:55,224:INFO:              xxhash: 3.5.0
2024-12-09 13:52:55,224:INFO:           wurlitzer: Not installed
2024-12-09 13:52:55,224:INFO:PyCaret optional dependencies:
2024-12-09 13:52:55,224:INFO:                shap: Not installed
2024-12-09 13:52:55,224:INFO:           interpret: Not installed
2024-12-09 13:52:55,224:INFO:                umap: Not installed
2024-12-09 13:52:55,224:INFO:     ydata_profiling: Not installed
2024-12-09 13:52:55,224:INFO:  explainerdashboard: Not installed
2024-12-09 13:52:55,224:INFO:             autoviz: Not installed
2024-12-09 13:52:55,224:INFO:           fairlearn: Not installed
2024-12-09 13:52:55,224:INFO:          deepchecks: Not installed
2024-12-09 13:52:55,224:INFO:             xgboost: Not installed
2024-12-09 13:52:55,224:INFO:            catboost: Not installed
2024-12-09 13:52:55,225:INFO:              kmodes: Not installed
2024-12-09 13:52:55,225:INFO:             mlxtend: Not installed
2024-12-09 13:52:55,225:INFO:       statsforecast: Not installed
2024-12-09 13:52:55,225:INFO:        tune_sklearn: Not installed
2024-12-09 13:52:55,225:INFO:                 ray: Not installed
2024-12-09 13:52:55,225:INFO:            hyperopt: Not installed
2024-12-09 13:52:55,225:INFO:              optuna: 4.1.0
2024-12-09 13:52:55,225:INFO:               skopt: Not installed
2024-12-09 13:52:55,225:INFO:              mlflow: Not installed
2024-12-09 13:52:55,225:INFO:              gradio: Not installed
2024-12-09 13:52:55,225:INFO:             fastapi: Not installed
2024-12-09 13:52:55,225:INFO:             uvicorn: Not installed
2024-12-09 13:52:55,225:INFO:              m2cgen: Not installed
2024-12-09 13:52:55,226:INFO:           evidently: Not installed
2024-12-09 13:52:55,226:INFO:               fugue: Not installed
2024-12-09 13:52:55,226:INFO:           streamlit: Not installed
2024-12-09 13:52:55,226:INFO:             prophet: Not installed
2024-12-09 13:52:55,226:INFO:None
2024-12-09 13:52:55,226:INFO:Set up data.
2024-12-09 13:52:55,233:INFO:Set up folding strategy.
2024-12-09 13:52:55,234:INFO:Set up train/test split.
2024-12-09 13:52:55,240:INFO:Set up index.
2024-12-09 13:52:55,240:INFO:Assigning column types.
2024-12-09 13:52:55,244:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-09 13:52:55,302:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 13:52:55,303:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:52:55,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:55,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:55,388:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 13:52:55,389:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:52:55,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:55,425:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:55,426:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-09 13:52:55,482:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:52:55,515:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:55,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:55,565:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:52:55,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:55,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:55,634:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-09 13:52:55,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:55,709:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:55,800:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:55,800:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:55,801:INFO:Preparing preprocessing pipeline...
2024-12-09 13:52:55,802:INFO:Set up simple imputation.
2024-12-09 13:52:55,805:INFO:Set up encoding of ordinal features.
2024-12-09 13:52:55,807:INFO:Set up encoding of categorical features.
2024-12-09 13:52:55,884:INFO:Finished creating preprocessing pipeline.
2024-12-09 13:52:55,902:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\EE715\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categ...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-12-09 13:52:55,902:INFO:Creating final display dataframe.
2024-12-09 13:52:56,121:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (623, 10)
6    Transformed test set shape         (268, 10)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              730c
2024-12-09 13:52:56,209:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:56,209:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:56,294:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:56,294:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:52:56,295:INFO:setup() successfully completed in 1.08s...............
2024-12-09 13:52:56,297:INFO:Initializing compare_models()
2024-12-09 13:52:56,297:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['dummy'])
2024-12-09 13:52:56,297:INFO:Checking exceptions
2024-12-09 13:52:56,301:INFO:Preparing display monitor
2024-12-09 13:52:56,335:INFO:Initializing Logistic Regression
2024-12-09 13:52:56,335:INFO:Total runtime is 0.0 minutes
2024-12-09 13:52:56,344:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:56,344:INFO:Initializing create_model()
2024-12-09 13:52:56,344:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E342015B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:56,345:INFO:Checking exceptions
2024-12-09 13:52:56,345:INFO:Importing libraries
2024-12-09 13:52:56,345:INFO:Copying training dataset
2024-12-09 13:52:56,354:INFO:Defining folds
2024-12-09 13:52:56,355:INFO:Declaring metric variables
2024-12-09 13:52:56,360:INFO:Importing untrained model
2024-12-09 13:52:56,368:INFO:Logistic Regression Imported successfully
2024-12-09 13:52:56,424:INFO:Starting cross validation
2024-12-09 13:52:56,426:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:56,805:INFO:Calculating mean and std
2024-12-09 13:52:56,805:INFO:Creating metrics dataframe
2024-12-09 13:52:56,809:INFO:Uploading results into container
2024-12-09 13:52:56,809:INFO:Uploading model into container now
2024-12-09 13:52:56,809:INFO:_master_model_container: 1
2024-12-09 13:52:56,809:INFO:_display_container: 2
2024-12-09 13:52:56,810:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 13:52:56,810:INFO:create_model() successfully completed......................................
2024-12-09 13:52:56,937:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:56,937:INFO:Creating metrics dataframe
2024-12-09 13:52:56,948:INFO:Initializing K Neighbors Classifier
2024-12-09 13:52:56,948:INFO:Total runtime is 0.010204935073852539 minutes
2024-12-09 13:52:56,952:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:56,953:INFO:Initializing create_model()
2024-12-09 13:52:56,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E342015B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:56,953:INFO:Checking exceptions
2024-12-09 13:52:56,953:INFO:Importing libraries
2024-12-09 13:52:56,953:INFO:Copying training dataset
2024-12-09 13:52:56,961:INFO:Defining folds
2024-12-09 13:52:56,961:INFO:Declaring metric variables
2024-12-09 13:52:56,966:INFO:Importing untrained model
2024-12-09 13:52:56,970:INFO:K Neighbors Classifier Imported successfully
2024-12-09 13:52:56,985:INFO:Starting cross validation
2024-12-09 13:52:56,987:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:57,301:INFO:Calculating mean and std
2024-12-09 13:52:57,301:INFO:Creating metrics dataframe
2024-12-09 13:52:57,304:INFO:Uploading results into container
2024-12-09 13:52:57,305:INFO:Uploading model into container now
2024-12-09 13:52:57,305:INFO:_master_model_container: 2
2024-12-09 13:52:57,305:INFO:_display_container: 2
2024-12-09 13:52:57,305:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 13:52:57,305:INFO:create_model() successfully completed......................................
2024-12-09 13:52:57,405:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:57,406:INFO:Creating metrics dataframe
2024-12-09 13:52:57,416:INFO:Initializing Naive Bayes
2024-12-09 13:52:57,416:INFO:Total runtime is 0.018018949031829833 minutes
2024-12-09 13:52:57,420:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:57,421:INFO:Initializing create_model()
2024-12-09 13:52:57,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E342015B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:57,421:INFO:Checking exceptions
2024-12-09 13:52:57,421:INFO:Importing libraries
2024-12-09 13:52:57,421:INFO:Copying training dataset
2024-12-09 13:52:57,427:INFO:Defining folds
2024-12-09 13:52:57,427:INFO:Declaring metric variables
2024-12-09 13:52:57,431:INFO:Importing untrained model
2024-12-09 13:52:57,438:INFO:Naive Bayes Imported successfully
2024-12-09 13:52:57,446:INFO:Starting cross validation
2024-12-09 13:52:57,447:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:57,716:INFO:Calculating mean and std
2024-12-09 13:52:57,718:INFO:Creating metrics dataframe
2024-12-09 13:52:57,722:INFO:Uploading results into container
2024-12-09 13:52:57,723:INFO:Uploading model into container now
2024-12-09 13:52:57,723:INFO:_master_model_container: 3
2024-12-09 13:52:57,723:INFO:_display_container: 2
2024-12-09 13:52:57,724:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 13:52:57,724:INFO:create_model() successfully completed......................................
2024-12-09 13:52:57,829:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:57,829:INFO:Creating metrics dataframe
2024-12-09 13:52:57,838:INFO:Initializing Decision Tree Classifier
2024-12-09 13:52:57,839:INFO:Total runtime is 0.025051458676656087 minutes
2024-12-09 13:52:57,842:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:57,842:INFO:Initializing create_model()
2024-12-09 13:52:57,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E342015B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:57,842:INFO:Checking exceptions
2024-12-09 13:52:57,843:INFO:Importing libraries
2024-12-09 13:52:57,843:INFO:Copying training dataset
2024-12-09 13:52:57,846:INFO:Defining folds
2024-12-09 13:52:57,847:INFO:Declaring metric variables
2024-12-09 13:52:57,851:INFO:Importing untrained model
2024-12-09 13:52:57,856:INFO:Decision Tree Classifier Imported successfully
2024-12-09 13:52:57,863:INFO:Starting cross validation
2024-12-09 13:52:57,865:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:58,084:INFO:Calculating mean and std
2024-12-09 13:52:58,085:INFO:Creating metrics dataframe
2024-12-09 13:52:58,088:INFO:Uploading results into container
2024-12-09 13:52:58,089:INFO:Uploading model into container now
2024-12-09 13:52:58,089:INFO:_master_model_container: 4
2024-12-09 13:52:58,089:INFO:_display_container: 2
2024-12-09 13:52:58,090:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 13:52:58,090:INFO:create_model() successfully completed......................................
2024-12-09 13:52:58,210:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:58,210:INFO:Creating metrics dataframe
2024-12-09 13:52:58,223:INFO:Initializing SVM - Linear Kernel
2024-12-09 13:52:58,223:INFO:Total runtime is 0.03145577907562256 minutes
2024-12-09 13:52:58,226:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:58,226:INFO:Initializing create_model()
2024-12-09 13:52:58,227:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E342015B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:58,227:INFO:Checking exceptions
2024-12-09 13:52:58,227:INFO:Importing libraries
2024-12-09 13:52:58,227:INFO:Copying training dataset
2024-12-09 13:52:58,232:INFO:Defining folds
2024-12-09 13:52:58,233:INFO:Declaring metric variables
2024-12-09 13:52:58,238:INFO:Importing untrained model
2024-12-09 13:52:58,241:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 13:52:58,251:INFO:Starting cross validation
2024-12-09 13:52:58,253:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:58,384:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:58,388:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:58,393:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:52:58,397:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:58,405:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:58,444:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:58,491:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:58,504:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:58,511:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:58,513:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:52:58,514:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:52:58,522:INFO:Calculating mean and std
2024-12-09 13:52:58,524:INFO:Creating metrics dataframe
2024-12-09 13:52:58,527:INFO:Uploading results into container
2024-12-09 13:52:58,528:INFO:Uploading model into container now
2024-12-09 13:52:58,528:INFO:_master_model_container: 5
2024-12-09 13:52:58,528:INFO:_display_container: 2
2024-12-09 13:52:58,529:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 13:52:58,529:INFO:create_model() successfully completed......................................
2024-12-09 13:52:58,645:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:58,645:INFO:Creating metrics dataframe
2024-12-09 13:52:58,656:INFO:Initializing Ridge Classifier
2024-12-09 13:52:58,657:INFO:Total runtime is 0.038700505097707116 minutes
2024-12-09 13:52:58,661:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:58,662:INFO:Initializing create_model()
2024-12-09 13:52:58,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E342015B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:58,662:INFO:Checking exceptions
2024-12-09 13:52:58,662:INFO:Importing libraries
2024-12-09 13:52:58,662:INFO:Copying training dataset
2024-12-09 13:52:58,669:INFO:Defining folds
2024-12-09 13:52:58,669:INFO:Declaring metric variables
2024-12-09 13:52:58,674:INFO:Importing untrained model
2024-12-09 13:52:58,679:INFO:Ridge Classifier Imported successfully
2024-12-09 13:52:58,692:INFO:Starting cross validation
2024-12-09 13:52:58,694:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:52:58,829:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:58,832:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:58,859:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:58,868:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:58,881:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:58,897:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:58,940:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:58,940:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:58,996:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:52:59,006:INFO:Calculating mean and std
2024-12-09 13:52:59,007:INFO:Creating metrics dataframe
2024-12-09 13:52:59,010:INFO:Uploading results into container
2024-12-09 13:52:59,011:INFO:Uploading model into container now
2024-12-09 13:52:59,012:INFO:_master_model_container: 6
2024-12-09 13:52:59,012:INFO:_display_container: 2
2024-12-09 13:52:59,012:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 13:52:59,012:INFO:create_model() successfully completed......................................
2024-12-09 13:52:59,119:INFO:SubProcess create_model() end ==================================
2024-12-09 13:52:59,119:INFO:Creating metrics dataframe
2024-12-09 13:52:59,129:INFO:Initializing Random Forest Classifier
2024-12-09 13:52:59,130:INFO:Total runtime is 0.046560494105021166 minutes
2024-12-09 13:52:59,133:INFO:SubProcess create_model() called ==================================
2024-12-09 13:52:59,133:INFO:Initializing create_model()
2024-12-09 13:52:59,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E342015B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:52:59,133:INFO:Checking exceptions
2024-12-09 13:52:59,133:INFO:Importing libraries
2024-12-09 13:52:59,134:INFO:Copying training dataset
2024-12-09 13:52:59,138:INFO:Defining folds
2024-12-09 13:52:59,138:INFO:Declaring metric variables
2024-12-09 13:52:59,143:INFO:Importing untrained model
2024-12-09 13:52:59,147:INFO:Random Forest Classifier Imported successfully
2024-12-09 13:52:59,156:INFO:Starting cross validation
2024-12-09 13:52:59,157:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:53:00,126:INFO:Calculating mean and std
2024-12-09 13:53:00,127:INFO:Creating metrics dataframe
2024-12-09 13:53:00,131:INFO:Uploading results into container
2024-12-09 13:53:00,131:INFO:Uploading model into container now
2024-12-09 13:53:00,132:INFO:_master_model_container: 7
2024-12-09 13:53:00,132:INFO:_display_container: 2
2024-12-09 13:53:00,132:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 13:53:00,133:INFO:create_model() successfully completed......................................
2024-12-09 13:53:00,284:INFO:SubProcess create_model() end ==================================
2024-12-09 13:53:00,284:INFO:Creating metrics dataframe
2024-12-09 13:53:00,297:INFO:Initializing Quadratic Discriminant Analysis
2024-12-09 13:53:00,298:INFO:Total runtime is 0.06603881518046062 minutes
2024-12-09 13:53:00,302:INFO:SubProcess create_model() called ==================================
2024-12-09 13:53:00,303:INFO:Initializing create_model()
2024-12-09 13:53:00,303:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E342015B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:00,304:INFO:Checking exceptions
2024-12-09 13:53:00,304:INFO:Importing libraries
2024-12-09 13:53:00,304:INFO:Copying training dataset
2024-12-09 13:53:00,308:INFO:Defining folds
2024-12-09 13:53:00,309:INFO:Declaring metric variables
2024-12-09 13:53:00,318:INFO:Importing untrained model
2024-12-09 13:53:00,327:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 13:53:00,336:INFO:Starting cross validation
2024-12-09 13:53:00,338:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:53:00,413:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:53:00,415:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:53:00,420:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:53:00,422:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:53:00,425:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:53:00,429:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:53:00,519:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:53:00,527:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:53:00,527:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:53:00,529:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:53:00,566:INFO:Calculating mean and std
2024-12-09 13:53:00,567:INFO:Creating metrics dataframe
2024-12-09 13:53:00,570:INFO:Uploading results into container
2024-12-09 13:53:00,571:INFO:Uploading model into container now
2024-12-09 13:53:00,571:INFO:_master_model_container: 8
2024-12-09 13:53:00,571:INFO:_display_container: 2
2024-12-09 13:53:00,572:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 13:53:00,572:INFO:create_model() successfully completed......................................
2024-12-09 13:53:00,678:INFO:SubProcess create_model() end ==================================
2024-12-09 13:53:00,678:INFO:Creating metrics dataframe
2024-12-09 13:53:00,690:INFO:Initializing Ada Boost Classifier
2024-12-09 13:53:00,690:INFO:Total runtime is 0.0725852409998576 minutes
2024-12-09 13:53:00,694:INFO:SubProcess create_model() called ==================================
2024-12-09 13:53:00,694:INFO:Initializing create_model()
2024-12-09 13:53:00,694:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E342015B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:00,694:INFO:Checking exceptions
2024-12-09 13:53:00,694:INFO:Importing libraries
2024-12-09 13:53:00,694:INFO:Copying training dataset
2024-12-09 13:53:00,698:INFO:Defining folds
2024-12-09 13:53:00,699:INFO:Declaring metric variables
2024-12-09 13:53:00,703:INFO:Importing untrained model
2024-12-09 13:53:00,707:INFO:Ada Boost Classifier Imported successfully
2024-12-09 13:53:00,715:INFO:Starting cross validation
2024-12-09 13:53:00,717:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:53:01,308:INFO:Calculating mean and std
2024-12-09 13:53:01,309:INFO:Creating metrics dataframe
2024-12-09 13:53:01,312:INFO:Uploading results into container
2024-12-09 13:53:01,313:INFO:Uploading model into container now
2024-12-09 13:53:01,314:INFO:_master_model_container: 9
2024-12-09 13:53:01,314:INFO:_display_container: 2
2024-12-09 13:53:01,314:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 13:53:01,314:INFO:create_model() successfully completed......................................
2024-12-09 13:53:01,429:INFO:SubProcess create_model() end ==================================
2024-12-09 13:53:01,429:INFO:Creating metrics dataframe
2024-12-09 13:53:01,442:INFO:Initializing Gradient Boosting Classifier
2024-12-09 13:53:01,442:INFO:Total runtime is 0.08510378996531169 minutes
2024-12-09 13:53:01,445:INFO:SubProcess create_model() called ==================================
2024-12-09 13:53:01,446:INFO:Initializing create_model()
2024-12-09 13:53:01,446:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E342015B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:01,446:INFO:Checking exceptions
2024-12-09 13:53:01,446:INFO:Importing libraries
2024-12-09 13:53:01,446:INFO:Copying training dataset
2024-12-09 13:53:01,450:INFO:Defining folds
2024-12-09 13:53:01,450:INFO:Declaring metric variables
2024-12-09 13:53:01,456:INFO:Importing untrained model
2024-12-09 13:53:01,461:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 13:53:01,468:INFO:Starting cross validation
2024-12-09 13:53:01,470:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:53:01,967:INFO:Calculating mean and std
2024-12-09 13:53:01,968:INFO:Creating metrics dataframe
2024-12-09 13:53:01,972:INFO:Uploading results into container
2024-12-09 13:53:01,973:INFO:Uploading model into container now
2024-12-09 13:53:01,973:INFO:_master_model_container: 10
2024-12-09 13:53:01,973:INFO:_display_container: 2
2024-12-09 13:53:01,974:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 13:53:01,975:INFO:create_model() successfully completed......................................
2024-12-09 13:53:02,083:INFO:SubProcess create_model() end ==================================
2024-12-09 13:53:02,083:INFO:Creating metrics dataframe
2024-12-09 13:53:02,096:INFO:Initializing Linear Discriminant Analysis
2024-12-09 13:53:02,096:INFO:Total runtime is 0.09601693550745646 minutes
2024-12-09 13:53:02,099:INFO:SubProcess create_model() called ==================================
2024-12-09 13:53:02,099:INFO:Initializing create_model()
2024-12-09 13:53:02,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E342015B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:02,099:INFO:Checking exceptions
2024-12-09 13:53:02,099:INFO:Importing libraries
2024-12-09 13:53:02,099:INFO:Copying training dataset
2024-12-09 13:53:02,107:INFO:Defining folds
2024-12-09 13:53:02,107:INFO:Declaring metric variables
2024-12-09 13:53:02,110:INFO:Importing untrained model
2024-12-09 13:53:02,116:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 13:53:02,134:INFO:Starting cross validation
2024-12-09 13:53:02,137:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:53:02,411:INFO:Calculating mean and std
2024-12-09 13:53:02,413:INFO:Creating metrics dataframe
2024-12-09 13:53:02,424:INFO:Uploading results into container
2024-12-09 13:53:02,425:INFO:Uploading model into container now
2024-12-09 13:53:02,425:INFO:_master_model_container: 11
2024-12-09 13:53:02,425:INFO:_display_container: 2
2024-12-09 13:53:02,425:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 13:53:02,425:INFO:create_model() successfully completed......................................
2024-12-09 13:53:02,557:INFO:SubProcess create_model() end ==================================
2024-12-09 13:53:02,557:INFO:Creating metrics dataframe
2024-12-09 13:53:02,573:INFO:Initializing Extra Trees Classifier
2024-12-09 13:53:02,573:INFO:Total runtime is 0.10395496288935344 minutes
2024-12-09 13:53:02,578:INFO:SubProcess create_model() called ==================================
2024-12-09 13:53:02,579:INFO:Initializing create_model()
2024-12-09 13:53:02,579:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E342015B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:02,579:INFO:Checking exceptions
2024-12-09 13:53:02,579:INFO:Importing libraries
2024-12-09 13:53:02,579:INFO:Copying training dataset
2024-12-09 13:53:02,584:INFO:Defining folds
2024-12-09 13:53:02,585:INFO:Declaring metric variables
2024-12-09 13:53:02,593:INFO:Importing untrained model
2024-12-09 13:53:02,597:INFO:Extra Trees Classifier Imported successfully
2024-12-09 13:53:02,611:INFO:Starting cross validation
2024-12-09 13:53:02,612:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:53:03,635:INFO:Calculating mean and std
2024-12-09 13:53:03,636:INFO:Creating metrics dataframe
2024-12-09 13:53:03,643:INFO:Uploading results into container
2024-12-09 13:53:03,643:INFO:Uploading model into container now
2024-12-09 13:53:03,644:INFO:_master_model_container: 12
2024-12-09 13:53:03,644:INFO:_display_container: 2
2024-12-09 13:53:03,645:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 13:53:03,646:INFO:create_model() successfully completed......................................
2024-12-09 13:53:03,797:INFO:SubProcess create_model() end ==================================
2024-12-09 13:53:03,798:INFO:Creating metrics dataframe
2024-12-09 13:53:03,814:INFO:Initializing Light Gradient Boosting Machine
2024-12-09 13:53:03,814:INFO:Total runtime is 0.1246511975924174 minutes
2024-12-09 13:53:03,819:INFO:SubProcess create_model() called ==================================
2024-12-09 13:53:03,819:INFO:Initializing create_model()
2024-12-09 13:53:03,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E342015B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:03,820:INFO:Checking exceptions
2024-12-09 13:53:03,820:INFO:Importing libraries
2024-12-09 13:53:03,820:INFO:Copying training dataset
2024-12-09 13:53:03,830:INFO:Defining folds
2024-12-09 13:53:03,830:INFO:Declaring metric variables
2024-12-09 13:53:03,834:INFO:Importing untrained model
2024-12-09 13:53:03,846:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:53:03,859:INFO:Starting cross validation
2024-12-09 13:53:03,864:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:53:05,367:INFO:Calculating mean and std
2024-12-09 13:53:05,368:INFO:Creating metrics dataframe
2024-12-09 13:53:05,381:INFO:Uploading results into container
2024-12-09 13:53:05,382:INFO:Uploading model into container now
2024-12-09 13:53:05,382:INFO:_master_model_container: 13
2024-12-09 13:53:05,382:INFO:_display_container: 2
2024-12-09 13:53:05,383:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:53:05,383:INFO:create_model() successfully completed......................................
2024-12-09 13:53:05,583:INFO:SubProcess create_model() end ==================================
2024-12-09 13:53:05,584:INFO:Creating metrics dataframe
2024-12-09 13:53:05,608:INFO:Initializing create_model()
2024-12-09 13:53:05,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:05,609:INFO:Checking exceptions
2024-12-09 13:53:05,612:INFO:Importing libraries
2024-12-09 13:53:05,612:INFO:Copying training dataset
2024-12-09 13:53:05,647:INFO:Defining folds
2024-12-09 13:53:05,648:INFO:Declaring metric variables
2024-12-09 13:53:05,649:INFO:Importing untrained model
2024-12-09 13:53:05,649:INFO:Declaring custom model
2024-12-09 13:53:05,650:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:53:05,651:INFO:Cross validation set to False
2024-12-09 13:53:05,651:INFO:Fitting Model
2024-12-09 13:53:05,719:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 13:53:05,719:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.
2024-12-09 13:53:05,719:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 13:53:05,719:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 13:53:05,719:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 13:53:05,719:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 13:53:05,719:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 13:53:05,719:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 13:53:05,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:53:05,797:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:53:05,797:INFO:create_model() successfully completed......................................
2024-12-09 13:53:05,918:INFO:Initializing create_model()
2024-12-09 13:53:05,919:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:05,919:INFO:Checking exceptions
2024-12-09 13:53:05,920:INFO:Importing libraries
2024-12-09 13:53:05,921:INFO:Copying training dataset
2024-12-09 13:53:05,927:INFO:Defining folds
2024-12-09 13:53:05,927:INFO:Declaring metric variables
2024-12-09 13:53:05,927:INFO:Importing untrained model
2024-12-09 13:53:05,928:INFO:Declaring custom model
2024-12-09 13:53:05,928:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 13:53:05,929:INFO:Cross validation set to False
2024-12-09 13:53:05,929:INFO:Fitting Model
2024-12-09 13:53:06,088:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 13:53:06,088:INFO:create_model() successfully completed......................................
2024-12-09 13:53:06,237:INFO:Initializing create_model()
2024-12-09 13:53:06,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:06,239:INFO:Checking exceptions
2024-12-09 13:53:06,245:INFO:Importing libraries
2024-12-09 13:53:06,245:INFO:Copying training dataset
2024-12-09 13:53:06,248:INFO:Defining folds
2024-12-09 13:53:06,249:INFO:Declaring metric variables
2024-12-09 13:53:06,249:INFO:Importing untrained model
2024-12-09 13:53:06,249:INFO:Declaring custom model
2024-12-09 13:53:06,249:INFO:Random Forest Classifier Imported successfully
2024-12-09 13:53:06,250:INFO:Cross validation set to False
2024-12-09 13:53:06,250:INFO:Fitting Model
2024-12-09 13:53:06,481:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 13:53:06,482:INFO:create_model() successfully completed......................................
2024-12-09 13:53:06,598:INFO:Initializing create_model()
2024-12-09 13:53:06,598:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:06,599:INFO:Checking exceptions
2024-12-09 13:53:06,601:INFO:Importing libraries
2024-12-09 13:53:06,601:INFO:Copying training dataset
2024-12-09 13:53:06,605:INFO:Defining folds
2024-12-09 13:53:06,605:INFO:Declaring metric variables
2024-12-09 13:53:06,605:INFO:Importing untrained model
2024-12-09 13:53:06,605:INFO:Declaring custom model
2024-12-09 13:53:06,607:INFO:Ada Boost Classifier Imported successfully
2024-12-09 13:53:06,610:INFO:Cross validation set to False
2024-12-09 13:53:06,610:INFO:Fitting Model
2024-12-09 13:53:06,746:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 13:53:06,746:INFO:create_model() successfully completed......................................
2024-12-09 13:53:06,878:INFO:Initializing create_model()
2024-12-09 13:53:06,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:06,878:INFO:Checking exceptions
2024-12-09 13:53:06,881:INFO:Importing libraries
2024-12-09 13:53:06,881:INFO:Copying training dataset
2024-12-09 13:53:06,885:INFO:Defining folds
2024-12-09 13:53:06,885:INFO:Declaring metric variables
2024-12-09 13:53:06,885:INFO:Importing untrained model
2024-12-09 13:53:06,885:INFO:Declaring custom model
2024-12-09 13:53:06,886:INFO:Logistic Regression Imported successfully
2024-12-09 13:53:06,887:INFO:Cross validation set to False
2024-12-09 13:53:06,887:INFO:Fitting Model
2024-12-09 13:53:06,987:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 13:53:06,987:INFO:create_model() successfully completed......................................
2024-12-09 13:53:07,118:INFO:Initializing create_model()
2024-12-09 13:53:07,119:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:07,119:INFO:Checking exceptions
2024-12-09 13:53:07,122:INFO:Importing libraries
2024-12-09 13:53:07,122:INFO:Copying training dataset
2024-12-09 13:53:07,130:INFO:Defining folds
2024-12-09 13:53:07,131:INFO:Declaring metric variables
2024-12-09 13:53:07,131:INFO:Importing untrained model
2024-12-09 13:53:07,131:INFO:Declaring custom model
2024-12-09 13:53:07,132:INFO:Extra Trees Classifier Imported successfully
2024-12-09 13:53:07,133:INFO:Cross validation set to False
2024-12-09 13:53:07,133:INFO:Fitting Model
2024-12-09 13:53:07,326:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 13:53:07,326:INFO:create_model() successfully completed......................................
2024-12-09 13:53:07,444:INFO:Initializing create_model()
2024-12-09 13:53:07,444:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:07,445:INFO:Checking exceptions
2024-12-09 13:53:07,448:INFO:Importing libraries
2024-12-09 13:53:07,448:INFO:Copying training dataset
2024-12-09 13:53:07,451:INFO:Defining folds
2024-12-09 13:53:07,451:INFO:Declaring metric variables
2024-12-09 13:53:07,452:INFO:Importing untrained model
2024-12-09 13:53:07,452:INFO:Declaring custom model
2024-12-09 13:53:07,452:INFO:Ridge Classifier Imported successfully
2024-12-09 13:53:07,453:INFO:Cross validation set to False
2024-12-09 13:53:07,453:INFO:Fitting Model
2024-12-09 13:53:07,505:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 13:53:07,505:INFO:create_model() successfully completed......................................
2024-12-09 13:53:07,640:INFO:Initializing create_model()
2024-12-09 13:53:07,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:07,642:INFO:Checking exceptions
2024-12-09 13:53:07,646:INFO:Importing libraries
2024-12-09 13:53:07,646:INFO:Copying training dataset
2024-12-09 13:53:07,650:INFO:Defining folds
2024-12-09 13:53:07,650:INFO:Declaring metric variables
2024-12-09 13:53:07,650:INFO:Importing untrained model
2024-12-09 13:53:07,650:INFO:Declaring custom model
2024-12-09 13:53:07,650:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 13:53:07,652:INFO:Cross validation set to False
2024-12-09 13:53:07,652:INFO:Fitting Model
2024-12-09 13:53:07,706:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 13:53:07,706:INFO:create_model() successfully completed......................................
2024-12-09 13:53:07,814:INFO:Initializing create_model()
2024-12-09 13:53:07,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:07,814:INFO:Checking exceptions
2024-12-09 13:53:07,817:INFO:Importing libraries
2024-12-09 13:53:07,817:INFO:Copying training dataset
2024-12-09 13:53:07,821:INFO:Defining folds
2024-12-09 13:53:07,821:INFO:Declaring metric variables
2024-12-09 13:53:07,821:INFO:Importing untrained model
2024-12-09 13:53:07,822:INFO:Declaring custom model
2024-12-09 13:53:07,822:INFO:Naive Bayes Imported successfully
2024-12-09 13:53:07,823:INFO:Cross validation set to False
2024-12-09 13:53:07,823:INFO:Fitting Model
2024-12-09 13:53:07,871:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 13:53:07,871:INFO:create_model() successfully completed......................................
2024-12-09 13:53:07,974:INFO:Initializing create_model()
2024-12-09 13:53:07,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:07,976:INFO:Checking exceptions
2024-12-09 13:53:07,978:INFO:Importing libraries
2024-12-09 13:53:07,978:INFO:Copying training dataset
2024-12-09 13:53:07,981:INFO:Defining folds
2024-12-09 13:53:07,981:INFO:Declaring metric variables
2024-12-09 13:53:07,981:INFO:Importing untrained model
2024-12-09 13:53:07,981:INFO:Declaring custom model
2024-12-09 13:53:07,982:INFO:Decision Tree Classifier Imported successfully
2024-12-09 13:53:07,983:INFO:Cross validation set to False
2024-12-09 13:53:07,983:INFO:Fitting Model
2024-12-09 13:53:08,029:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 13:53:08,029:INFO:create_model() successfully completed......................................
2024-12-09 13:53:08,178:INFO:Initializing create_model()
2024-12-09 13:53:08,178:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:08,179:INFO:Checking exceptions
2024-12-09 13:53:08,182:INFO:Importing libraries
2024-12-09 13:53:08,182:INFO:Copying training dataset
2024-12-09 13:53:08,185:INFO:Defining folds
2024-12-09 13:53:08,186:INFO:Declaring metric variables
2024-12-09 13:53:08,186:INFO:Importing untrained model
2024-12-09 13:53:08,186:INFO:Declaring custom model
2024-12-09 13:53:08,186:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 13:53:08,187:INFO:Cross validation set to False
2024-12-09 13:53:08,187:INFO:Fitting Model
2024-12-09 13:53:08,242:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:53:08,242:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 13:53:08,243:INFO:create_model() successfully completed......................................
2024-12-09 13:53:08,369:INFO:Initializing create_model()
2024-12-09 13:53:08,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:08,370:INFO:Checking exceptions
2024-12-09 13:53:08,373:INFO:Importing libraries
2024-12-09 13:53:08,373:INFO:Copying training dataset
2024-12-09 13:53:08,380:INFO:Defining folds
2024-12-09 13:53:08,380:INFO:Declaring metric variables
2024-12-09 13:53:08,380:INFO:Importing untrained model
2024-12-09 13:53:08,380:INFO:Declaring custom model
2024-12-09 13:53:08,381:INFO:K Neighbors Classifier Imported successfully
2024-12-09 13:53:08,383:INFO:Cross validation set to False
2024-12-09 13:53:08,383:INFO:Fitting Model
2024-12-09 13:53:08,433:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 13:53:08,433:INFO:create_model() successfully completed......................................
2024-12-09 13:53:08,547:INFO:Initializing create_model()
2024-12-09 13:53:08,547:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:08,547:INFO:Checking exceptions
2024-12-09 13:53:08,549:INFO:Importing libraries
2024-12-09 13:53:08,550:INFO:Copying training dataset
2024-12-09 13:53:08,553:INFO:Defining folds
2024-12-09 13:53:08,553:INFO:Declaring metric variables
2024-12-09 13:53:08,553:INFO:Importing untrained model
2024-12-09 13:53:08,553:INFO:Declaring custom model
2024-12-09 13:53:08,554:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 13:53:08,555:INFO:Cross validation set to False
2024-12-09 13:53:08,555:INFO:Fitting Model
2024-12-09 13:53:08,600:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 13:53:08,600:INFO:create_model() successfully completed......................................
2024-12-09 13:53:08,719:INFO:_master_model_container: 13
2024-12-09 13:53:08,720:INFO:_display_container: 2
2024-12-09 13:53:08,723:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-12-09 13:53:08,723:INFO:compare_models() successfully completed......................................
2024-12-09 13:53:08,726:INFO:Initializing finalize_model()
2024-12-09 13:53:08,726:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)], fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-09 13:53:08,729:INFO:Finalizing [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-12-09 13:53:08,734:INFO:Initializing create_model()
2024-12-09 13:53:08,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E341FD880>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)], fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:53:08,734:INFO:Checking exceptions
2024-12-09 13:54:25,379:INFO:PyCaret ClassificationExperiment
2024-12-09 13:54:25,379:INFO:Logging name: clf-default-name
2024-12-09 13:54:25,380:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-09 13:54:25,380:INFO:version 3.2.0
2024-12-09 13:54:25,380:INFO:Initializing setup()
2024-12-09 13:54:25,380:INFO:self.USI: c1b0
2024-12-09 13:54:25,380:INFO:self._variable_keys: {'fix_imbalance', 'log_plots_param', '_available_plots', 'X', 'seed', 'idx', 'gpu_param', '_ml_usecase', 'fold_generator', 'exp_name_log', 'y', 'is_multiclass', 'fold_shuffle_param', 'X_test', 'target_param', 'exp_id', 'logging_param', 'X_train', 'html_param', 'memory', 'fold_groups_param', 'y_train', 'n_jobs_param', 'data', 'gpu_n_jobs_param', 'USI', 'pipeline', 'y_test'}
2024-12-09 13:54:25,380:INFO:Checking environment
2024-12-09 13:54:25,380:INFO:python_version: 3.8.20
2024-12-09 13:54:25,380:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2024-12-09 13:54:25,380:INFO:machine: AMD64
2024-12-09 13:54:25,380:INFO:platform: Windows-10-10.0.19041-SP0
2024-12-09 13:54:25,383:INFO:Memory: svmem(total=17054896128, available=4504117248, percent=73.6, used=12550778880, free=4504117248)
2024-12-09 13:54:25,383:INFO:Physical Core: 6
2024-12-09 13:54:25,383:INFO:Logical Core: 6
2024-12-09 13:54:25,383:INFO:Checking libraries
2024-12-09 13:54:25,383:INFO:System:
2024-12-09 13:54:25,383:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2024-12-09 13:54:25,384:INFO:executable: c:\Users\EE715\anaconda3\envs\gym-env\python.exe
2024-12-09 13:54:25,384:INFO:   machine: Windows-10-10.0.19041-SP0
2024-12-09 13:54:25,384:INFO:PyCaret required dependencies:
2024-12-09 13:54:25,384:INFO:                 pip: 24.2
2024-12-09 13:54:25,384:INFO:          setuptools: 75.1.0
2024-12-09 13:54:25,384:INFO:             pycaret: 3.2.0
2024-12-09 13:54:25,384:INFO:             IPython: 8.12.3
2024-12-09 13:54:25,384:INFO:          ipywidgets: 8.1.5
2024-12-09 13:54:25,384:INFO:                tqdm: 4.67.1
2024-12-09 13:54:25,384:INFO:               numpy: 1.24.4
2024-12-09 13:54:25,384:INFO:              pandas: 1.5.3
2024-12-09 13:54:25,384:INFO:              jinja2: 3.1.4
2024-12-09 13:54:25,384:INFO:               scipy: 1.10.1
2024-12-09 13:54:25,384:INFO:              joblib: 1.2.0
2024-12-09 13:54:25,384:INFO:             sklearn: 1.2.2
2024-12-09 13:54:25,385:INFO:                pyod: 2.0.2
2024-12-09 13:54:25,385:INFO:            imblearn: 0.12.4
2024-12-09 13:54:25,385:INFO:   category_encoders: 2.6.4
2024-12-09 13:54:25,385:INFO:            lightgbm: 4.5.0
2024-12-09 13:54:25,385:INFO:               numba: 0.58.1
2024-12-09 13:54:25,385:INFO:            requests: 2.32.3
2024-12-09 13:54:25,385:INFO:          matplotlib: 3.6.0
2024-12-09 13:54:25,385:INFO:          scikitplot: 0.3.7
2024-12-09 13:54:25,385:INFO:         yellowbrick: 1.5
2024-12-09 13:54:25,385:INFO:              plotly: 5.24.1
2024-12-09 13:54:25,385:INFO:    plotly-resampler: Not installed
2024-12-09 13:54:25,385:INFO:             kaleido: 0.2.1
2024-12-09 13:54:25,385:INFO:           schemdraw: 0.15
2024-12-09 13:54:25,385:INFO:         statsmodels: 0.14.1
2024-12-09 13:54:25,385:INFO:              sktime: 0.21.1
2024-12-09 13:54:25,385:INFO:               tbats: 1.1.3
2024-12-09 13:54:25,385:INFO:            pmdarima: 2.0.4
2024-12-09 13:54:25,385:INFO:              psutil: 6.1.0
2024-12-09 13:54:25,385:INFO:          markupsafe: 2.1.5
2024-12-09 13:54:25,385:INFO:             pickle5: Not installed
2024-12-09 13:54:25,385:INFO:         cloudpickle: 3.1.0
2024-12-09 13:54:25,387:INFO:         deprecation: 2.1.0
2024-12-09 13:54:25,387:INFO:              xxhash: 3.5.0
2024-12-09 13:54:25,387:INFO:           wurlitzer: Not installed
2024-12-09 13:54:25,387:INFO:PyCaret optional dependencies:
2024-12-09 13:54:25,387:INFO:                shap: Not installed
2024-12-09 13:54:25,387:INFO:           interpret: Not installed
2024-12-09 13:54:25,388:INFO:                umap: Not installed
2024-12-09 13:54:25,388:INFO:     ydata_profiling: Not installed
2024-12-09 13:54:25,388:INFO:  explainerdashboard: Not installed
2024-12-09 13:54:25,388:INFO:             autoviz: Not installed
2024-12-09 13:54:25,388:INFO:           fairlearn: Not installed
2024-12-09 13:54:25,389:INFO:          deepchecks: Not installed
2024-12-09 13:54:25,389:INFO:             xgboost: Not installed
2024-12-09 13:54:25,389:INFO:            catboost: Not installed
2024-12-09 13:54:25,389:INFO:              kmodes: Not installed
2024-12-09 13:54:25,389:INFO:             mlxtend: Not installed
2024-12-09 13:54:25,389:INFO:       statsforecast: Not installed
2024-12-09 13:54:25,389:INFO:        tune_sklearn: Not installed
2024-12-09 13:54:25,389:INFO:                 ray: Not installed
2024-12-09 13:54:25,389:INFO:            hyperopt: Not installed
2024-12-09 13:54:25,389:INFO:              optuna: 4.1.0
2024-12-09 13:54:25,389:INFO:               skopt: Not installed
2024-12-09 13:54:25,389:INFO:              mlflow: Not installed
2024-12-09 13:54:25,389:INFO:              gradio: Not installed
2024-12-09 13:54:25,390:INFO:             fastapi: Not installed
2024-12-09 13:54:25,390:INFO:             uvicorn: Not installed
2024-12-09 13:54:25,390:INFO:              m2cgen: Not installed
2024-12-09 13:54:25,390:INFO:           evidently: Not installed
2024-12-09 13:54:25,391:INFO:               fugue: Not installed
2024-12-09 13:54:25,391:INFO:           streamlit: Not installed
2024-12-09 13:54:25,392:INFO:             prophet: Not installed
2024-12-09 13:54:25,393:INFO:None
2024-12-09 13:54:25,393:INFO:Set up data.
2024-12-09 13:54:25,405:INFO:Set up folding strategy.
2024-12-09 13:54:25,406:INFO:Set up train/test split.
2024-12-09 13:54:25,413:INFO:Set up index.
2024-12-09 13:54:25,413:INFO:Assigning column types.
2024-12-09 13:54:25,419:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-09 13:54:25,482:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 13:54:25,484:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:54:25,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:54:25,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:54:25,560:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 13:54:25,561:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:54:25,590:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:54:25,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:54:25,591:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-09 13:54:25,639:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:54:25,667:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:54:25,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:54:25,722:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:54:25,749:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:54:25,750:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:54:25,750:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-09 13:54:25,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:54:25,836:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:54:25,915:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:54:25,916:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:54:25,917:INFO:Preparing preprocessing pipeline...
2024-12-09 13:54:25,918:INFO:Set up simple imputation.
2024-12-09 13:54:25,922:INFO:Set up encoding of ordinal features.
2024-12-09 13:54:25,925:INFO:Set up encoding of categorical features.
2024-12-09 13:54:26,015:INFO:Finished creating preprocessing pipeline.
2024-12-09 13:54:26,032:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\EE715\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categ...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-12-09 13:54:26,032:INFO:Creating final display dataframe.
2024-12-09 13:54:26,278:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (623, 10)
6    Transformed test set shape         (268, 10)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              c1b0
2024-12-09 13:54:26,421:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:54:26,424:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:54:26,527:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:54:26,528:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:54:26,528:INFO:setup() successfully completed in 1.15s...............
2024-12-09 13:54:26,529:INFO:Initializing compare_models()
2024-12-09 13:54:26,529:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['dummy'])
2024-12-09 13:54:26,529:INFO:Checking exceptions
2024-12-09 13:54:26,532:INFO:Preparing display monitor
2024-12-09 13:54:26,584:INFO:Initializing Logistic Regression
2024-12-09 13:54:26,590:INFO:Total runtime is 9.981393814086914e-05 minutes
2024-12-09 13:54:26,602:INFO:SubProcess create_model() called ==================================
2024-12-09 13:54:26,603:INFO:Initializing create_model()
2024-12-09 13:54:26,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:26,609:INFO:Checking exceptions
2024-12-09 13:54:26,610:INFO:Importing libraries
2024-12-09 13:54:26,610:INFO:Copying training dataset
2024-12-09 13:54:26,615:INFO:Defining folds
2024-12-09 13:54:26,615:INFO:Declaring metric variables
2024-12-09 13:54:26,621:INFO:Importing untrained model
2024-12-09 13:54:26,627:INFO:Logistic Regression Imported successfully
2024-12-09 13:54:26,634:INFO:Starting cross validation
2024-12-09 13:54:26,636:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:54:27,160:INFO:Calculating mean and std
2024-12-09 13:54:27,161:INFO:Creating metrics dataframe
2024-12-09 13:54:27,164:INFO:Uploading results into container
2024-12-09 13:54:27,165:INFO:Uploading model into container now
2024-12-09 13:54:27,165:INFO:_master_model_container: 1
2024-12-09 13:54:27,165:INFO:_display_container: 2
2024-12-09 13:54:27,166:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 13:54:27,166:INFO:create_model() successfully completed......................................
2024-12-09 13:54:27,336:INFO:SubProcess create_model() end ==================================
2024-12-09 13:54:27,336:INFO:Creating metrics dataframe
2024-12-09 13:54:27,346:INFO:Initializing K Neighbors Classifier
2024-12-09 13:54:27,346:INFO:Total runtime is 0.01268999179204305 minutes
2024-12-09 13:54:27,349:INFO:SubProcess create_model() called ==================================
2024-12-09 13:54:27,350:INFO:Initializing create_model()
2024-12-09 13:54:27,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:27,350:INFO:Checking exceptions
2024-12-09 13:54:27,350:INFO:Importing libraries
2024-12-09 13:54:27,350:INFO:Copying training dataset
2024-12-09 13:54:27,355:INFO:Defining folds
2024-12-09 13:54:27,355:INFO:Declaring metric variables
2024-12-09 13:54:27,359:INFO:Importing untrained model
2024-12-09 13:54:27,365:INFO:K Neighbors Classifier Imported successfully
2024-12-09 13:54:27,374:INFO:Starting cross validation
2024-12-09 13:54:27,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:54:27,737:INFO:Calculating mean and std
2024-12-09 13:54:27,739:INFO:Creating metrics dataframe
2024-12-09 13:54:27,743:INFO:Uploading results into container
2024-12-09 13:54:27,743:INFO:Uploading model into container now
2024-12-09 13:54:27,744:INFO:_master_model_container: 2
2024-12-09 13:54:27,744:INFO:_display_container: 2
2024-12-09 13:54:27,744:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 13:54:27,744:INFO:create_model() successfully completed......................................
2024-12-09 13:54:27,857:INFO:SubProcess create_model() end ==================================
2024-12-09 13:54:27,857:INFO:Creating metrics dataframe
2024-12-09 13:54:27,867:INFO:Initializing Naive Bayes
2024-12-09 13:54:27,867:INFO:Total runtime is 0.02137877941131592 minutes
2024-12-09 13:54:27,872:INFO:SubProcess create_model() called ==================================
2024-12-09 13:54:27,873:INFO:Initializing create_model()
2024-12-09 13:54:27,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:27,873:INFO:Checking exceptions
2024-12-09 13:54:27,873:INFO:Importing libraries
2024-12-09 13:54:27,873:INFO:Copying training dataset
2024-12-09 13:54:27,879:INFO:Defining folds
2024-12-09 13:54:27,879:INFO:Declaring metric variables
2024-12-09 13:54:27,884:INFO:Importing untrained model
2024-12-09 13:54:27,890:INFO:Naive Bayes Imported successfully
2024-12-09 13:54:27,899:INFO:Starting cross validation
2024-12-09 13:54:27,900:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:54:28,160:INFO:Calculating mean and std
2024-12-09 13:54:28,161:INFO:Creating metrics dataframe
2024-12-09 13:54:28,164:INFO:Uploading results into container
2024-12-09 13:54:28,165:INFO:Uploading model into container now
2024-12-09 13:54:28,165:INFO:_master_model_container: 3
2024-12-09 13:54:28,165:INFO:_display_container: 2
2024-12-09 13:54:28,166:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 13:54:28,166:INFO:create_model() successfully completed......................................
2024-12-09 13:54:28,320:INFO:SubProcess create_model() end ==================================
2024-12-09 13:54:28,332:INFO:Creating metrics dataframe
2024-12-09 13:54:28,360:INFO:Initializing Decision Tree Classifier
2024-12-09 13:54:28,360:INFO:Total runtime is 0.02960119644800822 minutes
2024-12-09 13:54:28,370:INFO:SubProcess create_model() called ==================================
2024-12-09 13:54:28,371:INFO:Initializing create_model()
2024-12-09 13:54:28,373:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:28,374:INFO:Checking exceptions
2024-12-09 13:54:28,374:INFO:Importing libraries
2024-12-09 13:54:28,374:INFO:Copying training dataset
2024-12-09 13:54:28,381:INFO:Defining folds
2024-12-09 13:54:28,382:INFO:Declaring metric variables
2024-12-09 13:54:28,396:INFO:Importing untrained model
2024-12-09 13:54:28,402:INFO:Decision Tree Classifier Imported successfully
2024-12-09 13:54:28,429:INFO:Starting cross validation
2024-12-09 13:54:28,430:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:54:28,753:INFO:Calculating mean and std
2024-12-09 13:54:28,754:INFO:Creating metrics dataframe
2024-12-09 13:54:28,761:INFO:Uploading results into container
2024-12-09 13:54:28,761:INFO:Uploading model into container now
2024-12-09 13:54:28,762:INFO:_master_model_container: 4
2024-12-09 13:54:28,762:INFO:_display_container: 2
2024-12-09 13:54:28,762:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 13:54:28,762:INFO:create_model() successfully completed......................................
2024-12-09 13:54:28,874:INFO:SubProcess create_model() end ==================================
2024-12-09 13:54:28,875:INFO:Creating metrics dataframe
2024-12-09 13:54:28,884:INFO:Initializing SVM - Linear Kernel
2024-12-09 13:54:28,884:INFO:Total runtime is 0.03833329677581787 minutes
2024-12-09 13:54:28,888:INFO:SubProcess create_model() called ==================================
2024-12-09 13:54:28,888:INFO:Initializing create_model()
2024-12-09 13:54:28,888:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:28,889:INFO:Checking exceptions
2024-12-09 13:54:28,889:INFO:Importing libraries
2024-12-09 13:54:28,889:INFO:Copying training dataset
2024-12-09 13:54:28,894:INFO:Defining folds
2024-12-09 13:54:28,894:INFO:Declaring metric variables
2024-12-09 13:54:28,898:INFO:Importing untrained model
2024-12-09 13:54:28,902:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 13:54:28,913:INFO:Starting cross validation
2024-12-09 13:54:28,914:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:54:29,018:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:54:29,028:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:54:29,045:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:54:29,049:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:54:29,068:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:54:29,068:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:54:29,077:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:54:29,120:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:54:29,133:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:54:29,149:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:54:29,153:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:54:29,169:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:54:29,177:INFO:Calculating mean and std
2024-12-09 13:54:29,179:INFO:Creating metrics dataframe
2024-12-09 13:54:29,182:INFO:Uploading results into container
2024-12-09 13:54:29,183:INFO:Uploading model into container now
2024-12-09 13:54:29,183:INFO:_master_model_container: 5
2024-12-09 13:54:29,183:INFO:_display_container: 2
2024-12-09 13:54:29,183:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 13:54:29,183:INFO:create_model() successfully completed......................................
2024-12-09 13:54:29,310:INFO:SubProcess create_model() end ==================================
2024-12-09 13:54:29,310:INFO:Creating metrics dataframe
2024-12-09 13:54:29,321:INFO:Initializing Ridge Classifier
2024-12-09 13:54:29,322:INFO:Total runtime is 0.0456220547358195 minutes
2024-12-09 13:54:29,329:INFO:SubProcess create_model() called ==================================
2024-12-09 13:54:29,329:INFO:Initializing create_model()
2024-12-09 13:54:29,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:29,330:INFO:Checking exceptions
2024-12-09 13:54:29,330:INFO:Importing libraries
2024-12-09 13:54:29,330:INFO:Copying training dataset
2024-12-09 13:54:29,334:INFO:Defining folds
2024-12-09 13:54:29,334:INFO:Declaring metric variables
2024-12-09 13:54:29,338:INFO:Importing untrained model
2024-12-09 13:54:29,346:INFO:Ridge Classifier Imported successfully
2024-12-09 13:54:29,354:INFO:Starting cross validation
2024-12-09 13:54:29,356:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:54:29,470:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:54:29,493:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:54:29,502:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:54:29,515:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:54:29,554:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:54:29,571:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:54:29,585:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:54:29,597:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:54:29,605:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:54:29,620:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:54:29,627:INFO:Calculating mean and std
2024-12-09 13:54:29,629:INFO:Creating metrics dataframe
2024-12-09 13:54:29,633:INFO:Uploading results into container
2024-12-09 13:54:29,633:INFO:Uploading model into container now
2024-12-09 13:54:29,634:INFO:_master_model_container: 6
2024-12-09 13:54:29,634:INFO:_display_container: 2
2024-12-09 13:54:29,634:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 13:54:29,635:INFO:create_model() successfully completed......................................
2024-12-09 13:54:29,734:INFO:SubProcess create_model() end ==================================
2024-12-09 13:54:29,734:INFO:Creating metrics dataframe
2024-12-09 13:54:29,745:INFO:Initializing Random Forest Classifier
2024-12-09 13:54:29,745:INFO:Total runtime is 0.052676316102345785 minutes
2024-12-09 13:54:29,748:INFO:SubProcess create_model() called ==================================
2024-12-09 13:54:29,748:INFO:Initializing create_model()
2024-12-09 13:54:29,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:29,748:INFO:Checking exceptions
2024-12-09 13:54:29,748:INFO:Importing libraries
2024-12-09 13:54:29,748:INFO:Copying training dataset
2024-12-09 13:54:29,753:INFO:Defining folds
2024-12-09 13:54:29,753:INFO:Declaring metric variables
2024-12-09 13:54:29,757:INFO:Importing untrained model
2024-12-09 13:54:29,761:INFO:Random Forest Classifier Imported successfully
2024-12-09 13:54:29,769:INFO:Starting cross validation
2024-12-09 13:54:29,771:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:54:30,562:INFO:Calculating mean and std
2024-12-09 13:54:30,563:INFO:Creating metrics dataframe
2024-12-09 13:54:30,567:INFO:Uploading results into container
2024-12-09 13:54:30,567:INFO:Uploading model into container now
2024-12-09 13:54:30,567:INFO:_master_model_container: 7
2024-12-09 13:54:30,568:INFO:_display_container: 2
2024-12-09 13:54:30,568:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 13:54:30,568:INFO:create_model() successfully completed......................................
2024-12-09 13:54:30,667:INFO:SubProcess create_model() end ==================================
2024-12-09 13:54:30,667:INFO:Creating metrics dataframe
2024-12-09 13:54:30,679:INFO:Initializing Quadratic Discriminant Analysis
2024-12-09 13:54:30,679:INFO:Total runtime is 0.06824270884195964 minutes
2024-12-09 13:54:30,682:INFO:SubProcess create_model() called ==================================
2024-12-09 13:54:30,683:INFO:Initializing create_model()
2024-12-09 13:54:30,683:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:30,683:INFO:Checking exceptions
2024-12-09 13:54:30,683:INFO:Importing libraries
2024-12-09 13:54:30,683:INFO:Copying training dataset
2024-12-09 13:54:30,687:INFO:Defining folds
2024-12-09 13:54:30,687:INFO:Declaring metric variables
2024-12-09 13:54:30,691:INFO:Importing untrained model
2024-12-09 13:54:30,697:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 13:54:30,703:INFO:Starting cross validation
2024-12-09 13:54:30,705:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:54:30,789:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:54:30,789:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:54:30,793:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:54:30,794:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:54:30,798:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:54:30,817:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:54:30,900:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:54:30,910:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:54:30,911:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:54:30,912:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:54:30,954:INFO:Calculating mean and std
2024-12-09 13:54:30,956:INFO:Creating metrics dataframe
2024-12-09 13:54:30,960:INFO:Uploading results into container
2024-12-09 13:54:30,961:INFO:Uploading model into container now
2024-12-09 13:54:30,961:INFO:_master_model_container: 8
2024-12-09 13:54:30,961:INFO:_display_container: 2
2024-12-09 13:54:30,961:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 13:54:30,962:INFO:create_model() successfully completed......................................
2024-12-09 13:54:31,066:INFO:SubProcess create_model() end ==================================
2024-12-09 13:54:31,066:INFO:Creating metrics dataframe
2024-12-09 13:54:31,078:INFO:Initializing Ada Boost Classifier
2024-12-09 13:54:31,078:INFO:Total runtime is 0.07490144968032837 minutes
2024-12-09 13:54:31,082:INFO:SubProcess create_model() called ==================================
2024-12-09 13:54:31,082:INFO:Initializing create_model()
2024-12-09 13:54:31,082:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:31,082:INFO:Checking exceptions
2024-12-09 13:54:31,082:INFO:Importing libraries
2024-12-09 13:54:31,082:INFO:Copying training dataset
2024-12-09 13:54:31,087:INFO:Defining folds
2024-12-09 13:54:31,087:INFO:Declaring metric variables
2024-12-09 13:54:31,093:INFO:Importing untrained model
2024-12-09 13:54:31,097:INFO:Ada Boost Classifier Imported successfully
2024-12-09 13:54:31,105:INFO:Starting cross validation
2024-12-09 13:54:31,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:54:31,519:INFO:Calculating mean and std
2024-12-09 13:54:31,520:INFO:Creating metrics dataframe
2024-12-09 13:54:31,524:INFO:Uploading results into container
2024-12-09 13:54:31,524:INFO:Uploading model into container now
2024-12-09 13:54:31,525:INFO:_master_model_container: 9
2024-12-09 13:54:31,525:INFO:_display_container: 2
2024-12-09 13:54:31,526:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 13:54:31,526:INFO:create_model() successfully completed......................................
2024-12-09 13:54:31,627:INFO:SubProcess create_model() end ==================================
2024-12-09 13:54:31,627:INFO:Creating metrics dataframe
2024-12-09 13:54:31,638:INFO:Initializing Gradient Boosting Classifier
2024-12-09 13:54:31,638:INFO:Total runtime is 0.08422091007232667 minutes
2024-12-09 13:54:31,642:INFO:SubProcess create_model() called ==================================
2024-12-09 13:54:31,642:INFO:Initializing create_model()
2024-12-09 13:54:31,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:31,643:INFO:Checking exceptions
2024-12-09 13:54:31,643:INFO:Importing libraries
2024-12-09 13:54:31,643:INFO:Copying training dataset
2024-12-09 13:54:31,647:INFO:Defining folds
2024-12-09 13:54:31,648:INFO:Declaring metric variables
2024-12-09 13:54:31,651:INFO:Importing untrained model
2024-12-09 13:54:31,657:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 13:54:31,666:INFO:Starting cross validation
2024-12-09 13:54:31,667:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:54:32,089:INFO:Calculating mean and std
2024-12-09 13:54:32,090:INFO:Creating metrics dataframe
2024-12-09 13:54:32,095:INFO:Uploading results into container
2024-12-09 13:54:32,096:INFO:Uploading model into container now
2024-12-09 13:54:32,096:INFO:_master_model_container: 10
2024-12-09 13:54:32,096:INFO:_display_container: 2
2024-12-09 13:54:32,097:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 13:54:32,097:INFO:create_model() successfully completed......................................
2024-12-09 13:54:32,206:INFO:SubProcess create_model() end ==================================
2024-12-09 13:54:32,206:INFO:Creating metrics dataframe
2024-12-09 13:54:32,218:INFO:Initializing Linear Discriminant Analysis
2024-12-09 13:54:32,218:INFO:Total runtime is 0.09388876756032309 minutes
2024-12-09 13:54:32,221:INFO:SubProcess create_model() called ==================================
2024-12-09 13:54:32,222:INFO:Initializing create_model()
2024-12-09 13:54:32,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:32,222:INFO:Checking exceptions
2024-12-09 13:54:32,222:INFO:Importing libraries
2024-12-09 13:54:32,222:INFO:Copying training dataset
2024-12-09 13:54:32,228:INFO:Defining folds
2024-12-09 13:54:32,228:INFO:Declaring metric variables
2024-12-09 13:54:32,233:INFO:Importing untrained model
2024-12-09 13:54:32,236:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 13:54:32,281:INFO:Starting cross validation
2024-12-09 13:54:32,283:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:54:32,496:INFO:Calculating mean and std
2024-12-09 13:54:32,497:INFO:Creating metrics dataframe
2024-12-09 13:54:32,500:INFO:Uploading results into container
2024-12-09 13:54:32,501:INFO:Uploading model into container now
2024-12-09 13:54:32,501:INFO:_master_model_container: 11
2024-12-09 13:54:32,501:INFO:_display_container: 2
2024-12-09 13:54:32,502:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 13:54:32,502:INFO:create_model() successfully completed......................................
2024-12-09 13:54:32,602:INFO:SubProcess create_model() end ==================================
2024-12-09 13:54:32,602:INFO:Creating metrics dataframe
2024-12-09 13:54:32,614:INFO:Initializing Extra Trees Classifier
2024-12-09 13:54:32,614:INFO:Total runtime is 0.1004999041557312 minutes
2024-12-09 13:54:32,618:INFO:SubProcess create_model() called ==================================
2024-12-09 13:54:32,618:INFO:Initializing create_model()
2024-12-09 13:54:32,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:32,618:INFO:Checking exceptions
2024-12-09 13:54:32,618:INFO:Importing libraries
2024-12-09 13:54:32,618:INFO:Copying training dataset
2024-12-09 13:54:32,623:INFO:Defining folds
2024-12-09 13:54:32,623:INFO:Declaring metric variables
2024-12-09 13:54:32,627:INFO:Importing untrained model
2024-12-09 13:54:32,632:INFO:Extra Trees Classifier Imported successfully
2024-12-09 13:54:32,639:INFO:Starting cross validation
2024-12-09 13:54:32,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:54:33,364:INFO:Calculating mean and std
2024-12-09 13:54:33,365:INFO:Creating metrics dataframe
2024-12-09 13:54:33,370:INFO:Uploading results into container
2024-12-09 13:54:33,371:INFO:Uploading model into container now
2024-12-09 13:54:33,371:INFO:_master_model_container: 12
2024-12-09 13:54:33,371:INFO:_display_container: 2
2024-12-09 13:54:33,371:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 13:54:33,371:INFO:create_model() successfully completed......................................
2024-12-09 13:54:33,475:INFO:SubProcess create_model() end ==================================
2024-12-09 13:54:33,476:INFO:Creating metrics dataframe
2024-12-09 13:54:33,488:INFO:Initializing Light Gradient Boosting Machine
2024-12-09 13:54:33,488:INFO:Total runtime is 0.11505915721257529 minutes
2024-12-09 13:54:33,491:INFO:SubProcess create_model() called ==================================
2024-12-09 13:54:33,491:INFO:Initializing create_model()
2024-12-09 13:54:33,491:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:33,491:INFO:Checking exceptions
2024-12-09 13:54:33,492:INFO:Importing libraries
2024-12-09 13:54:33,492:INFO:Copying training dataset
2024-12-09 13:54:33,497:INFO:Defining folds
2024-12-09 13:54:33,497:INFO:Declaring metric variables
2024-12-09 13:54:33,501:INFO:Importing untrained model
2024-12-09 13:54:33,505:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:54:33,515:INFO:Starting cross validation
2024-12-09 13:54:33,517:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:54:34,353:INFO:Calculating mean and std
2024-12-09 13:54:34,354:INFO:Creating metrics dataframe
2024-12-09 13:54:34,358:INFO:Uploading results into container
2024-12-09 13:54:34,358:INFO:Uploading model into container now
2024-12-09 13:54:34,358:INFO:_master_model_container: 13
2024-12-09 13:54:34,359:INFO:_display_container: 2
2024-12-09 13:54:34,360:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:54:34,361:INFO:create_model() successfully completed......................................
2024-12-09 13:54:34,476:INFO:SubProcess create_model() end ==================================
2024-12-09 13:54:34,476:INFO:Creating metrics dataframe
2024-12-09 13:54:34,501:INFO:Initializing create_model()
2024-12-09 13:54:34,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:34,502:INFO:Checking exceptions
2024-12-09 13:54:34,504:INFO:Importing libraries
2024-12-09 13:54:34,504:INFO:Copying training dataset
2024-12-09 13:54:34,507:INFO:Defining folds
2024-12-09 13:54:34,507:INFO:Declaring metric variables
2024-12-09 13:54:34,507:INFO:Importing untrained model
2024-12-09 13:54:34,507:INFO:Declaring custom model
2024-12-09 13:54:34,508:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:54:34,509:INFO:Cross validation set to False
2024-12-09 13:54:34,509:INFO:Fitting Model
2024-12-09 13:54:34,566:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 13:54:34,566:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000072 seconds.
2024-12-09 13:54:34,567:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 13:54:34,567:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 13:54:34,567:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 13:54:34,567:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 13:54:34,567:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 13:54:34,567:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 13:54:34,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:54:34,600:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:54:34,600:INFO:create_model() successfully completed......................................
2024-12-09 13:54:34,705:INFO:Initializing create_model()
2024-12-09 13:54:34,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:34,706:INFO:Checking exceptions
2024-12-09 13:54:34,708:INFO:Importing libraries
2024-12-09 13:54:34,708:INFO:Copying training dataset
2024-12-09 13:54:34,712:INFO:Defining folds
2024-12-09 13:54:34,713:INFO:Declaring metric variables
2024-12-09 13:54:34,713:INFO:Importing untrained model
2024-12-09 13:54:34,713:INFO:Declaring custom model
2024-12-09 13:54:34,714:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 13:54:34,715:INFO:Cross validation set to False
2024-12-09 13:54:34,715:INFO:Fitting Model
2024-12-09 13:54:34,855:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 13:54:34,855:INFO:create_model() successfully completed......................................
2024-12-09 13:54:34,958:INFO:Initializing create_model()
2024-12-09 13:54:34,958:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:34,958:INFO:Checking exceptions
2024-12-09 13:54:34,960:INFO:Importing libraries
2024-12-09 13:54:34,960:INFO:Copying training dataset
2024-12-09 13:54:34,964:INFO:Defining folds
2024-12-09 13:54:34,964:INFO:Declaring metric variables
2024-12-09 13:54:34,964:INFO:Importing untrained model
2024-12-09 13:54:34,964:INFO:Declaring custom model
2024-12-09 13:54:34,965:INFO:Random Forest Classifier Imported successfully
2024-12-09 13:54:34,966:INFO:Cross validation set to False
2024-12-09 13:54:34,966:INFO:Fitting Model
2024-12-09 13:54:35,170:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 13:54:35,170:INFO:create_model() successfully completed......................................
2024-12-09 13:54:35,274:INFO:Initializing create_model()
2024-12-09 13:54:35,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:35,274:INFO:Checking exceptions
2024-12-09 13:54:35,277:INFO:Importing libraries
2024-12-09 13:54:35,277:INFO:Copying training dataset
2024-12-09 13:54:35,282:INFO:Defining folds
2024-12-09 13:54:35,282:INFO:Declaring metric variables
2024-12-09 13:54:35,282:INFO:Importing untrained model
2024-12-09 13:54:35,282:INFO:Declaring custom model
2024-12-09 13:54:35,283:INFO:Ada Boost Classifier Imported successfully
2024-12-09 13:54:35,284:INFO:Cross validation set to False
2024-12-09 13:54:35,284:INFO:Fitting Model
2024-12-09 13:54:35,404:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 13:54:35,404:INFO:create_model() successfully completed......................................
2024-12-09 13:54:35,515:INFO:Initializing create_model()
2024-12-09 13:54:35,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:35,515:INFO:Checking exceptions
2024-12-09 13:54:35,517:INFO:Importing libraries
2024-12-09 13:54:35,517:INFO:Copying training dataset
2024-12-09 13:54:35,521:INFO:Defining folds
2024-12-09 13:54:35,521:INFO:Declaring metric variables
2024-12-09 13:54:35,521:INFO:Importing untrained model
2024-12-09 13:54:35,521:INFO:Declaring custom model
2024-12-09 13:54:35,522:INFO:Logistic Regression Imported successfully
2024-12-09 13:54:35,523:INFO:Cross validation set to False
2024-12-09 13:54:35,523:INFO:Fitting Model
2024-12-09 13:54:35,610:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 13:54:35,610:INFO:create_model() successfully completed......................................
2024-12-09 13:54:35,713:INFO:Initializing create_model()
2024-12-09 13:54:35,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:35,714:INFO:Checking exceptions
2024-12-09 13:54:35,715:INFO:Importing libraries
2024-12-09 13:54:35,715:INFO:Copying training dataset
2024-12-09 13:54:35,720:INFO:Defining folds
2024-12-09 13:54:35,720:INFO:Declaring metric variables
2024-12-09 13:54:35,720:INFO:Importing untrained model
2024-12-09 13:54:35,720:INFO:Declaring custom model
2024-12-09 13:54:35,720:INFO:Extra Trees Classifier Imported successfully
2024-12-09 13:54:35,721:INFO:Cross validation set to False
2024-12-09 13:54:35,721:INFO:Fitting Model
2024-12-09 13:54:35,896:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 13:54:35,896:INFO:create_model() successfully completed......................................
2024-12-09 13:54:35,999:INFO:Initializing create_model()
2024-12-09 13:54:35,999:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:35,999:INFO:Checking exceptions
2024-12-09 13:54:36,002:INFO:Importing libraries
2024-12-09 13:54:36,002:INFO:Copying training dataset
2024-12-09 13:54:36,005:INFO:Defining folds
2024-12-09 13:54:36,005:INFO:Declaring metric variables
2024-12-09 13:54:36,006:INFO:Importing untrained model
2024-12-09 13:54:36,006:INFO:Declaring custom model
2024-12-09 13:54:36,006:INFO:Ridge Classifier Imported successfully
2024-12-09 13:54:36,007:INFO:Cross validation set to False
2024-12-09 13:54:36,008:INFO:Fitting Model
2024-12-09 13:54:36,053:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 13:54:36,054:INFO:create_model() successfully completed......................................
2024-12-09 13:54:36,157:INFO:Initializing create_model()
2024-12-09 13:54:36,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:36,157:INFO:Checking exceptions
2024-12-09 13:54:36,159:INFO:Importing libraries
2024-12-09 13:54:36,160:INFO:Copying training dataset
2024-12-09 13:54:36,165:INFO:Defining folds
2024-12-09 13:54:36,165:INFO:Declaring metric variables
2024-12-09 13:54:36,165:INFO:Importing untrained model
2024-12-09 13:54:36,165:INFO:Declaring custom model
2024-12-09 13:54:36,166:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 13:54:36,167:INFO:Cross validation set to False
2024-12-09 13:54:36,167:INFO:Fitting Model
2024-12-09 13:54:36,211:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 13:54:36,211:INFO:create_model() successfully completed......................................
2024-12-09 13:54:36,319:INFO:Initializing create_model()
2024-12-09 13:54:36,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:36,319:INFO:Checking exceptions
2024-12-09 13:54:36,321:INFO:Importing libraries
2024-12-09 13:54:36,321:INFO:Copying training dataset
2024-12-09 13:54:36,325:INFO:Defining folds
2024-12-09 13:54:36,325:INFO:Declaring metric variables
2024-12-09 13:54:36,325:INFO:Importing untrained model
2024-12-09 13:54:36,325:INFO:Declaring custom model
2024-12-09 13:54:36,325:INFO:Naive Bayes Imported successfully
2024-12-09 13:54:36,326:INFO:Cross validation set to False
2024-12-09 13:54:36,326:INFO:Fitting Model
2024-12-09 13:54:36,372:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 13:54:36,372:INFO:create_model() successfully completed......................................
2024-12-09 13:54:36,481:INFO:Initializing create_model()
2024-12-09 13:54:36,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:36,481:INFO:Checking exceptions
2024-12-09 13:54:36,483:INFO:Importing libraries
2024-12-09 13:54:36,483:INFO:Copying training dataset
2024-12-09 13:54:36,486:INFO:Defining folds
2024-12-09 13:54:36,486:INFO:Declaring metric variables
2024-12-09 13:54:36,486:INFO:Importing untrained model
2024-12-09 13:54:36,486:INFO:Declaring custom model
2024-12-09 13:54:36,487:INFO:Decision Tree Classifier Imported successfully
2024-12-09 13:54:36,488:INFO:Cross validation set to False
2024-12-09 13:54:36,488:INFO:Fitting Model
2024-12-09 13:54:36,535:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 13:54:36,535:INFO:create_model() successfully completed......................................
2024-12-09 13:54:36,643:INFO:Initializing create_model()
2024-12-09 13:54:36,644:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:36,644:INFO:Checking exceptions
2024-12-09 13:54:36,647:INFO:Importing libraries
2024-12-09 13:54:36,647:INFO:Copying training dataset
2024-12-09 13:54:36,651:INFO:Defining folds
2024-12-09 13:54:36,651:INFO:Declaring metric variables
2024-12-09 13:54:36,652:INFO:Importing untrained model
2024-12-09 13:54:36,652:INFO:Declaring custom model
2024-12-09 13:54:36,652:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 13:54:36,653:INFO:Cross validation set to False
2024-12-09 13:54:36,653:INFO:Fitting Model
2024-12-09 13:54:36,696:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:54:36,697:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 13:54:36,698:INFO:create_model() successfully completed......................................
2024-12-09 13:54:36,800:INFO:Initializing create_model()
2024-12-09 13:54:36,801:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:36,801:INFO:Checking exceptions
2024-12-09 13:54:36,803:INFO:Importing libraries
2024-12-09 13:54:36,803:INFO:Copying training dataset
2024-12-09 13:54:36,806:INFO:Defining folds
2024-12-09 13:54:36,806:INFO:Declaring metric variables
2024-12-09 13:54:36,807:INFO:Importing untrained model
2024-12-09 13:54:36,807:INFO:Declaring custom model
2024-12-09 13:54:36,807:INFO:K Neighbors Classifier Imported successfully
2024-12-09 13:54:36,808:INFO:Cross validation set to False
2024-12-09 13:54:36,808:INFO:Fitting Model
2024-12-09 13:54:36,854:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 13:54:36,854:INFO:create_model() successfully completed......................................
2024-12-09 13:54:36,958:INFO:Initializing create_model()
2024-12-09 13:54:36,958:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:36,958:INFO:Checking exceptions
2024-12-09 13:54:36,960:INFO:Importing libraries
2024-12-09 13:54:36,960:INFO:Copying training dataset
2024-12-09 13:54:36,965:INFO:Defining folds
2024-12-09 13:54:36,965:INFO:Declaring metric variables
2024-12-09 13:54:36,965:INFO:Importing untrained model
2024-12-09 13:54:36,965:INFO:Declaring custom model
2024-12-09 13:54:36,966:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 13:54:36,967:INFO:Cross validation set to False
2024-12-09 13:54:36,967:INFO:Fitting Model
2024-12-09 13:54:37,013:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 13:54:37,013:INFO:create_model() successfully completed......................................
2024-12-09 13:54:37,134:INFO:_master_model_container: 13
2024-12-09 13:54:37,134:INFO:_display_container: 2
2024-12-09 13:54:37,137:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-12-09 13:54:37,137:INFO:compare_models() successfully completed......................................
2024-12-09 13:54:37,140:INFO:Initializing finalize_model()
2024-12-09 13:54:37,140:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)], fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-09 13:54:37,143:INFO:Finalizing [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-12-09 13:54:37,148:INFO:Initializing create_model()
2024-12-09 13:54:37,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E16899DF0>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)], fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:54:37,148:INFO:Checking exceptions
2024-12-09 13:55:23,056:INFO:PyCaret ClassificationExperiment
2024-12-09 13:55:23,056:INFO:Logging name: clf-default-name
2024-12-09 13:55:23,056:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-09 13:55:23,056:INFO:version 3.2.0
2024-12-09 13:55:23,056:INFO:Initializing setup()
2024-12-09 13:55:23,056:INFO:self.USI: ee29
2024-12-09 13:55:23,056:INFO:self._variable_keys: {'fix_imbalance', 'log_plots_param', '_available_plots', 'X', 'seed', 'idx', 'gpu_param', '_ml_usecase', 'fold_generator', 'exp_name_log', 'y', 'is_multiclass', 'fold_shuffle_param', 'X_test', 'target_param', 'exp_id', 'logging_param', 'X_train', 'html_param', 'memory', 'fold_groups_param', 'y_train', 'n_jobs_param', 'data', 'gpu_n_jobs_param', 'USI', 'pipeline', 'y_test'}
2024-12-09 13:55:23,056:INFO:Checking environment
2024-12-09 13:55:23,056:INFO:python_version: 3.8.20
2024-12-09 13:55:23,057:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2024-12-09 13:55:23,057:INFO:machine: AMD64
2024-12-09 13:55:23,057:INFO:platform: Windows-10-10.0.19041-SP0
2024-12-09 13:55:23,060:INFO:Memory: svmem(total=17054896128, available=4589428736, percent=73.1, used=12465467392, free=4589428736)
2024-12-09 13:55:23,060:INFO:Physical Core: 6
2024-12-09 13:55:23,061:INFO:Logical Core: 6
2024-12-09 13:55:23,061:INFO:Checking libraries
2024-12-09 13:55:23,061:INFO:System:
2024-12-09 13:55:23,061:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2024-12-09 13:55:23,061:INFO:executable: c:\Users\EE715\anaconda3\envs\gym-env\python.exe
2024-12-09 13:55:23,061:INFO:   machine: Windows-10-10.0.19041-SP0
2024-12-09 13:55:23,061:INFO:PyCaret required dependencies:
2024-12-09 13:55:23,061:INFO:                 pip: 24.2
2024-12-09 13:55:23,061:INFO:          setuptools: 75.1.0
2024-12-09 13:55:23,061:INFO:             pycaret: 3.2.0
2024-12-09 13:55:23,061:INFO:             IPython: 8.12.3
2024-12-09 13:55:23,061:INFO:          ipywidgets: 8.1.5
2024-12-09 13:55:23,062:INFO:                tqdm: 4.67.1
2024-12-09 13:55:23,062:INFO:               numpy: 1.24.4
2024-12-09 13:55:23,062:INFO:              pandas: 1.5.3
2024-12-09 13:55:23,062:INFO:              jinja2: 3.1.4
2024-12-09 13:55:23,062:INFO:               scipy: 1.10.1
2024-12-09 13:55:23,062:INFO:              joblib: 1.2.0
2024-12-09 13:55:23,062:INFO:             sklearn: 1.2.2
2024-12-09 13:55:23,062:INFO:                pyod: 2.0.2
2024-12-09 13:55:23,062:INFO:            imblearn: 0.12.4
2024-12-09 13:55:23,062:INFO:   category_encoders: 2.6.4
2024-12-09 13:55:23,062:INFO:            lightgbm: 4.5.0
2024-12-09 13:55:23,062:INFO:               numba: 0.58.1
2024-12-09 13:55:23,062:INFO:            requests: 2.32.3
2024-12-09 13:55:23,062:INFO:          matplotlib: 3.6.0
2024-12-09 13:55:23,062:INFO:          scikitplot: 0.3.7
2024-12-09 13:55:23,062:INFO:         yellowbrick: 1.5
2024-12-09 13:55:23,062:INFO:              plotly: 5.24.1
2024-12-09 13:55:23,062:INFO:    plotly-resampler: Not installed
2024-12-09 13:55:23,062:INFO:             kaleido: 0.2.1
2024-12-09 13:55:23,062:INFO:           schemdraw: 0.15
2024-12-09 13:55:23,062:INFO:         statsmodels: 0.14.1
2024-12-09 13:55:23,063:INFO:              sktime: 0.21.1
2024-12-09 13:55:23,063:INFO:               tbats: 1.1.3
2024-12-09 13:55:23,063:INFO:            pmdarima: 2.0.4
2024-12-09 13:55:23,063:INFO:              psutil: 6.1.0
2024-12-09 13:55:23,063:INFO:          markupsafe: 2.1.5
2024-12-09 13:55:23,063:INFO:             pickle5: Not installed
2024-12-09 13:55:23,063:INFO:         cloudpickle: 3.1.0
2024-12-09 13:55:23,063:INFO:         deprecation: 2.1.0
2024-12-09 13:55:23,063:INFO:              xxhash: 3.5.0
2024-12-09 13:55:23,063:INFO:           wurlitzer: Not installed
2024-12-09 13:55:23,063:INFO:PyCaret optional dependencies:
2024-12-09 13:55:23,063:INFO:                shap: Not installed
2024-12-09 13:55:23,063:INFO:           interpret: Not installed
2024-12-09 13:55:23,063:INFO:                umap: Not installed
2024-12-09 13:55:23,063:INFO:     ydata_profiling: Not installed
2024-12-09 13:55:23,063:INFO:  explainerdashboard: Not installed
2024-12-09 13:55:23,063:INFO:             autoviz: Not installed
2024-12-09 13:55:23,063:INFO:           fairlearn: Not installed
2024-12-09 13:55:23,063:INFO:          deepchecks: Not installed
2024-12-09 13:55:23,063:INFO:             xgboost: Not installed
2024-12-09 13:55:23,064:INFO:            catboost: Not installed
2024-12-09 13:55:23,064:INFO:              kmodes: Not installed
2024-12-09 13:55:23,064:INFO:             mlxtend: Not installed
2024-12-09 13:55:23,064:INFO:       statsforecast: Not installed
2024-12-09 13:55:23,064:INFO:        tune_sklearn: Not installed
2024-12-09 13:55:23,064:INFO:                 ray: Not installed
2024-12-09 13:55:23,064:INFO:            hyperopt: Not installed
2024-12-09 13:55:23,064:INFO:              optuna: 4.1.0
2024-12-09 13:55:23,064:INFO:               skopt: Not installed
2024-12-09 13:55:23,064:INFO:              mlflow: Not installed
2024-12-09 13:55:23,064:INFO:              gradio: Not installed
2024-12-09 13:55:23,064:INFO:             fastapi: Not installed
2024-12-09 13:55:23,064:INFO:             uvicorn: Not installed
2024-12-09 13:55:23,064:INFO:              m2cgen: Not installed
2024-12-09 13:55:23,064:INFO:           evidently: Not installed
2024-12-09 13:55:23,064:INFO:               fugue: Not installed
2024-12-09 13:55:23,064:INFO:           streamlit: Not installed
2024-12-09 13:55:23,064:INFO:             prophet: Not installed
2024-12-09 13:55:23,064:INFO:None
2024-12-09 13:55:23,064:INFO:Set up data.
2024-12-09 13:55:23,070:INFO:Set up folding strategy.
2024-12-09 13:55:23,070:INFO:Set up train/test split.
2024-12-09 13:55:23,075:INFO:Set up index.
2024-12-09 13:55:23,075:INFO:Assigning column types.
2024-12-09 13:55:23,080:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-09 13:55:23,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 13:55:23,127:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:55:23,156:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:55:23,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:55:23,212:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 13:55:23,213:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:55:23,242:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:55:23,242:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:55:23,243:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-09 13:55:23,288:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:55:23,317:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:55:23,317:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:55:23,363:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:55:23,391:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:55:23,391:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:55:23,391:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-09 13:55:23,466:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:55:23,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:55:23,540:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:55:23,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:55:23,541:INFO:Preparing preprocessing pipeline...
2024-12-09 13:55:23,542:INFO:Set up simple imputation.
2024-12-09 13:55:23,546:INFO:Set up encoding of ordinal features.
2024-12-09 13:55:23,547:INFO:Set up encoding of categorical features.
2024-12-09 13:55:23,619:INFO:Finished creating preprocessing pipeline.
2024-12-09 13:55:23,636:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\EE715\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categ...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-12-09 13:55:23,636:INFO:Creating final display dataframe.
2024-12-09 13:55:23,839:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (623, 10)
6    Transformed test set shape         (268, 10)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              ee29
2024-12-09 13:55:23,917:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:55:23,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:55:23,989:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:55:23,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:55:23,990:INFO:setup() successfully completed in 0.94s...............
2024-12-09 13:55:23,990:INFO:Initializing compare_models()
2024-12-09 13:55:23,991:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['dummy'])
2024-12-09 13:55:23,991:INFO:Checking exceptions
2024-12-09 13:55:23,993:INFO:Preparing display monitor
2024-12-09 13:55:24,017:INFO:Initializing Logistic Regression
2024-12-09 13:55:24,017:INFO:Total runtime is 0.0 minutes
2024-12-09 13:55:24,021:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:24,022:INFO:Initializing create_model()
2024-12-09 13:55:24,022:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A086FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:24,023:INFO:Checking exceptions
2024-12-09 13:55:24,023:INFO:Importing libraries
2024-12-09 13:55:24,023:INFO:Copying training dataset
2024-12-09 13:55:24,030:INFO:Defining folds
2024-12-09 13:55:24,031:INFO:Declaring metric variables
2024-12-09 13:55:24,046:INFO:Importing untrained model
2024-12-09 13:55:24,062:INFO:Logistic Regression Imported successfully
2024-12-09 13:55:24,074:INFO:Starting cross validation
2024-12-09 13:55:24,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:24,456:INFO:Calculating mean and std
2024-12-09 13:55:24,457:INFO:Creating metrics dataframe
2024-12-09 13:55:24,460:INFO:Uploading results into container
2024-12-09 13:55:24,461:INFO:Uploading model into container now
2024-12-09 13:55:24,462:INFO:_master_model_container: 1
2024-12-09 13:55:24,462:INFO:_display_container: 2
2024-12-09 13:55:24,462:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 13:55:24,462:INFO:create_model() successfully completed......................................
2024-12-09 13:55:24,567:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:24,567:INFO:Creating metrics dataframe
2024-12-09 13:55:24,576:INFO:Initializing K Neighbors Classifier
2024-12-09 13:55:24,576:INFO:Total runtime is 0.009316086769104004 minutes
2024-12-09 13:55:24,580:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:24,580:INFO:Initializing create_model()
2024-12-09 13:55:24,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A086FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:24,580:INFO:Checking exceptions
2024-12-09 13:55:24,580:INFO:Importing libraries
2024-12-09 13:55:24,580:INFO:Copying training dataset
2024-12-09 13:55:24,584:INFO:Defining folds
2024-12-09 13:55:24,584:INFO:Declaring metric variables
2024-12-09 13:55:24,588:INFO:Importing untrained model
2024-12-09 13:55:24,591:INFO:K Neighbors Classifier Imported successfully
2024-12-09 13:55:24,603:INFO:Starting cross validation
2024-12-09 13:55:24,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:24,892:INFO:Calculating mean and std
2024-12-09 13:55:24,892:INFO:Creating metrics dataframe
2024-12-09 13:55:24,896:INFO:Uploading results into container
2024-12-09 13:55:24,896:INFO:Uploading model into container now
2024-12-09 13:55:24,897:INFO:_master_model_container: 2
2024-12-09 13:55:24,897:INFO:_display_container: 2
2024-12-09 13:55:24,897:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 13:55:24,897:INFO:create_model() successfully completed......................................
2024-12-09 13:55:24,999:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:24,999:INFO:Creating metrics dataframe
2024-12-09 13:55:25,009:INFO:Initializing Naive Bayes
2024-12-09 13:55:25,009:INFO:Total runtime is 0.016539212067921957 minutes
2024-12-09 13:55:25,013:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:25,013:INFO:Initializing create_model()
2024-12-09 13:55:25,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A086FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:25,013:INFO:Checking exceptions
2024-12-09 13:55:25,014:INFO:Importing libraries
2024-12-09 13:55:25,014:INFO:Copying training dataset
2024-12-09 13:55:25,018:INFO:Defining folds
2024-12-09 13:55:25,018:INFO:Declaring metric variables
2024-12-09 13:55:25,021:INFO:Importing untrained model
2024-12-09 13:55:25,028:INFO:Naive Bayes Imported successfully
2024-12-09 13:55:25,037:INFO:Starting cross validation
2024-12-09 13:55:25,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:25,267:INFO:Calculating mean and std
2024-12-09 13:55:25,268:INFO:Creating metrics dataframe
2024-12-09 13:55:25,271:INFO:Uploading results into container
2024-12-09 13:55:25,272:INFO:Uploading model into container now
2024-12-09 13:55:25,272:INFO:_master_model_container: 3
2024-12-09 13:55:25,272:INFO:_display_container: 2
2024-12-09 13:55:25,273:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 13:55:25,273:INFO:create_model() successfully completed......................................
2024-12-09 13:55:25,375:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:25,376:INFO:Creating metrics dataframe
2024-12-09 13:55:25,386:INFO:Initializing Decision Tree Classifier
2024-12-09 13:55:25,386:INFO:Total runtime is 0.02281226714452108 minutes
2024-12-09 13:55:25,389:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:25,389:INFO:Initializing create_model()
2024-12-09 13:55:25,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A086FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:25,390:INFO:Checking exceptions
2024-12-09 13:55:25,390:INFO:Importing libraries
2024-12-09 13:55:25,390:INFO:Copying training dataset
2024-12-09 13:55:25,394:INFO:Defining folds
2024-12-09 13:55:25,394:INFO:Declaring metric variables
2024-12-09 13:55:25,399:INFO:Importing untrained model
2024-12-09 13:55:25,404:INFO:Decision Tree Classifier Imported successfully
2024-12-09 13:55:25,412:INFO:Starting cross validation
2024-12-09 13:55:25,413:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:25,635:INFO:Calculating mean and std
2024-12-09 13:55:25,637:INFO:Creating metrics dataframe
2024-12-09 13:55:25,640:INFO:Uploading results into container
2024-12-09 13:55:25,640:INFO:Uploading model into container now
2024-12-09 13:55:25,640:INFO:_master_model_container: 4
2024-12-09 13:55:25,640:INFO:_display_container: 2
2024-12-09 13:55:25,641:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 13:55:25,641:INFO:create_model() successfully completed......................................
2024-12-09 13:55:25,748:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:25,748:INFO:Creating metrics dataframe
2024-12-09 13:55:25,760:INFO:Initializing SVM - Linear Kernel
2024-12-09 13:55:25,760:INFO:Total runtime is 0.029051677385965986 minutes
2024-12-09 13:55:25,767:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:25,768:INFO:Initializing create_model()
2024-12-09 13:55:25,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A086FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:25,768:INFO:Checking exceptions
2024-12-09 13:55:25,768:INFO:Importing libraries
2024-12-09 13:55:25,768:INFO:Copying training dataset
2024-12-09 13:55:25,772:INFO:Defining folds
2024-12-09 13:55:25,772:INFO:Declaring metric variables
2024-12-09 13:55:25,777:INFO:Importing untrained model
2024-12-09 13:55:25,786:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 13:55:25,794:INFO:Starting cross validation
2024-12-09 13:55:25,797:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:25,914:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:25,917:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:25,918:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:25,923:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:55:25,926:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:25,947:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:25,971:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:26,020:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:26,023:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:26,024:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:26,027:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:55:26,035:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:26,043:INFO:Calculating mean and std
2024-12-09 13:55:26,044:INFO:Creating metrics dataframe
2024-12-09 13:55:26,048:INFO:Uploading results into container
2024-12-09 13:55:26,048:INFO:Uploading model into container now
2024-12-09 13:55:26,049:INFO:_master_model_container: 5
2024-12-09 13:55:26,049:INFO:_display_container: 2
2024-12-09 13:55:26,049:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 13:55:26,050:INFO:create_model() successfully completed......................................
2024-12-09 13:55:26,153:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:26,153:INFO:Creating metrics dataframe
2024-12-09 13:55:26,164:INFO:Initializing Ridge Classifier
2024-12-09 13:55:26,164:INFO:Total runtime is 0.03577431440353394 minutes
2024-12-09 13:55:26,167:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:26,168:INFO:Initializing create_model()
2024-12-09 13:55:26,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A086FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:26,168:INFO:Checking exceptions
2024-12-09 13:55:26,168:INFO:Importing libraries
2024-12-09 13:55:26,168:INFO:Copying training dataset
2024-12-09 13:55:26,172:INFO:Defining folds
2024-12-09 13:55:26,172:INFO:Declaring metric variables
2024-12-09 13:55:26,176:INFO:Importing untrained model
2024-12-09 13:55:26,182:INFO:Ridge Classifier Imported successfully
2024-12-09 13:55:26,191:INFO:Starting cross validation
2024-12-09 13:55:26,192:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:26,320:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:26,324:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:26,338:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:26,350:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:26,353:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:26,365:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:26,425:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:26,425:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:26,438:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:26,445:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:26,453:INFO:Calculating mean and std
2024-12-09 13:55:26,454:INFO:Creating metrics dataframe
2024-12-09 13:55:26,457:INFO:Uploading results into container
2024-12-09 13:55:26,458:INFO:Uploading model into container now
2024-12-09 13:55:26,458:INFO:_master_model_container: 6
2024-12-09 13:55:26,458:INFO:_display_container: 2
2024-12-09 13:55:26,458:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 13:55:26,459:INFO:create_model() successfully completed......................................
2024-12-09 13:55:26,562:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:26,562:INFO:Creating metrics dataframe
2024-12-09 13:55:26,574:INFO:Initializing Random Forest Classifier
2024-12-09 13:55:26,574:INFO:Total runtime is 0.042615822950998944 minutes
2024-12-09 13:55:26,578:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:26,578:INFO:Initializing create_model()
2024-12-09 13:55:26,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A086FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:26,578:INFO:Checking exceptions
2024-12-09 13:55:26,578:INFO:Importing libraries
2024-12-09 13:55:26,578:INFO:Copying training dataset
2024-12-09 13:55:26,584:INFO:Defining folds
2024-12-09 13:55:26,585:INFO:Declaring metric variables
2024-12-09 13:55:26,589:INFO:Importing untrained model
2024-12-09 13:55:26,593:INFO:Random Forest Classifier Imported successfully
2024-12-09 13:55:26,602:INFO:Starting cross validation
2024-12-09 13:55:26,605:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:27,467:INFO:Calculating mean and std
2024-12-09 13:55:27,468:INFO:Creating metrics dataframe
2024-12-09 13:55:27,471:INFO:Uploading results into container
2024-12-09 13:55:27,472:INFO:Uploading model into container now
2024-12-09 13:55:27,472:INFO:_master_model_container: 7
2024-12-09 13:55:27,472:INFO:_display_container: 2
2024-12-09 13:55:27,472:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 13:55:27,472:INFO:create_model() successfully completed......................................
2024-12-09 13:55:27,569:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:27,569:INFO:Creating metrics dataframe
2024-12-09 13:55:27,581:INFO:Initializing Quadratic Discriminant Analysis
2024-12-09 13:55:27,581:INFO:Total runtime is 0.059403526782989505 minutes
2024-12-09 13:55:27,585:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:27,585:INFO:Initializing create_model()
2024-12-09 13:55:27,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A086FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:27,585:INFO:Checking exceptions
2024-12-09 13:55:27,585:INFO:Importing libraries
2024-12-09 13:55:27,585:INFO:Copying training dataset
2024-12-09 13:55:27,590:INFO:Defining folds
2024-12-09 13:55:27,590:INFO:Declaring metric variables
2024-12-09 13:55:27,594:INFO:Importing untrained model
2024-12-09 13:55:27,599:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 13:55:27,607:INFO:Starting cross validation
2024-12-09 13:55:27,609:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:27,685:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:27,686:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:27,687:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:27,689:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:27,690:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:27,701:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:27,777:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:27,778:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:27,781:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:27,818:INFO:Calculating mean and std
2024-12-09 13:55:27,820:INFO:Creating metrics dataframe
2024-12-09 13:55:27,823:INFO:Uploading results into container
2024-12-09 13:55:27,823:INFO:Uploading model into container now
2024-12-09 13:55:27,824:INFO:_master_model_container: 8
2024-12-09 13:55:27,824:INFO:_display_container: 2
2024-12-09 13:55:27,825:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 13:55:27,825:INFO:create_model() successfully completed......................................
2024-12-09 13:55:27,924:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:27,924:INFO:Creating metrics dataframe
2024-12-09 13:55:27,937:INFO:Initializing Ada Boost Classifier
2024-12-09 13:55:27,937:INFO:Total runtime is 0.0653239369392395 minutes
2024-12-09 13:55:27,941:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:27,941:INFO:Initializing create_model()
2024-12-09 13:55:27,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A086FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:27,941:INFO:Checking exceptions
2024-12-09 13:55:27,941:INFO:Importing libraries
2024-12-09 13:55:27,941:INFO:Copying training dataset
2024-12-09 13:55:27,945:INFO:Defining folds
2024-12-09 13:55:27,946:INFO:Declaring metric variables
2024-12-09 13:55:27,950:INFO:Importing untrained model
2024-12-09 13:55:27,954:INFO:Ada Boost Classifier Imported successfully
2024-12-09 13:55:27,961:INFO:Starting cross validation
2024-12-09 13:55:27,963:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:28,394:INFO:Calculating mean and std
2024-12-09 13:55:28,395:INFO:Creating metrics dataframe
2024-12-09 13:55:28,400:INFO:Uploading results into container
2024-12-09 13:55:28,400:INFO:Uploading model into container now
2024-12-09 13:55:28,401:INFO:_master_model_container: 9
2024-12-09 13:55:28,401:INFO:_display_container: 2
2024-12-09 13:55:28,402:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 13:55:28,402:INFO:create_model() successfully completed......................................
2024-12-09 13:55:28,501:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:28,501:INFO:Creating metrics dataframe
2024-12-09 13:55:28,512:INFO:Initializing Gradient Boosting Classifier
2024-12-09 13:55:28,513:INFO:Total runtime is 0.0749342401822408 minutes
2024-12-09 13:55:28,516:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:28,517:INFO:Initializing create_model()
2024-12-09 13:55:28,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A086FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:28,517:INFO:Checking exceptions
2024-12-09 13:55:28,517:INFO:Importing libraries
2024-12-09 13:55:28,517:INFO:Copying training dataset
2024-12-09 13:55:28,522:INFO:Defining folds
2024-12-09 13:55:28,522:INFO:Declaring metric variables
2024-12-09 13:55:28,525:INFO:Importing untrained model
2024-12-09 13:55:28,530:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 13:55:28,539:INFO:Starting cross validation
2024-12-09 13:55:28,541:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:28,955:INFO:Calculating mean and std
2024-12-09 13:55:28,956:INFO:Creating metrics dataframe
2024-12-09 13:55:28,959:INFO:Uploading results into container
2024-12-09 13:55:28,960:INFO:Uploading model into container now
2024-12-09 13:55:28,960:INFO:_master_model_container: 10
2024-12-09 13:55:28,961:INFO:_display_container: 2
2024-12-09 13:55:28,961:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 13:55:28,961:INFO:create_model() successfully completed......................................
2024-12-09 13:55:29,060:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:29,061:INFO:Creating metrics dataframe
2024-12-09 13:55:29,073:INFO:Initializing Linear Discriminant Analysis
2024-12-09 13:55:29,073:INFO:Total runtime is 0.08427140712738038 minutes
2024-12-09 13:55:29,077:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:29,077:INFO:Initializing create_model()
2024-12-09 13:55:29,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A086FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:29,077:INFO:Checking exceptions
2024-12-09 13:55:29,078:INFO:Importing libraries
2024-12-09 13:55:29,078:INFO:Copying training dataset
2024-12-09 13:55:29,083:INFO:Defining folds
2024-12-09 13:55:29,083:INFO:Declaring metric variables
2024-12-09 13:55:29,087:INFO:Importing untrained model
2024-12-09 13:55:29,091:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 13:55:29,101:INFO:Starting cross validation
2024-12-09 13:55:29,103:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:29,328:INFO:Calculating mean and std
2024-12-09 13:55:29,330:INFO:Creating metrics dataframe
2024-12-09 13:55:29,333:INFO:Uploading results into container
2024-12-09 13:55:29,334:INFO:Uploading model into container now
2024-12-09 13:55:29,334:INFO:_master_model_container: 11
2024-12-09 13:55:29,335:INFO:_display_container: 2
2024-12-09 13:55:29,335:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 13:55:29,335:INFO:create_model() successfully completed......................................
2024-12-09 13:55:29,437:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:29,437:INFO:Creating metrics dataframe
2024-12-09 13:55:29,450:INFO:Initializing Extra Trees Classifier
2024-12-09 13:55:29,452:INFO:Total runtime is 0.09057658116022746 minutes
2024-12-09 13:55:29,456:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:29,456:INFO:Initializing create_model()
2024-12-09 13:55:29,456:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A086FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:29,456:INFO:Checking exceptions
2024-12-09 13:55:29,456:INFO:Importing libraries
2024-12-09 13:55:29,456:INFO:Copying training dataset
2024-12-09 13:55:29,460:INFO:Defining folds
2024-12-09 13:55:29,460:INFO:Declaring metric variables
2024-12-09 13:55:29,465:INFO:Importing untrained model
2024-12-09 13:55:29,471:INFO:Extra Trees Classifier Imported successfully
2024-12-09 13:55:29,486:INFO:Starting cross validation
2024-12-09 13:55:29,488:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:30,257:INFO:Calculating mean and std
2024-12-09 13:55:30,258:INFO:Creating metrics dataframe
2024-12-09 13:55:30,261:INFO:Uploading results into container
2024-12-09 13:55:30,262:INFO:Uploading model into container now
2024-12-09 13:55:30,262:INFO:_master_model_container: 12
2024-12-09 13:55:30,262:INFO:_display_container: 2
2024-12-09 13:55:30,263:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 13:55:30,263:INFO:create_model() successfully completed......................................
2024-12-09 13:55:30,376:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:30,376:INFO:Creating metrics dataframe
2024-12-09 13:55:30,391:INFO:Initializing Light Gradient Boosting Machine
2024-12-09 13:55:30,392:INFO:Total runtime is 0.10624695221583048 minutes
2024-12-09 13:55:30,396:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:30,397:INFO:Initializing create_model()
2024-12-09 13:55:30,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A086FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:30,397:INFO:Checking exceptions
2024-12-09 13:55:30,397:INFO:Importing libraries
2024-12-09 13:55:30,397:INFO:Copying training dataset
2024-12-09 13:55:30,406:INFO:Defining folds
2024-12-09 13:55:30,407:INFO:Declaring metric variables
2024-12-09 13:55:30,412:INFO:Importing untrained model
2024-12-09 13:55:30,420:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:55:30,431:INFO:Starting cross validation
2024-12-09 13:55:30,432:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:31,569:INFO:Calculating mean and std
2024-12-09 13:55:31,570:INFO:Creating metrics dataframe
2024-12-09 13:55:31,574:INFO:Uploading results into container
2024-12-09 13:55:31,574:INFO:Uploading model into container now
2024-12-09 13:55:31,575:INFO:_master_model_container: 13
2024-12-09 13:55:31,575:INFO:_display_container: 2
2024-12-09 13:55:31,576:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:55:31,576:INFO:create_model() successfully completed......................................
2024-12-09 13:55:31,692:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:31,692:INFO:Creating metrics dataframe
2024-12-09 13:55:31,717:INFO:Initializing create_model()
2024-12-09 13:55:31,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:31,718:INFO:Checking exceptions
2024-12-09 13:55:31,721:INFO:Importing libraries
2024-12-09 13:55:31,721:INFO:Copying training dataset
2024-12-09 13:55:31,725:INFO:Defining folds
2024-12-09 13:55:31,725:INFO:Declaring metric variables
2024-12-09 13:55:31,725:INFO:Importing untrained model
2024-12-09 13:55:31,725:INFO:Declaring custom model
2024-12-09 13:55:31,726:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:55:31,727:INFO:Cross validation set to False
2024-12-09 13:55:31,727:INFO:Fitting Model
2024-12-09 13:55:31,817:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 13:55:31,818:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.
2024-12-09 13:55:31,818:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-12-09 13:55:31,818:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 13:55:31,818:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 13:55:31,819:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 13:55:31,819:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 13:55:31,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:31,880:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:55:31,880:INFO:create_model() successfully completed......................................
2024-12-09 13:55:31,987:INFO:Initializing create_model()
2024-12-09 13:55:31,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:31,987:INFO:Checking exceptions
2024-12-09 13:55:31,989:INFO:Importing libraries
2024-12-09 13:55:31,990:INFO:Copying training dataset
2024-12-09 13:55:31,993:INFO:Defining folds
2024-12-09 13:55:31,993:INFO:Declaring metric variables
2024-12-09 13:55:31,993:INFO:Importing untrained model
2024-12-09 13:55:31,993:INFO:Declaring custom model
2024-12-09 13:55:31,994:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 13:55:31,995:INFO:Cross validation set to False
2024-12-09 13:55:31,995:INFO:Fitting Model
2024-12-09 13:55:32,139:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 13:55:32,139:INFO:create_model() successfully completed......................................
2024-12-09 13:55:32,243:INFO:Initializing create_model()
2024-12-09 13:55:32,244:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:32,244:INFO:Checking exceptions
2024-12-09 13:55:32,246:INFO:Importing libraries
2024-12-09 13:55:32,246:INFO:Copying training dataset
2024-12-09 13:55:32,250:INFO:Defining folds
2024-12-09 13:55:32,250:INFO:Declaring metric variables
2024-12-09 13:55:32,250:INFO:Importing untrained model
2024-12-09 13:55:32,250:INFO:Declaring custom model
2024-12-09 13:55:32,251:INFO:Random Forest Classifier Imported successfully
2024-12-09 13:55:32,252:INFO:Cross validation set to False
2024-12-09 13:55:32,252:INFO:Fitting Model
2024-12-09 13:55:32,473:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 13:55:32,473:INFO:create_model() successfully completed......................................
2024-12-09 13:55:32,589:INFO:Initializing create_model()
2024-12-09 13:55:32,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:32,589:INFO:Checking exceptions
2024-12-09 13:55:32,592:INFO:Importing libraries
2024-12-09 13:55:32,592:INFO:Copying training dataset
2024-12-09 13:55:32,596:INFO:Defining folds
2024-12-09 13:55:32,596:INFO:Declaring metric variables
2024-12-09 13:55:32,597:INFO:Importing untrained model
2024-12-09 13:55:32,597:INFO:Declaring custom model
2024-12-09 13:55:32,597:INFO:Ada Boost Classifier Imported successfully
2024-12-09 13:55:32,598:INFO:Cross validation set to False
2024-12-09 13:55:32,598:INFO:Fitting Model
2024-12-09 13:55:32,726:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 13:55:32,726:INFO:create_model() successfully completed......................................
2024-12-09 13:55:32,838:INFO:Initializing create_model()
2024-12-09 13:55:32,839:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:32,839:INFO:Checking exceptions
2024-12-09 13:55:32,840:INFO:Importing libraries
2024-12-09 13:55:32,840:INFO:Copying training dataset
2024-12-09 13:55:32,844:INFO:Defining folds
2024-12-09 13:55:32,844:INFO:Declaring metric variables
2024-12-09 13:55:32,844:INFO:Importing untrained model
2024-12-09 13:55:32,845:INFO:Declaring custom model
2024-12-09 13:55:32,845:INFO:Logistic Regression Imported successfully
2024-12-09 13:55:32,846:INFO:Cross validation set to False
2024-12-09 13:55:32,846:INFO:Fitting Model
2024-12-09 13:55:32,930:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 13:55:32,930:INFO:create_model() successfully completed......................................
2024-12-09 13:55:33,032:INFO:Initializing create_model()
2024-12-09 13:55:33,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:33,033:INFO:Checking exceptions
2024-12-09 13:55:33,036:INFO:Importing libraries
2024-12-09 13:55:33,036:INFO:Copying training dataset
2024-12-09 13:55:33,041:INFO:Defining folds
2024-12-09 13:55:33,041:INFO:Declaring metric variables
2024-12-09 13:55:33,041:INFO:Importing untrained model
2024-12-09 13:55:33,041:INFO:Declaring custom model
2024-12-09 13:55:33,042:INFO:Extra Trees Classifier Imported successfully
2024-12-09 13:55:33,043:INFO:Cross validation set to False
2024-12-09 13:55:33,043:INFO:Fitting Model
2024-12-09 13:55:33,220:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 13:55:33,220:INFO:create_model() successfully completed......................................
2024-12-09 13:55:33,325:INFO:Initializing create_model()
2024-12-09 13:55:33,325:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:33,325:INFO:Checking exceptions
2024-12-09 13:55:33,327:INFO:Importing libraries
2024-12-09 13:55:33,327:INFO:Copying training dataset
2024-12-09 13:55:33,330:INFO:Defining folds
2024-12-09 13:55:33,330:INFO:Declaring metric variables
2024-12-09 13:55:33,330:INFO:Importing untrained model
2024-12-09 13:55:33,330:INFO:Declaring custom model
2024-12-09 13:55:33,331:INFO:Ridge Classifier Imported successfully
2024-12-09 13:55:33,332:INFO:Cross validation set to False
2024-12-09 13:55:33,332:INFO:Fitting Model
2024-12-09 13:55:33,380:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 13:55:33,380:INFO:create_model() successfully completed......................................
2024-12-09 13:55:33,490:INFO:Initializing create_model()
2024-12-09 13:55:33,490:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:33,490:INFO:Checking exceptions
2024-12-09 13:55:33,493:INFO:Importing libraries
2024-12-09 13:55:33,493:INFO:Copying training dataset
2024-12-09 13:55:33,496:INFO:Defining folds
2024-12-09 13:55:33,496:INFO:Declaring metric variables
2024-12-09 13:55:33,496:INFO:Importing untrained model
2024-12-09 13:55:33,496:INFO:Declaring custom model
2024-12-09 13:55:33,497:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 13:55:33,498:INFO:Cross validation set to False
2024-12-09 13:55:33,498:INFO:Fitting Model
2024-12-09 13:55:33,547:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 13:55:33,547:INFO:create_model() successfully completed......................................
2024-12-09 13:55:33,658:INFO:Initializing create_model()
2024-12-09 13:55:33,658:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:33,658:INFO:Checking exceptions
2024-12-09 13:55:33,660:INFO:Importing libraries
2024-12-09 13:55:33,661:INFO:Copying training dataset
2024-12-09 13:55:33,664:INFO:Defining folds
2024-12-09 13:55:33,664:INFO:Declaring metric variables
2024-12-09 13:55:33,664:INFO:Importing untrained model
2024-12-09 13:55:33,664:INFO:Declaring custom model
2024-12-09 13:55:33,665:INFO:Naive Bayes Imported successfully
2024-12-09 13:55:33,666:INFO:Cross validation set to False
2024-12-09 13:55:33,666:INFO:Fitting Model
2024-12-09 13:55:33,711:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 13:55:33,711:INFO:create_model() successfully completed......................................
2024-12-09 13:55:33,815:INFO:Initializing create_model()
2024-12-09 13:55:33,815:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:33,815:INFO:Checking exceptions
2024-12-09 13:55:33,818:INFO:Importing libraries
2024-12-09 13:55:33,818:INFO:Copying training dataset
2024-12-09 13:55:33,823:INFO:Defining folds
2024-12-09 13:55:33,823:INFO:Declaring metric variables
2024-12-09 13:55:33,823:INFO:Importing untrained model
2024-12-09 13:55:33,823:INFO:Declaring custom model
2024-12-09 13:55:33,824:INFO:Decision Tree Classifier Imported successfully
2024-12-09 13:55:33,825:INFO:Cross validation set to False
2024-12-09 13:55:33,825:INFO:Fitting Model
2024-12-09 13:55:33,871:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 13:55:33,871:INFO:create_model() successfully completed......................................
2024-12-09 13:55:33,974:INFO:Initializing create_model()
2024-12-09 13:55:33,974:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:33,974:INFO:Checking exceptions
2024-12-09 13:55:33,976:INFO:Importing libraries
2024-12-09 13:55:33,976:INFO:Copying training dataset
2024-12-09 13:55:33,979:INFO:Defining folds
2024-12-09 13:55:33,979:INFO:Declaring metric variables
2024-12-09 13:55:33,980:INFO:Importing untrained model
2024-12-09 13:55:33,980:INFO:Declaring custom model
2024-12-09 13:55:33,980:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 13:55:33,981:INFO:Cross validation set to False
2024-12-09 13:55:33,981:INFO:Fitting Model
2024-12-09 13:55:34,027:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:34,027:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 13:55:34,027:INFO:create_model() successfully completed......................................
2024-12-09 13:55:34,130:INFO:Initializing create_model()
2024-12-09 13:55:34,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:34,131:INFO:Checking exceptions
2024-12-09 13:55:34,133:INFO:Importing libraries
2024-12-09 13:55:34,133:INFO:Copying training dataset
2024-12-09 13:55:34,137:INFO:Defining folds
2024-12-09 13:55:34,138:INFO:Declaring metric variables
2024-12-09 13:55:34,138:INFO:Importing untrained model
2024-12-09 13:55:34,138:INFO:Declaring custom model
2024-12-09 13:55:34,139:INFO:K Neighbors Classifier Imported successfully
2024-12-09 13:55:34,141:INFO:Cross validation set to False
2024-12-09 13:55:34,141:INFO:Fitting Model
2024-12-09 13:55:34,186:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 13:55:34,186:INFO:create_model() successfully completed......................................
2024-12-09 13:55:34,292:INFO:Initializing create_model()
2024-12-09 13:55:34,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:34,293:INFO:Checking exceptions
2024-12-09 13:55:34,294:INFO:Importing libraries
2024-12-09 13:55:34,294:INFO:Copying training dataset
2024-12-09 13:55:34,298:INFO:Defining folds
2024-12-09 13:55:34,298:INFO:Declaring metric variables
2024-12-09 13:55:34,298:INFO:Importing untrained model
2024-12-09 13:55:34,298:INFO:Declaring custom model
2024-12-09 13:55:34,299:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 13:55:34,300:INFO:Cross validation set to False
2024-12-09 13:55:34,300:INFO:Fitting Model
2024-12-09 13:55:34,346:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 13:55:34,346:INFO:create_model() successfully completed......................................
2024-12-09 13:55:34,467:INFO:_master_model_container: 13
2024-12-09 13:55:34,467:INFO:_display_container: 2
2024-12-09 13:55:34,470:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-12-09 13:55:34,470:INFO:compare_models() successfully completed......................................
2024-12-09 13:55:34,474:INFO:Initializing finalize_model()
2024-12-09 13:55:34,474:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)], fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-09 13:55:34,477:INFO:Finalizing [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-12-09 13:55:34,482:INFO:Initializing create_model()
2024-12-09 13:55:34,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)], fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:34,482:INFO:Checking exceptions
2024-12-09 13:55:34,490:INFO:Initializing compare_models()
2024-12-09 13:55:34,490:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, 'include': None, 'exclude': ['dummy', [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['dummy', [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]])
2024-12-09 13:55:34,490:INFO:Checking exceptions
2024-12-09 13:55:34,492:INFO:Preparing display monitor
2024-12-09 13:55:34,522:INFO:Initializing Logistic Regression
2024-12-09 13:55:34,523:INFO:Total runtime is 1.647075017293294e-05 minutes
2024-12-09 13:55:34,528:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:34,529:INFO:Initializing create_model()
2024-12-09 13:55:34,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:34,529:INFO:Checking exceptions
2024-12-09 13:55:34,529:INFO:Importing libraries
2024-12-09 13:55:34,529:INFO:Copying training dataset
2024-12-09 13:55:34,534:INFO:Defining folds
2024-12-09 13:55:34,534:INFO:Declaring metric variables
2024-12-09 13:55:34,540:INFO:Importing untrained model
2024-12-09 13:55:34,549:INFO:Logistic Regression Imported successfully
2024-12-09 13:55:34,595:INFO:Starting cross validation
2024-12-09 13:55:34,597:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:34,922:INFO:Calculating mean and std
2024-12-09 13:55:34,922:INFO:Creating metrics dataframe
2024-12-09 13:55:34,925:INFO:Uploading results into container
2024-12-09 13:55:34,926:INFO:Uploading model into container now
2024-12-09 13:55:34,927:INFO:_master_model_container: 14
2024-12-09 13:55:34,927:INFO:_display_container: 3
2024-12-09 13:55:34,927:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 13:55:34,927:INFO:create_model() successfully completed......................................
2024-12-09 13:55:35,025:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:35,026:INFO:Creating metrics dataframe
2024-12-09 13:55:35,034:INFO:Initializing K Neighbors Classifier
2024-12-09 13:55:35,034:INFO:Total runtime is 0.008539823691050212 minutes
2024-12-09 13:55:35,038:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:35,039:INFO:Initializing create_model()
2024-12-09 13:55:35,039:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:35,039:INFO:Checking exceptions
2024-12-09 13:55:35,039:INFO:Importing libraries
2024-12-09 13:55:35,039:INFO:Copying training dataset
2024-12-09 13:55:35,043:INFO:Defining folds
2024-12-09 13:55:35,043:INFO:Declaring metric variables
2024-12-09 13:55:35,047:INFO:Importing untrained model
2024-12-09 13:55:35,051:INFO:K Neighbors Classifier Imported successfully
2024-12-09 13:55:35,060:INFO:Starting cross validation
2024-12-09 13:55:35,062:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:35,360:INFO:Calculating mean and std
2024-12-09 13:55:35,361:INFO:Creating metrics dataframe
2024-12-09 13:55:35,364:INFO:Uploading results into container
2024-12-09 13:55:35,365:INFO:Uploading model into container now
2024-12-09 13:55:35,365:INFO:_master_model_container: 15
2024-12-09 13:55:35,365:INFO:_display_container: 3
2024-12-09 13:55:35,365:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 13:55:35,366:INFO:create_model() successfully completed......................................
2024-12-09 13:55:35,462:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:35,462:INFO:Creating metrics dataframe
2024-12-09 13:55:35,471:INFO:Initializing Naive Bayes
2024-12-09 13:55:35,472:INFO:Total runtime is 0.015834438800811767 minutes
2024-12-09 13:55:35,475:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:35,475:INFO:Initializing create_model()
2024-12-09 13:55:35,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:35,475:INFO:Checking exceptions
2024-12-09 13:55:35,475:INFO:Importing libraries
2024-12-09 13:55:35,476:INFO:Copying training dataset
2024-12-09 13:55:35,479:INFO:Defining folds
2024-12-09 13:55:35,479:INFO:Declaring metric variables
2024-12-09 13:55:35,483:INFO:Importing untrained model
2024-12-09 13:55:35,488:INFO:Naive Bayes Imported successfully
2024-12-09 13:55:35,497:INFO:Starting cross validation
2024-12-09 13:55:35,498:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:35,730:INFO:Calculating mean and std
2024-12-09 13:55:35,731:INFO:Creating metrics dataframe
2024-12-09 13:55:35,735:INFO:Uploading results into container
2024-12-09 13:55:35,735:INFO:Uploading model into container now
2024-12-09 13:55:35,735:INFO:_master_model_container: 16
2024-12-09 13:55:35,735:INFO:_display_container: 3
2024-12-09 13:55:35,736:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 13:55:35,736:INFO:create_model() successfully completed......................................
2024-12-09 13:55:35,840:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:35,840:INFO:Creating metrics dataframe
2024-12-09 13:55:35,851:INFO:Initializing Decision Tree Classifier
2024-12-09 13:55:35,851:INFO:Total runtime is 0.02214857339859009 minutes
2024-12-09 13:55:35,855:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:35,856:INFO:Initializing create_model()
2024-12-09 13:55:35,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:35,856:INFO:Checking exceptions
2024-12-09 13:55:35,856:INFO:Importing libraries
2024-12-09 13:55:35,856:INFO:Copying training dataset
2024-12-09 13:55:35,861:INFO:Defining folds
2024-12-09 13:55:35,861:INFO:Declaring metric variables
2024-12-09 13:55:35,865:INFO:Importing untrained model
2024-12-09 13:55:35,869:INFO:Decision Tree Classifier Imported successfully
2024-12-09 13:55:35,879:INFO:Starting cross validation
2024-12-09 13:55:35,881:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:36,103:INFO:Calculating mean and std
2024-12-09 13:55:36,104:INFO:Creating metrics dataframe
2024-12-09 13:55:36,108:INFO:Uploading results into container
2024-12-09 13:55:36,108:INFO:Uploading model into container now
2024-12-09 13:55:36,109:INFO:_master_model_container: 17
2024-12-09 13:55:36,109:INFO:_display_container: 3
2024-12-09 13:55:36,110:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 13:55:36,110:INFO:create_model() successfully completed......................................
2024-12-09 13:55:36,211:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:36,211:INFO:Creating metrics dataframe
2024-12-09 13:55:36,221:INFO:Initializing SVM - Linear Kernel
2024-12-09 13:55:36,221:INFO:Total runtime is 0.028321011861165365 minutes
2024-12-09 13:55:36,226:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:36,226:INFO:Initializing create_model()
2024-12-09 13:55:36,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:36,226:INFO:Checking exceptions
2024-12-09 13:55:36,227:INFO:Importing libraries
2024-12-09 13:55:36,227:INFO:Copying training dataset
2024-12-09 13:55:36,231:INFO:Defining folds
2024-12-09 13:55:36,231:INFO:Declaring metric variables
2024-12-09 13:55:36,235:INFO:Importing untrained model
2024-12-09 13:55:36,240:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 13:55:36,248:INFO:Starting cross validation
2024-12-09 13:55:36,250:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:36,363:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:36,363:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:36,366:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:36,368:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:55:36,372:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:36,384:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:36,385:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:36,450:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:36,451:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:36,452:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:36,455:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:55:36,458:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:55:36,466:INFO:Calculating mean and std
2024-12-09 13:55:36,467:INFO:Creating metrics dataframe
2024-12-09 13:55:36,470:INFO:Uploading results into container
2024-12-09 13:55:36,471:INFO:Uploading model into container now
2024-12-09 13:55:36,472:INFO:_master_model_container: 18
2024-12-09 13:55:36,472:INFO:_display_container: 3
2024-12-09 13:55:36,473:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 13:55:36,474:INFO:create_model() successfully completed......................................
2024-12-09 13:55:36,573:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:36,573:INFO:Creating metrics dataframe
2024-12-09 13:55:36,583:INFO:Initializing Ridge Classifier
2024-12-09 13:55:36,584:INFO:Total runtime is 0.03436131874720256 minutes
2024-12-09 13:55:36,587:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:36,587:INFO:Initializing create_model()
2024-12-09 13:55:36,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:36,588:INFO:Checking exceptions
2024-12-09 13:55:36,588:INFO:Importing libraries
2024-12-09 13:55:36,588:INFO:Copying training dataset
2024-12-09 13:55:36,592:INFO:Defining folds
2024-12-09 13:55:36,592:INFO:Declaring metric variables
2024-12-09 13:55:36,595:INFO:Importing untrained model
2024-12-09 13:55:36,601:INFO:Ridge Classifier Imported successfully
2024-12-09 13:55:36,610:INFO:Starting cross validation
2024-12-09 13:55:36,612:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:36,726:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:36,729:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:36,736:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:36,744:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:36,745:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:36,756:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:36,820:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:36,822:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:36,833:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:36,836:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:55:36,844:INFO:Calculating mean and std
2024-12-09 13:55:36,845:INFO:Creating metrics dataframe
2024-12-09 13:55:36,850:INFO:Uploading results into container
2024-12-09 13:55:36,851:INFO:Uploading model into container now
2024-12-09 13:55:36,851:INFO:_master_model_container: 19
2024-12-09 13:55:36,851:INFO:_display_container: 3
2024-12-09 13:55:36,852:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 13:55:36,852:INFO:create_model() successfully completed......................................
2024-12-09 13:55:36,961:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:36,961:INFO:Creating metrics dataframe
2024-12-09 13:55:36,971:INFO:Initializing Random Forest Classifier
2024-12-09 13:55:36,971:INFO:Total runtime is 0.04082418282826742 minutes
2024-12-09 13:55:36,977:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:36,978:INFO:Initializing create_model()
2024-12-09 13:55:36,978:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:36,978:INFO:Checking exceptions
2024-12-09 13:55:36,978:INFO:Importing libraries
2024-12-09 13:55:36,978:INFO:Copying training dataset
2024-12-09 13:55:36,982:INFO:Defining folds
2024-12-09 13:55:36,983:INFO:Declaring metric variables
2024-12-09 13:55:36,987:INFO:Importing untrained model
2024-12-09 13:55:36,994:INFO:Random Forest Classifier Imported successfully
2024-12-09 13:55:37,001:INFO:Starting cross validation
2024-12-09 13:55:37,003:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:37,775:INFO:Calculating mean and std
2024-12-09 13:55:37,776:INFO:Creating metrics dataframe
2024-12-09 13:55:37,780:INFO:Uploading results into container
2024-12-09 13:55:37,780:INFO:Uploading model into container now
2024-12-09 13:55:37,780:INFO:_master_model_container: 20
2024-12-09 13:55:37,781:INFO:_display_container: 3
2024-12-09 13:55:37,781:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 13:55:37,782:INFO:create_model() successfully completed......................................
2024-12-09 13:55:37,920:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:37,921:INFO:Creating metrics dataframe
2024-12-09 13:55:37,932:INFO:Initializing Quadratic Discriminant Analysis
2024-12-09 13:55:37,932:INFO:Total runtime is 0.0568270246187846 minutes
2024-12-09 13:55:37,936:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:37,936:INFO:Initializing create_model()
2024-12-09 13:55:37,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:37,936:INFO:Checking exceptions
2024-12-09 13:55:37,936:INFO:Importing libraries
2024-12-09 13:55:37,936:INFO:Copying training dataset
2024-12-09 13:55:37,941:INFO:Defining folds
2024-12-09 13:55:37,941:INFO:Declaring metric variables
2024-12-09 13:55:37,945:INFO:Importing untrained model
2024-12-09 13:55:37,950:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 13:55:37,958:INFO:Starting cross validation
2024-12-09 13:55:37,960:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:38,036:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:38,038:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:38,045:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:38,046:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:38,049:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:38,050:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:38,134:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:38,134:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:38,144:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:38,151:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:55:38,188:INFO:Calculating mean and std
2024-12-09 13:55:38,190:INFO:Creating metrics dataframe
2024-12-09 13:55:38,193:INFO:Uploading results into container
2024-12-09 13:55:38,194:INFO:Uploading model into container now
2024-12-09 13:55:38,194:INFO:_master_model_container: 21
2024-12-09 13:55:38,195:INFO:_display_container: 3
2024-12-09 13:55:38,195:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 13:55:38,195:INFO:create_model() successfully completed......................................
2024-12-09 13:55:38,310:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:38,310:INFO:Creating metrics dataframe
2024-12-09 13:55:38,321:INFO:Initializing Ada Boost Classifier
2024-12-09 13:55:38,321:INFO:Total runtime is 0.06331748962402345 minutes
2024-12-09 13:55:38,325:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:38,325:INFO:Initializing create_model()
2024-12-09 13:55:38,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:38,326:INFO:Checking exceptions
2024-12-09 13:55:38,326:INFO:Importing libraries
2024-12-09 13:55:38,326:INFO:Copying training dataset
2024-12-09 13:55:38,330:INFO:Defining folds
2024-12-09 13:55:38,330:INFO:Declaring metric variables
2024-12-09 13:55:38,334:INFO:Importing untrained model
2024-12-09 13:55:38,339:INFO:Ada Boost Classifier Imported successfully
2024-12-09 13:55:38,349:INFO:Starting cross validation
2024-12-09 13:55:38,350:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:38,772:INFO:Calculating mean and std
2024-12-09 13:55:38,773:INFO:Creating metrics dataframe
2024-12-09 13:55:38,777:INFO:Uploading results into container
2024-12-09 13:55:38,778:INFO:Uploading model into container now
2024-12-09 13:55:38,778:INFO:_master_model_container: 22
2024-12-09 13:55:38,778:INFO:_display_container: 3
2024-12-09 13:55:38,779:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 13:55:38,779:INFO:create_model() successfully completed......................................
2024-12-09 13:55:38,885:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:38,885:INFO:Creating metrics dataframe
2024-12-09 13:55:38,897:INFO:Initializing Gradient Boosting Classifier
2024-12-09 13:55:38,897:INFO:Total runtime is 0.0729222059249878 minutes
2024-12-09 13:55:38,900:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:38,900:INFO:Initializing create_model()
2024-12-09 13:55:38,900:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:38,900:INFO:Checking exceptions
2024-12-09 13:55:38,900:INFO:Importing libraries
2024-12-09 13:55:38,901:INFO:Copying training dataset
2024-12-09 13:55:38,906:INFO:Defining folds
2024-12-09 13:55:38,906:INFO:Declaring metric variables
2024-12-09 13:55:38,910:INFO:Importing untrained model
2024-12-09 13:55:38,914:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 13:55:38,922:INFO:Starting cross validation
2024-12-09 13:55:38,923:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:39,354:INFO:Calculating mean and std
2024-12-09 13:55:39,355:INFO:Creating metrics dataframe
2024-12-09 13:55:39,358:INFO:Uploading results into container
2024-12-09 13:55:39,359:INFO:Uploading model into container now
2024-12-09 13:55:39,359:INFO:_master_model_container: 23
2024-12-09 13:55:39,359:INFO:_display_container: 3
2024-12-09 13:55:39,360:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 13:55:39,361:INFO:create_model() successfully completed......................................
2024-12-09 13:55:39,462:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:39,462:INFO:Creating metrics dataframe
2024-12-09 13:55:39,474:INFO:Initializing Linear Discriminant Analysis
2024-12-09 13:55:39,474:INFO:Total runtime is 0.08253742059071859 minutes
2024-12-09 13:55:39,477:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:39,478:INFO:Initializing create_model()
2024-12-09 13:55:39,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:39,478:INFO:Checking exceptions
2024-12-09 13:55:39,478:INFO:Importing libraries
2024-12-09 13:55:39,478:INFO:Copying training dataset
2024-12-09 13:55:39,482:INFO:Defining folds
2024-12-09 13:55:39,482:INFO:Declaring metric variables
2024-12-09 13:55:39,486:INFO:Importing untrained model
2024-12-09 13:55:39,491:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 13:55:39,500:INFO:Starting cross validation
2024-12-09 13:55:39,502:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:39,774:INFO:Calculating mean and std
2024-12-09 13:55:39,775:INFO:Creating metrics dataframe
2024-12-09 13:55:39,780:INFO:Uploading results into container
2024-12-09 13:55:39,781:INFO:Uploading model into container now
2024-12-09 13:55:39,781:INFO:_master_model_container: 24
2024-12-09 13:55:39,782:INFO:_display_container: 3
2024-12-09 13:55:39,782:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 13:55:39,782:INFO:create_model() successfully completed......................................
2024-12-09 13:55:39,892:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:39,892:INFO:Creating metrics dataframe
2024-12-09 13:55:39,904:INFO:Initializing Extra Trees Classifier
2024-12-09 13:55:39,904:INFO:Total runtime is 0.08969914118448893 minutes
2024-12-09 13:55:39,908:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:39,908:INFO:Initializing create_model()
2024-12-09 13:55:39,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:39,908:INFO:Checking exceptions
2024-12-09 13:55:39,908:INFO:Importing libraries
2024-12-09 13:55:39,908:INFO:Copying training dataset
2024-12-09 13:55:39,914:INFO:Defining folds
2024-12-09 13:55:39,914:INFO:Declaring metric variables
2024-12-09 13:55:39,917:INFO:Importing untrained model
2024-12-09 13:55:39,922:INFO:Extra Trees Classifier Imported successfully
2024-12-09 13:55:39,931:INFO:Starting cross validation
2024-12-09 13:55:39,932:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:40,590:INFO:Calculating mean and std
2024-12-09 13:55:40,591:INFO:Creating metrics dataframe
2024-12-09 13:55:40,595:INFO:Uploading results into container
2024-12-09 13:55:40,596:INFO:Uploading model into container now
2024-12-09 13:55:40,596:INFO:_master_model_container: 25
2024-12-09 13:55:40,596:INFO:_display_container: 3
2024-12-09 13:55:40,597:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 13:55:40,597:INFO:create_model() successfully completed......................................
2024-12-09 13:55:40,698:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:40,698:INFO:Creating metrics dataframe
2024-12-09 13:55:40,709:INFO:Initializing Light Gradient Boosting Machine
2024-12-09 13:55:40,710:INFO:Total runtime is 0.10313605467478434 minutes
2024-12-09 13:55:40,714:INFO:SubProcess create_model() called ==================================
2024-12-09 13:55:40,714:INFO:Initializing create_model()
2024-12-09 13:55:40,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E3A029C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:40,714:INFO:Checking exceptions
2024-12-09 13:55:40,714:INFO:Importing libraries
2024-12-09 13:55:40,714:INFO:Copying training dataset
2024-12-09 13:55:40,719:INFO:Defining folds
2024-12-09 13:55:40,719:INFO:Declaring metric variables
2024-12-09 13:55:40,723:INFO:Importing untrained model
2024-12-09 13:55:40,729:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:55:40,738:INFO:Starting cross validation
2024-12-09 13:55:40,740:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:55:41,509:INFO:Calculating mean and std
2024-12-09 13:55:41,519:INFO:Creating metrics dataframe
2024-12-09 13:55:41,523:INFO:Uploading results into container
2024-12-09 13:55:41,523:INFO:Uploading model into container now
2024-12-09 13:55:41,524:INFO:_master_model_container: 26
2024-12-09 13:55:41,524:INFO:_display_container: 3
2024-12-09 13:55:41,524:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:55:41,524:INFO:create_model() successfully completed......................................
2024-12-09 13:55:41,655:INFO:SubProcess create_model() end ==================================
2024-12-09 13:55:41,656:INFO:Creating metrics dataframe
2024-12-09 13:55:41,678:INFO:Initializing create_model()
2024-12-09 13:55:41,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:41,679:INFO:Checking exceptions
2024-12-09 13:55:41,682:INFO:Importing libraries
2024-12-09 13:55:41,682:INFO:Copying training dataset
2024-12-09 13:55:41,685:INFO:Defining folds
2024-12-09 13:55:41,685:INFO:Declaring metric variables
2024-12-09 13:55:41,686:INFO:Importing untrained model
2024-12-09 13:55:41,686:INFO:Declaring custom model
2024-12-09 13:55:41,686:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:55:41,687:INFO:Cross validation set to False
2024-12-09 13:55:41,687:INFO:Fitting Model
2024-12-09 13:55:41,739:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 13:55:41,740:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.
2024-12-09 13:55:41,740:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 13:55:41,740:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 13:55:41,740:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 13:55:41,740:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 13:55:41,740:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 13:55:41,740:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 13:55:41,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:41,774:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:55:41,774:INFO:create_model() successfully completed......................................
2024-12-09 13:55:41,904:INFO:_master_model_container: 26
2024-12-09 13:55:41,904:INFO:_display_container: 3
2024-12-09 13:55:41,905:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:55:41,905:INFO:compare_models() successfully completed......................................
2024-12-09 13:55:41,905:INFO:Initializing finalize_model()
2024-12-09 13:55:41,905:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-09 13:55:41,906:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:55:41,909:INFO:Initializing create_model()
2024-12-09 13:55:41,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:55:41,909:INFO:Checking exceptions
2024-12-09 13:55:41,912:INFO:Importing libraries
2024-12-09 13:55:41,912:INFO:Copying training dataset
2024-12-09 13:55:41,912:INFO:Defining folds
2024-12-09 13:55:41,912:INFO:Declaring metric variables
2024-12-09 13:55:41,913:INFO:Importing untrained model
2024-12-09 13:55:41,913:INFO:Declaring custom model
2024-12-09 13:55:41,914:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:55:41,915:INFO:Cross validation set to False
2024-12-09 13:55:41,915:INFO:Fitting Model
2024-12-09 13:55:41,984:INFO:[LightGBM] [Info] Number of positive: 342, number of negative: 549
2024-12-09 13:55:41,984:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000113 seconds.
2024-12-09 13:55:41,985:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 13:55:41,985:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 13:55:41,985:INFO:[LightGBM] [Info] Total Bins 224
2024-12-09 13:55:41,985:INFO:[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 9
2024-12-09 13:55:41,985:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288
2024-12-09 13:55:41,985:INFO:[LightGBM] [Info] Start training from score -0.473288
2024-12-09 13:55:41,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:55:42,060:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-09 13:55:42,060:INFO:create_model() successfully completed......................................
2024-12-09 13:55:42,158:INFO:_master_model_container: 26
2024-12-09 13:55:42,158:INFO:_display_container: 3
2024-12-09 13:55:42,177:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-09 13:55:42,177:INFO:finalize_model() successfully completed......................................
2024-12-09 13:55:42,295:INFO:Initializing predict_model()
2024-12-09 13:55:42,295:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025E39E9C820>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025E3315F040>)
2024-12-09 13:55:42,295:INFO:Checking exceptions
2024-12-09 13:55:42,295:INFO:Preloading libraries
2024-12-09 13:55:42,297:INFO:Set up data.
2024-12-09 13:55:42,300:INFO:Set up index.
2024-12-09 13:58:50,920:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 13:58:50,920:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 13:58:50,920:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 13:58:50,920:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 13:58:51,343:INFO:PyCaret ClassificationExperiment
2024-12-09 13:58:51,343:INFO:Logging name: clf-default-name
2024-12-09 13:58:51,343:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-09 13:58:51,343:INFO:version 3.2.0
2024-12-09 13:58:51,343:INFO:Initializing setup()
2024-12-09 13:58:51,343:INFO:self.USI: 747a
2024-12-09 13:58:51,343:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'pipeline', 'X_test', 'html_param', '_ml_usecase', 'seed', 'gpu_param', '_available_plots', 'X', 'X_train', 'fold_shuffle_param', 'y_test', 'log_plots_param', 'y', 'gpu_n_jobs_param', 'target_param', 'USI', 'fix_imbalance', 'n_jobs_param', 'idx', 'logging_param', 'exp_id', 'memory', 'data', 'fold_generator', 'y_train', 'exp_name_log'}
2024-12-09 13:58:51,343:INFO:Checking environment
2024-12-09 13:58:51,343:INFO:python_version: 3.8.20
2024-12-09 13:58:51,343:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2024-12-09 13:58:51,343:INFO:machine: AMD64
2024-12-09 13:58:51,343:INFO:platform: Windows-10-10.0.19041-SP0
2024-12-09 13:58:51,346:INFO:Memory: svmem(total=17054896128, available=5473128448, percent=67.9, used=11581767680, free=5473128448)
2024-12-09 13:58:51,346:INFO:Physical Core: 6
2024-12-09 13:58:51,346:INFO:Logical Core: 6
2024-12-09 13:58:51,346:INFO:Checking libraries
2024-12-09 13:58:51,346:INFO:System:
2024-12-09 13:58:51,346:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2024-12-09 13:58:51,346:INFO:executable: c:\Users\EE715\anaconda3\envs\gym-env\python.exe
2024-12-09 13:58:51,346:INFO:   machine: Windows-10-10.0.19041-SP0
2024-12-09 13:58:51,346:INFO:PyCaret required dependencies:
2024-12-09 13:58:51,368:INFO:                 pip: 24.2
2024-12-09 13:58:51,368:INFO:          setuptools: 75.1.0
2024-12-09 13:58:51,368:INFO:             pycaret: 3.2.0
2024-12-09 13:58:51,368:INFO:             IPython: 8.12.3
2024-12-09 13:58:51,368:INFO:          ipywidgets: 8.1.5
2024-12-09 13:58:51,368:INFO:                tqdm: 4.67.1
2024-12-09 13:58:51,368:INFO:               numpy: 1.24.4
2024-12-09 13:58:51,368:INFO:              pandas: 1.5.3
2024-12-09 13:58:51,368:INFO:              jinja2: 3.1.4
2024-12-09 13:58:51,368:INFO:               scipy: 1.10.1
2024-12-09 13:58:51,368:INFO:              joblib: 1.2.0
2024-12-09 13:58:51,368:INFO:             sklearn: 1.2.2
2024-12-09 13:58:51,368:INFO:                pyod: 2.0.2
2024-12-09 13:58:51,368:INFO:            imblearn: 0.12.4
2024-12-09 13:58:51,368:INFO:   category_encoders: 2.6.4
2024-12-09 13:58:51,368:INFO:            lightgbm: 4.5.0
2024-12-09 13:58:51,368:INFO:               numba: 0.58.1
2024-12-09 13:58:51,368:INFO:            requests: 2.32.3
2024-12-09 13:58:51,369:INFO:          matplotlib: 3.6.0
2024-12-09 13:58:51,369:INFO:          scikitplot: 0.3.7
2024-12-09 13:58:51,369:INFO:         yellowbrick: 1.5
2024-12-09 13:58:51,369:INFO:              plotly: 5.24.1
2024-12-09 13:58:51,369:INFO:    plotly-resampler: Not installed
2024-12-09 13:58:51,369:INFO:             kaleido: 0.2.1
2024-12-09 13:58:51,369:INFO:           schemdraw: 0.15
2024-12-09 13:58:51,369:INFO:         statsmodels: 0.14.1
2024-12-09 13:58:51,369:INFO:              sktime: 0.21.1
2024-12-09 13:58:51,369:INFO:               tbats: 1.1.3
2024-12-09 13:58:51,369:INFO:            pmdarima: 2.0.4
2024-12-09 13:58:51,369:INFO:              psutil: 6.1.0
2024-12-09 13:58:51,369:INFO:          markupsafe: 2.1.5
2024-12-09 13:58:51,369:INFO:             pickle5: Not installed
2024-12-09 13:58:51,369:INFO:         cloudpickle: 3.1.0
2024-12-09 13:58:51,369:INFO:         deprecation: 2.1.0
2024-12-09 13:58:51,369:INFO:              xxhash: 3.5.0
2024-12-09 13:58:51,369:INFO:           wurlitzer: Not installed
2024-12-09 13:58:51,369:INFO:PyCaret optional dependencies:
2024-12-09 13:58:51,384:INFO:                shap: Not installed
2024-12-09 13:58:51,384:INFO:           interpret: Not installed
2024-12-09 13:58:51,384:INFO:                umap: Not installed
2024-12-09 13:58:51,384:INFO:     ydata_profiling: Not installed
2024-12-09 13:58:51,384:INFO:  explainerdashboard: Not installed
2024-12-09 13:58:51,384:INFO:             autoviz: Not installed
2024-12-09 13:58:51,384:INFO:           fairlearn: Not installed
2024-12-09 13:58:51,384:INFO:          deepchecks: Not installed
2024-12-09 13:58:51,384:INFO:             xgboost: Not installed
2024-12-09 13:58:51,384:INFO:            catboost: Not installed
2024-12-09 13:58:51,384:INFO:              kmodes: Not installed
2024-12-09 13:58:51,384:INFO:             mlxtend: Not installed
2024-12-09 13:58:51,384:INFO:       statsforecast: Not installed
2024-12-09 13:58:51,385:INFO:        tune_sklearn: Not installed
2024-12-09 13:58:51,385:INFO:                 ray: Not installed
2024-12-09 13:58:51,385:INFO:            hyperopt: Not installed
2024-12-09 13:58:51,385:INFO:              optuna: 4.1.0
2024-12-09 13:58:51,385:INFO:               skopt: Not installed
2024-12-09 13:58:51,385:INFO:              mlflow: Not installed
2024-12-09 13:58:51,385:INFO:              gradio: Not installed
2024-12-09 13:58:51,385:INFO:             fastapi: Not installed
2024-12-09 13:58:51,385:INFO:             uvicorn: Not installed
2024-12-09 13:58:51,385:INFO:              m2cgen: Not installed
2024-12-09 13:58:51,385:INFO:           evidently: Not installed
2024-12-09 13:58:51,385:INFO:               fugue: Not installed
2024-12-09 13:58:51,385:INFO:           streamlit: Not installed
2024-12-09 13:58:51,385:INFO:             prophet: Not installed
2024-12-09 13:58:51,385:INFO:None
2024-12-09 13:58:51,385:INFO:Set up data.
2024-12-09 13:58:51,392:INFO:Set up folding strategy.
2024-12-09 13:58:51,392:INFO:Set up train/test split.
2024-12-09 13:58:51,397:INFO:Set up index.
2024-12-09 13:58:51,397:INFO:Assigning column types.
2024-12-09 13:58:51,400:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-09 13:58:51,439:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 13:58:51,441:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:58:51,475:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:58:51,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:58:51,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 13:58:51,517:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:58:51,541:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:58:51,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:58:51,542:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-09 13:58:51,582:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:58:51,608:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:58:51,608:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:58:51,649:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 13:58:51,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:58:51,674:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:58:51,674:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-09 13:58:51,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:58:51,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:58:51,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:58:51,803:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:58:51,805:INFO:Preparing preprocessing pipeline...
2024-12-09 13:58:51,806:INFO:Set up simple imputation.
2024-12-09 13:58:51,809:INFO:Set up encoding of ordinal features.
2024-12-09 13:58:51,810:INFO:Set up encoding of categorical features.
2024-12-09 13:58:51,879:INFO:Finished creating preprocessing pipeline.
2024-12-09 13:58:51,898:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\EE715\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categ...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-12-09 13:58:51,899:INFO:Creating final display dataframe.
2024-12-09 13:58:52,110:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (623, 10)
6    Transformed test set shape         (268, 10)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              747a
2024-12-09 13:58:52,189:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:58:52,190:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:58:52,258:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:58:52,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 13:58:52,259:INFO:setup() successfully completed in 0.92s...............
2024-12-09 13:58:52,259:INFO:Initializing compare_models()
2024-12-09 13:58:52,259:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-12-09 13:58:52,260:INFO:Checking exceptions
2024-12-09 13:58:52,262:INFO:Preparing display monitor
2024-12-09 13:58:52,294:INFO:Initializing Logistic Regression
2024-12-09 13:58:52,294:INFO:Total runtime is 0.0 minutes
2024-12-09 13:58:52,302:INFO:SubProcess create_model() called ==================================
2024-12-09 13:58:52,303:INFO:Initializing create_model()
2024-12-09 13:58:52,303:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE7A3C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:58:52,304:INFO:Checking exceptions
2024-12-09 13:58:52,304:INFO:Importing libraries
2024-12-09 13:58:52,304:INFO:Copying training dataset
2024-12-09 13:58:52,310:INFO:Defining folds
2024-12-09 13:58:52,310:INFO:Declaring metric variables
2024-12-09 13:58:52,314:INFO:Importing untrained model
2024-12-09 13:58:52,322:INFO:Logistic Regression Imported successfully
2024-12-09 13:58:52,351:INFO:Starting cross validation
2024-12-09 13:58:52,357:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:58:57,041:INFO:Calculating mean and std
2024-12-09 13:58:57,042:INFO:Creating metrics dataframe
2024-12-09 13:58:57,046:INFO:Uploading results into container
2024-12-09 13:58:57,046:INFO:Uploading model into container now
2024-12-09 13:58:57,046:INFO:_master_model_container: 1
2024-12-09 13:58:57,047:INFO:_display_container: 2
2024-12-09 13:58:57,047:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 13:58:57,047:INFO:create_model() successfully completed......................................
2024-12-09 13:58:57,110:INFO:SubProcess create_model() end ==================================
2024-12-09 13:58:57,110:INFO:Creating metrics dataframe
2024-12-09 13:58:57,120:INFO:Initializing K Neighbors Classifier
2024-12-09 13:58:57,121:INFO:Total runtime is 0.08044538497924805 minutes
2024-12-09 13:58:57,124:INFO:SubProcess create_model() called ==================================
2024-12-09 13:58:57,125:INFO:Initializing create_model()
2024-12-09 13:58:57,125:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE7A3C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:58:57,125:INFO:Checking exceptions
2024-12-09 13:58:57,125:INFO:Importing libraries
2024-12-09 13:58:57,125:INFO:Copying training dataset
2024-12-09 13:58:57,129:INFO:Defining folds
2024-12-09 13:58:57,129:INFO:Declaring metric variables
2024-12-09 13:58:57,132:INFO:Importing untrained model
2024-12-09 13:58:57,136:INFO:K Neighbors Classifier Imported successfully
2024-12-09 13:58:57,145:INFO:Starting cross validation
2024-12-09 13:58:57,147:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:58:57,479:INFO:Calculating mean and std
2024-12-09 13:58:57,480:INFO:Creating metrics dataframe
2024-12-09 13:58:57,483:INFO:Uploading results into container
2024-12-09 13:58:57,484:INFO:Uploading model into container now
2024-12-09 13:58:57,484:INFO:_master_model_container: 2
2024-12-09 13:58:57,484:INFO:_display_container: 2
2024-12-09 13:58:57,484:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 13:58:57,484:INFO:create_model() successfully completed......................................
2024-12-09 13:58:57,552:INFO:SubProcess create_model() end ==================================
2024-12-09 13:58:57,552:INFO:Creating metrics dataframe
2024-12-09 13:58:57,562:INFO:Initializing Naive Bayes
2024-12-09 13:58:57,562:INFO:Total runtime is 0.08780964215596518 minutes
2024-12-09 13:58:57,565:INFO:SubProcess create_model() called ==================================
2024-12-09 13:58:57,565:INFO:Initializing create_model()
2024-12-09 13:58:57,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE7A3C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:58:57,567:INFO:Checking exceptions
2024-12-09 13:58:57,567:INFO:Importing libraries
2024-12-09 13:58:57,567:INFO:Copying training dataset
2024-12-09 13:58:57,571:INFO:Defining folds
2024-12-09 13:58:57,571:INFO:Declaring metric variables
2024-12-09 13:58:57,575:INFO:Importing untrained model
2024-12-09 13:58:57,579:INFO:Naive Bayes Imported successfully
2024-12-09 13:58:57,589:INFO:Starting cross validation
2024-12-09 13:58:57,591:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:58:57,835:INFO:Calculating mean and std
2024-12-09 13:58:57,836:INFO:Creating metrics dataframe
2024-12-09 13:58:57,840:INFO:Uploading results into container
2024-12-09 13:58:57,840:INFO:Uploading model into container now
2024-12-09 13:58:57,841:INFO:_master_model_container: 3
2024-12-09 13:58:57,841:INFO:_display_container: 2
2024-12-09 13:58:57,841:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 13:58:57,841:INFO:create_model() successfully completed......................................
2024-12-09 13:58:57,907:INFO:SubProcess create_model() end ==================================
2024-12-09 13:58:57,907:INFO:Creating metrics dataframe
2024-12-09 13:58:57,920:INFO:Initializing Decision Tree Classifier
2024-12-09 13:58:57,920:INFO:Total runtime is 0.0937771240870158 minutes
2024-12-09 13:58:57,926:INFO:SubProcess create_model() called ==================================
2024-12-09 13:58:57,927:INFO:Initializing create_model()
2024-12-09 13:58:57,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE7A3C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:58:57,927:INFO:Checking exceptions
2024-12-09 13:58:57,928:INFO:Importing libraries
2024-12-09 13:58:57,928:INFO:Copying training dataset
2024-12-09 13:58:57,933:INFO:Defining folds
2024-12-09 13:58:57,933:INFO:Declaring metric variables
2024-12-09 13:58:57,937:INFO:Importing untrained model
2024-12-09 13:58:57,942:INFO:Decision Tree Classifier Imported successfully
2024-12-09 13:58:57,953:INFO:Starting cross validation
2024-12-09 13:58:57,954:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:58:58,221:INFO:Calculating mean and std
2024-12-09 13:58:58,222:INFO:Creating metrics dataframe
2024-12-09 13:58:58,227:INFO:Uploading results into container
2024-12-09 13:58:58,227:INFO:Uploading model into container now
2024-12-09 13:58:58,228:INFO:_master_model_container: 4
2024-12-09 13:58:58,228:INFO:_display_container: 2
2024-12-09 13:58:58,228:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 13:58:58,229:INFO:create_model() successfully completed......................................
2024-12-09 13:58:58,303:INFO:SubProcess create_model() end ==================================
2024-12-09 13:58:58,303:INFO:Creating metrics dataframe
2024-12-09 13:58:58,314:INFO:Initializing SVM - Linear Kernel
2024-12-09 13:58:58,315:INFO:Total runtime is 0.10035939613978069 minutes
2024-12-09 13:58:58,318:INFO:SubProcess create_model() called ==================================
2024-12-09 13:58:58,319:INFO:Initializing create_model()
2024-12-09 13:58:58,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE7A3C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:58:58,319:INFO:Checking exceptions
2024-12-09 13:58:58,319:INFO:Importing libraries
2024-12-09 13:58:58,319:INFO:Copying training dataset
2024-12-09 13:58:58,324:INFO:Defining folds
2024-12-09 13:58:58,324:INFO:Declaring metric variables
2024-12-09 13:58:58,327:INFO:Importing untrained model
2024-12-09 13:58:58,333:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 13:58:58,346:INFO:Starting cross validation
2024-12-09 13:58:58,347:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:58:58,497:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:58:58,499:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:58:58,508:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:58:58,515:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:58:58,532:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:58:58,569:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:58:58,600:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:58:58,612:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:58:58,625:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:58:58,653:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:58:58,660:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:58:58,676:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 13:58:58,684:INFO:Calculating mean and std
2024-12-09 13:58:58,684:INFO:Creating metrics dataframe
2024-12-09 13:58:58,689:INFO:Uploading results into container
2024-12-09 13:58:58,692:INFO:Uploading model into container now
2024-12-09 13:58:58,693:INFO:_master_model_container: 5
2024-12-09 13:58:58,693:INFO:_display_container: 2
2024-12-09 13:58:58,694:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 13:58:58,694:INFO:create_model() successfully completed......................................
2024-12-09 13:58:58,764:INFO:SubProcess create_model() end ==================================
2024-12-09 13:58:58,765:INFO:Creating metrics dataframe
2024-12-09 13:58:58,776:INFO:Initializing Ridge Classifier
2024-12-09 13:58:58,776:INFO:Total runtime is 0.10804463624954225 minutes
2024-12-09 13:58:58,780:INFO:SubProcess create_model() called ==================================
2024-12-09 13:58:58,781:INFO:Initializing create_model()
2024-12-09 13:58:58,781:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE7A3C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:58:58,781:INFO:Checking exceptions
2024-12-09 13:58:58,781:INFO:Importing libraries
2024-12-09 13:58:58,781:INFO:Copying training dataset
2024-12-09 13:58:58,785:INFO:Defining folds
2024-12-09 13:58:58,785:INFO:Declaring metric variables
2024-12-09 13:58:58,789:INFO:Importing untrained model
2024-12-09 13:58:58,794:INFO:Ridge Classifier Imported successfully
2024-12-09 13:58:58,805:INFO:Starting cross validation
2024-12-09 13:58:58,806:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:58:58,922:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:58:58,922:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:58:58,962:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:58:58,968:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:58:58,986:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:58:58,996:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:58:59,029:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:58:59,035:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:58:59,063:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:58:59,084:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 13:58:59,092:INFO:Calculating mean and std
2024-12-09 13:58:59,093:INFO:Creating metrics dataframe
2024-12-09 13:58:59,096:INFO:Uploading results into container
2024-12-09 13:58:59,097:INFO:Uploading model into container now
2024-12-09 13:58:59,097:INFO:_master_model_container: 6
2024-12-09 13:58:59,098:INFO:_display_container: 2
2024-12-09 13:58:59,098:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 13:58:59,098:INFO:create_model() successfully completed......................................
2024-12-09 13:58:59,162:INFO:SubProcess create_model() end ==================================
2024-12-09 13:58:59,162:INFO:Creating metrics dataframe
2024-12-09 13:58:59,173:INFO:Initializing Random Forest Classifier
2024-12-09 13:58:59,173:INFO:Total runtime is 0.11465365091959637 minutes
2024-12-09 13:58:59,178:INFO:SubProcess create_model() called ==================================
2024-12-09 13:58:59,178:INFO:Initializing create_model()
2024-12-09 13:58:59,178:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE7A3C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:58:59,178:INFO:Checking exceptions
2024-12-09 13:58:59,178:INFO:Importing libraries
2024-12-09 13:58:59,178:INFO:Copying training dataset
2024-12-09 13:58:59,182:INFO:Defining folds
2024-12-09 13:58:59,182:INFO:Declaring metric variables
2024-12-09 13:58:59,185:INFO:Importing untrained model
2024-12-09 13:58:59,191:INFO:Random Forest Classifier Imported successfully
2024-12-09 13:58:59,200:INFO:Starting cross validation
2024-12-09 13:58:59,202:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:59:00,238:INFO:Calculating mean and std
2024-12-09 13:59:00,239:INFO:Creating metrics dataframe
2024-12-09 13:59:00,242:INFO:Uploading results into container
2024-12-09 13:59:00,243:INFO:Uploading model into container now
2024-12-09 13:59:00,244:INFO:_master_model_container: 7
2024-12-09 13:59:00,244:INFO:_display_container: 2
2024-12-09 13:59:00,244:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 13:59:00,245:INFO:create_model() successfully completed......................................
2024-12-09 13:59:00,320:INFO:SubProcess create_model() end ==================================
2024-12-09 13:59:00,321:INFO:Creating metrics dataframe
2024-12-09 13:59:00,336:INFO:Initializing Quadratic Discriminant Analysis
2024-12-09 13:59:00,336:INFO:Total runtime is 0.13404368162155153 minutes
2024-12-09 13:59:00,341:INFO:SubProcess create_model() called ==================================
2024-12-09 13:59:00,341:INFO:Initializing create_model()
2024-12-09 13:59:00,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE7A3C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:59:00,343:INFO:Checking exceptions
2024-12-09 13:59:00,343:INFO:Importing libraries
2024-12-09 13:59:00,343:INFO:Copying training dataset
2024-12-09 13:59:00,349:INFO:Defining folds
2024-12-09 13:59:00,349:INFO:Declaring metric variables
2024-12-09 13:59:00,354:INFO:Importing untrained model
2024-12-09 13:59:00,359:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 13:59:00,368:INFO:Starting cross validation
2024-12-09 13:59:00,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:59:00,468:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:59:00,471:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:59:00,472:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:59:00,488:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:59:00,506:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:59:00,507:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:59:00,588:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:59:00,591:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:59:00,595:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:59:00,607:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 13:59:00,656:INFO:Calculating mean and std
2024-12-09 13:59:00,657:INFO:Creating metrics dataframe
2024-12-09 13:59:00,661:INFO:Uploading results into container
2024-12-09 13:59:00,662:INFO:Uploading model into container now
2024-12-09 13:59:00,662:INFO:_master_model_container: 8
2024-12-09 13:59:00,662:INFO:_display_container: 2
2024-12-09 13:59:00,663:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 13:59:00,663:INFO:create_model() successfully completed......................................
2024-12-09 13:59:00,736:INFO:SubProcess create_model() end ==================================
2024-12-09 13:59:00,737:INFO:Creating metrics dataframe
2024-12-09 13:59:00,752:INFO:Initializing Ada Boost Classifier
2024-12-09 13:59:00,752:INFO:Total runtime is 0.1409639835357666 minutes
2024-12-09 13:59:00,758:INFO:SubProcess create_model() called ==================================
2024-12-09 13:59:00,758:INFO:Initializing create_model()
2024-12-09 13:59:00,758:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE7A3C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:59:00,758:INFO:Checking exceptions
2024-12-09 13:59:00,758:INFO:Importing libraries
2024-12-09 13:59:00,758:INFO:Copying training dataset
2024-12-09 13:59:00,766:INFO:Defining folds
2024-12-09 13:59:00,766:INFO:Declaring metric variables
2024-12-09 13:59:00,772:INFO:Importing untrained model
2024-12-09 13:59:00,778:INFO:Ada Boost Classifier Imported successfully
2024-12-09 13:59:00,791:INFO:Starting cross validation
2024-12-09 13:59:00,795:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:59:01,571:INFO:Calculating mean and std
2024-12-09 13:59:01,572:INFO:Creating metrics dataframe
2024-12-09 13:59:01,576:INFO:Uploading results into container
2024-12-09 13:59:01,577:INFO:Uploading model into container now
2024-12-09 13:59:01,577:INFO:_master_model_container: 9
2024-12-09 13:59:01,577:INFO:_display_container: 2
2024-12-09 13:59:01,578:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 13:59:01,578:INFO:create_model() successfully completed......................................
2024-12-09 13:59:01,642:INFO:SubProcess create_model() end ==================================
2024-12-09 13:59:01,642:INFO:Creating metrics dataframe
2024-12-09 13:59:01,656:INFO:Initializing Gradient Boosting Classifier
2024-12-09 13:59:01,656:INFO:Total runtime is 0.15602848529815674 minutes
2024-12-09 13:59:01,659:INFO:SubProcess create_model() called ==================================
2024-12-09 13:59:01,659:INFO:Initializing create_model()
2024-12-09 13:59:01,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE7A3C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:59:01,659:INFO:Checking exceptions
2024-12-09 13:59:01,659:INFO:Importing libraries
2024-12-09 13:59:01,660:INFO:Copying training dataset
2024-12-09 13:59:01,665:INFO:Defining folds
2024-12-09 13:59:01,665:INFO:Declaring metric variables
2024-12-09 13:59:01,668:INFO:Importing untrained model
2024-12-09 13:59:01,671:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 13:59:01,680:INFO:Starting cross validation
2024-12-09 13:59:01,684:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:59:02,307:INFO:Calculating mean and std
2024-12-09 13:59:02,308:INFO:Creating metrics dataframe
2024-12-09 13:59:02,311:INFO:Uploading results into container
2024-12-09 13:59:02,312:INFO:Uploading model into container now
2024-12-09 13:59:02,313:INFO:_master_model_container: 10
2024-12-09 13:59:02,313:INFO:_display_container: 2
2024-12-09 13:59:02,314:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 13:59:02,314:INFO:create_model() successfully completed......................................
2024-12-09 13:59:02,388:INFO:SubProcess create_model() end ==================================
2024-12-09 13:59:02,388:INFO:Creating metrics dataframe
2024-12-09 13:59:02,402:INFO:Initializing Linear Discriminant Analysis
2024-12-09 13:59:02,402:INFO:Total runtime is 0.16847254037857057 minutes
2024-12-09 13:59:02,406:INFO:SubProcess create_model() called ==================================
2024-12-09 13:59:02,407:INFO:Initializing create_model()
2024-12-09 13:59:02,407:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE7A3C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:59:02,407:INFO:Checking exceptions
2024-12-09 13:59:02,407:INFO:Importing libraries
2024-12-09 13:59:02,407:INFO:Copying training dataset
2024-12-09 13:59:02,413:INFO:Defining folds
2024-12-09 13:59:02,414:INFO:Declaring metric variables
2024-12-09 13:59:02,419:INFO:Importing untrained model
2024-12-09 13:59:02,431:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 13:59:02,444:INFO:Starting cross validation
2024-12-09 13:59:02,445:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:59:02,732:INFO:Calculating mean and std
2024-12-09 13:59:02,733:INFO:Creating metrics dataframe
2024-12-09 13:59:02,737:INFO:Uploading results into container
2024-12-09 13:59:02,737:INFO:Uploading model into container now
2024-12-09 13:59:02,738:INFO:_master_model_container: 11
2024-12-09 13:59:02,738:INFO:_display_container: 2
2024-12-09 13:59:02,739:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 13:59:02,739:INFO:create_model() successfully completed......................................
2024-12-09 13:59:02,803:INFO:SubProcess create_model() end ==================================
2024-12-09 13:59:02,803:INFO:Creating metrics dataframe
2024-12-09 13:59:02,816:INFO:Initializing Extra Trees Classifier
2024-12-09 13:59:02,816:INFO:Total runtime is 0.17537055810292562 minutes
2024-12-09 13:59:02,820:INFO:SubProcess create_model() called ==================================
2024-12-09 13:59:02,820:INFO:Initializing create_model()
2024-12-09 13:59:02,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE7A3C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:59:02,820:INFO:Checking exceptions
2024-12-09 13:59:02,820:INFO:Importing libraries
2024-12-09 13:59:02,820:INFO:Copying training dataset
2024-12-09 13:59:02,824:INFO:Defining folds
2024-12-09 13:59:02,824:INFO:Declaring metric variables
2024-12-09 13:59:02,827:INFO:Importing untrained model
2024-12-09 13:59:02,833:INFO:Extra Trees Classifier Imported successfully
2024-12-09 13:59:02,840:INFO:Starting cross validation
2024-12-09 13:59:02,842:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:59:03,680:INFO:Calculating mean and std
2024-12-09 13:59:03,682:INFO:Creating metrics dataframe
2024-12-09 13:59:03,685:INFO:Uploading results into container
2024-12-09 13:59:03,685:INFO:Uploading model into container now
2024-12-09 13:59:03,686:INFO:_master_model_container: 12
2024-12-09 13:59:03,686:INFO:_display_container: 2
2024-12-09 13:59:03,687:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 13:59:03,687:INFO:create_model() successfully completed......................................
2024-12-09 13:59:03,748:INFO:SubProcess create_model() end ==================================
2024-12-09 13:59:03,749:INFO:Creating metrics dataframe
2024-12-09 13:59:03,761:INFO:Initializing Light Gradient Boosting Machine
2024-12-09 13:59:03,761:INFO:Total runtime is 0.19112396240234375 minutes
2024-12-09 13:59:03,766:INFO:SubProcess create_model() called ==================================
2024-12-09 13:59:03,767:INFO:Initializing create_model()
2024-12-09 13:59:03,767:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE7A3C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:59:03,767:INFO:Checking exceptions
2024-12-09 13:59:03,767:INFO:Importing libraries
2024-12-09 13:59:03,767:INFO:Copying training dataset
2024-12-09 13:59:03,771:INFO:Defining folds
2024-12-09 13:59:03,771:INFO:Declaring metric variables
2024-12-09 13:59:03,774:INFO:Importing untrained model
2024-12-09 13:59:03,779:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:59:03,790:INFO:Starting cross validation
2024-12-09 13:59:03,792:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:59:04,599:INFO:Calculating mean and std
2024-12-09 13:59:04,601:INFO:Creating metrics dataframe
2024-12-09 13:59:04,604:INFO:Uploading results into container
2024-12-09 13:59:04,605:INFO:Uploading model into container now
2024-12-09 13:59:04,605:INFO:_master_model_container: 13
2024-12-09 13:59:04,605:INFO:_display_container: 2
2024-12-09 13:59:04,606:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:59:04,606:INFO:create_model() successfully completed......................................
2024-12-09 13:59:04,677:INFO:SubProcess create_model() end ==================================
2024-12-09 13:59:04,677:INFO:Creating metrics dataframe
2024-12-09 13:59:04,692:INFO:Initializing Dummy Classifier
2024-12-09 13:59:04,693:INFO:Total runtime is 0.2066495180130005 minutes
2024-12-09 13:59:04,698:INFO:SubProcess create_model() called ==================================
2024-12-09 13:59:04,699:INFO:Initializing create_model()
2024-12-09 13:59:04,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE7A3C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:59:04,699:INFO:Checking exceptions
2024-12-09 13:59:04,699:INFO:Importing libraries
2024-12-09 13:59:04,699:INFO:Copying training dataset
2024-12-09 13:59:04,705:INFO:Defining folds
2024-12-09 13:59:04,705:INFO:Declaring metric variables
2024-12-09 13:59:04,709:INFO:Importing untrained model
2024-12-09 13:59:04,714:INFO:Dummy Classifier Imported successfully
2024-12-09 13:59:04,725:INFO:Starting cross validation
2024-12-09 13:59:04,726:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:59:04,842:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:59:04,853:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:59:04,871:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:59:04,876:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:59:04,881:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:59:04,889:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:59:04,955:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:59:04,969:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:59:04,975:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:59:04,985:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 13:59:04,989:INFO:Calculating mean and std
2024-12-09 13:59:04,991:INFO:Creating metrics dataframe
2024-12-09 13:59:04,995:INFO:Uploading results into container
2024-12-09 13:59:04,995:INFO:Uploading model into container now
2024-12-09 13:59:04,996:INFO:_master_model_container: 14
2024-12-09 13:59:04,996:INFO:_display_container: 2
2024-12-09 13:59:04,996:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-12-09 13:59:04,997:INFO:create_model() successfully completed......................................
2024-12-09 13:59:05,064:INFO:SubProcess create_model() end ==================================
2024-12-09 13:59:05,064:INFO:Creating metrics dataframe
2024-12-09 13:59:05,088:INFO:Initializing create_model()
2024-12-09 13:59:05,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:59:05,088:INFO:Checking exceptions
2024-12-09 13:59:05,091:INFO:Importing libraries
2024-12-09 13:59:05,093:INFO:Copying training dataset
2024-12-09 13:59:05,099:INFO:Defining folds
2024-12-09 13:59:05,099:INFO:Declaring metric variables
2024-12-09 13:59:05,100:INFO:Importing untrained model
2024-12-09 13:59:05,100:INFO:Declaring custom model
2024-12-09 13:59:05,100:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:59:05,102:INFO:Cross validation set to False
2024-12-09 13:59:05,102:INFO:Fitting Model
2024-12-09 13:59:05,167:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 13:59:05,167:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.
2024-12-09 13:59:05,168:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 13:59:05,168:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 13:59:05,168:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 13:59:05,168:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 13:59:05,168:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 13:59:05,168:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 13:59:05,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:05,205:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:59:05,206:INFO:create_model() successfully completed......................................
2024-12-09 13:59:05,299:INFO:_master_model_container: 14
2024-12-09 13:59:05,300:INFO:_display_container: 2
2024-12-09 13:59:05,300:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:59:05,300:INFO:compare_models() successfully completed......................................
2024-12-09 13:59:05,301:INFO:Initializing tune_model()
2024-12-09 13:59:05,301:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>)
2024-12-09 13:59:05,301:INFO:Checking exceptions
2024-12-09 13:59:05,320:INFO:Copying training dataset
2024-12-09 13:59:05,324:INFO:Checking base model
2024-12-09 13:59:05,326:INFO:Base model : Light Gradient Boosting Machine
2024-12-09 13:59:05,330:INFO:Declaring metric variables
2024-12-09 13:59:05,336:INFO:Defining Hyperparameters
2024-12-09 13:59:05,420:INFO:Tuning with n_jobs=-1
2024-12-09 13:59:05,420:INFO:Initializing RandomizedSearchCV
2024-12-09 13:59:11,250:INFO:best_params: {'actual_estimator__reg_lambda': 0.4, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 60, 'actual_estimator__n_estimators': 80, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__feature_fraction': 0.7, 'actual_estimator__bagging_freq': 7, 'actual_estimator__bagging_fraction': 1.0}
2024-12-09 13:59:11,251:INFO:Hyperparameter search completed
2024-12-09 13:59:11,251:INFO:SubProcess create_model() called ==================================
2024-12-09 13:59:11,252:INFO:Initializing create_model()
2024-12-09 13:59:11,253:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6AF6942B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.4, 'reg_alpha': 0.0005, 'num_leaves': 60, 'n_estimators': 80, 'min_split_gain': 0.2, 'min_child_samples': 11, 'learning_rate': 0.01, 'feature_fraction': 0.7, 'bagging_freq': 7, 'bagging_fraction': 1.0})
2024-12-09 13:59:11,253:INFO:Checking exceptions
2024-12-09 13:59:11,253:INFO:Importing libraries
2024-12-09 13:59:11,253:INFO:Copying training dataset
2024-12-09 13:59:11,261:INFO:Defining folds
2024-12-09 13:59:11,261:INFO:Declaring metric variables
2024-12-09 13:59:11,265:INFO:Importing untrained model
2024-12-09 13:59:11,266:INFO:Declaring custom model
2024-12-09 13:59:11,273:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:59:11,282:INFO:Starting cross validation
2024-12-09 13:59:11,287:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:59:12,293:INFO:Calculating mean and std
2024-12-09 13:59:12,295:INFO:Creating metrics dataframe
2024-12-09 13:59:12,301:INFO:Finalizing model
2024-12-09 13:59:12,362:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2024-12-09 13:59:12,363:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-12-09 13:59:12,363:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-12-09 13:59:12,364:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2024-12-09 13:59:12,364:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-12-09 13:59:12,364:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-12-09 13:59:12,364:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 13:59:12,365:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.
2024-12-09 13:59:12,365:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-12-09 13:59:12,365:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 13:59:12,365:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 13:59:12,366:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 13:59:12,366:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 13:59:12,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:12,460:INFO:Uploading results into container
2024-12-09 13:59:12,460:INFO:Uploading model into container now
2024-12-09 13:59:12,461:INFO:_master_model_container: 15
2024-12-09 13:59:12,462:INFO:_display_container: 3
2024-12-09 13:59:12,463:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=80, n_jobs=-1, num_leaves=60, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.4,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:59:12,463:INFO:create_model() successfully completed......................................
2024-12-09 13:59:12,568:INFO:SubProcess create_model() end ==================================
2024-12-09 13:59:12,568:INFO:choose_better activated
2024-12-09 13:59:12,579:INFO:SubProcess create_model() called ==================================
2024-12-09 13:59:12,580:INFO:Initializing create_model()
2024-12-09 13:59:12,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:59:12,580:INFO:Checking exceptions
2024-12-09 13:59:12,583:INFO:Importing libraries
2024-12-09 13:59:12,583:INFO:Copying training dataset
2024-12-09 13:59:12,587:INFO:Defining folds
2024-12-09 13:59:12,587:INFO:Declaring metric variables
2024-12-09 13:59:12,587:INFO:Importing untrained model
2024-12-09 13:59:12,587:INFO:Declaring custom model
2024-12-09 13:59:12,589:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 13:59:12,589:INFO:Starting cross validation
2024-12-09 13:59:12,590:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:59:13,447:INFO:Calculating mean and std
2024-12-09 13:59:13,447:INFO:Creating metrics dataframe
2024-12-09 13:59:13,449:INFO:Finalizing model
2024-12-09 13:59:13,511:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 13:59:13,511:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000186 seconds.
2024-12-09 13:59:13,511:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 13:59:13,511:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 13:59:13,511:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 13:59:13,512:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 13:59:13,512:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 13:59:13,512:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 13:59:13,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:13,628:INFO:Uploading results into container
2024-12-09 13:59:13,628:INFO:Uploading model into container now
2024-12-09 13:59:13,629:INFO:_master_model_container: 16
2024-12-09 13:59:13,629:INFO:_display_container: 4
2024-12-09 13:59:13,629:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:59:13,629:INFO:create_model() successfully completed......................................
2024-12-09 13:59:13,704:INFO:SubProcess create_model() end ==================================
2024-12-09 13:59:13,705:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8169
2024-12-09 13:59:13,707:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=80, n_jobs=-1, num_leaves=60, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.4,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8153
2024-12-09 13:59:13,708:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-12-09 13:59:13,709:INFO:choose_better completed
2024-12-09 13:59:13,709:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-12-09 13:59:13,726:INFO:_master_model_container: 16
2024-12-09 13:59:13,726:INFO:_display_container: 3
2024-12-09 13:59:13,727:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 13:59:13,727:INFO:tune_model() successfully completed......................................
2024-12-09 13:59:13,845:INFO:Initializing blend_models()
2024-12-09 13:59:13,845:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-12-09 13:59:13,845:INFO:Checking exceptions
2024-12-09 13:59:13,931:INFO:Importing libraries
2024-12-09 13:59:13,931:INFO:Copying training dataset
2024-12-09 13:59:13,939:INFO:Getting model names
2024-12-09 13:59:13,946:INFO:SubProcess create_model() called ==================================
2024-12-09 13:59:13,949:INFO:Initializing create_model()
2024-12-09 13:59:13,949:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6AF620D30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:59:13,950:INFO:Checking exceptions
2024-12-09 13:59:13,950:INFO:Importing libraries
2024-12-09 13:59:13,950:INFO:Copying training dataset
2024-12-09 13:59:13,957:INFO:Defining folds
2024-12-09 13:59:13,957:INFO:Declaring metric variables
2024-12-09 13:59:13,971:INFO:Importing untrained model
2024-12-09 13:59:13,971:INFO:Declaring custom model
2024-12-09 13:59:13,986:INFO:Voting Classifier Imported successfully
2024-12-09 13:59:14,000:INFO:Starting cross validation
2024-12-09 13:59:14,003:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:59:16,340:INFO:Calculating mean and std
2024-12-09 13:59:16,347:INFO:Creating metrics dataframe
2024-12-09 13:59:16,363:INFO:Finalizing model
2024-12-09 13:59:16,544:INFO:Uploading results into container
2024-12-09 13:59:16,544:INFO:Uploading model into container now
2024-12-09 13:59:16,545:INFO:_master_model_container: 17
2024-12-09 13:59:16,545:INFO:_display_container: 4
2024-12-09 13:59:16,547:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-12-09 13:59:16,547:INFO:create_model() successfully completed......................................
2024-12-09 13:59:16,622:INFO:SubProcess create_model() end ==================================
2024-12-09 13:59:16,634:INFO:_master_model_container: 17
2024-12-09 13:59:16,635:INFO:_display_container: 4
2024-12-09 13:59:16,637:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-12-09 13:59:16,637:INFO:blend_models() successfully completed......................................
2024-12-09 13:59:16,723:INFO:Initializing stack_models()
2024-12-09 13:59:16,723:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)], meta_model=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-12-09 13:59:16,723:INFO:Checking exceptions
2024-12-09 13:59:16,726:INFO:Defining meta model
2024-12-09 13:59:16,757:INFO:Getting model names
2024-12-09 13:59:16,758:INFO:[('Light Gradient Boosting Machine', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0))]
2024-12-09 13:59:16,879:INFO:SubProcess create_model() called ==================================
2024-12-09 13:59:16,883:INFO:Initializing create_model()
2024-12-09 13:59:16,883:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=123, reg_alpha=0.0,
                                               re...
                                                  colsample_bytree=1.0,
                                                  importance_type='split',
                                                  learning_rate=0.1,
                                                  max_depth=-1,
                                                  min_child_samples=20,
                                                  min_child_weight=0.001,
                                                  min_split_gain=0.0,
                                                  n_estimators=100, n_jobs=-1,
                                                  num_leaves=31, objective=None,
                                                  random_state=123,
                                                  reg_alpha=0.0, reg_lambda=0.0,
                                                  subsample=1.0,
                                                  subsample_for_bin=200000,
                                                  subsample_freq=0),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6A2F0A7C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:59:16,883:INFO:Checking exceptions
2024-12-09 13:59:16,884:INFO:Importing libraries
2024-12-09 13:59:16,884:INFO:Copying training dataset
2024-12-09 13:59:16,889:INFO:Defining folds
2024-12-09 13:59:16,889:INFO:Declaring metric variables
2024-12-09 13:59:16,894:INFO:Importing untrained model
2024-12-09 13:59:16,894:INFO:Declaring custom model
2024-12-09 13:59:16,900:INFO:Stacking Classifier Imported successfully
2024-12-09 13:59:16,910:INFO:Starting cross validation
2024-12-09 13:59:16,913:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 13:59:21,896:INFO:Calculating mean and std
2024-12-09 13:59:21,901:INFO:Creating metrics dataframe
2024-12-09 13:59:21,909:INFO:Finalizing model
2024-12-09 13:59:22,258:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 13:59:22,259:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000206 seconds.
2024-12-09 13:59:22,259:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 13:59:22,259:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 13:59:22,259:INFO:[LightGBM] [Info] Total Bins 399
2024-12-09 13:59:22,259:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 10
2024-12-09 13:59:22,259:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 13:59:22,259:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 13:59:22,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 13:59:22,396:INFO:Uploading results into container
2024-12-09 13:59:22,397:INFO:Uploading model into container now
2024-12-09 13:59:22,399:INFO:_master_model_container: 18
2024-12-09 13:59:22,399:INFO:_display_container: 5
2024-12-09 13:59:22,403:INFO:StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=123, reg_alpha=0.0,
                                               re...
                                                  colsample_bytree=1.0,
                                                  importance_type='split',
                                                  learning_rate=0.1,
                                                  max_depth=-1,
                                                  min_child_samples=20,
                                                  min_child_weight=0.001,
                                                  min_split_gain=0.0,
                                                  n_estimators=100, n_jobs=-1,
                                                  num_leaves=31, objective=None,
                                                  random_state=123,
                                                  reg_alpha=0.0, reg_lambda=0.0,
                                                  subsample=1.0,
                                                  subsample_for_bin=200000,
                                                  subsample_freq=0),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-12-09 13:59:22,403:INFO:create_model() successfully completed......................................
2024-12-09 13:59:22,480:INFO:SubProcess create_model() end ==================================
2024-12-09 13:59:22,492:INFO:_master_model_container: 18
2024-12-09 13:59:22,493:INFO:_display_container: 5
2024-12-09 13:59:22,495:INFO:StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=123, reg_alpha=0.0,
                                               re...
                                                  colsample_bytree=1.0,
                                                  importance_type='split',
                                                  learning_rate=0.1,
                                                  max_depth=-1,
                                                  min_child_samples=20,
                                                  min_child_weight=0.001,
                                                  min_split_gain=0.0,
                                                  n_estimators=100, n_jobs=-1,
                                                  num_leaves=31, objective=None,
                                                  random_state=123,
                                                  reg_alpha=0.0, reg_lambda=0.0,
                                                  subsample=1.0,
                                                  subsample_for_bin=200000,
                                                  subsample_freq=0),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-12-09 13:59:22,496:INFO:stack_models() successfully completed......................................
2024-12-09 13:59:22,587:INFO:Initializing finalize_model()
2024-12-09 13:59:22,587:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=123, reg_alpha=0.0,
                                               re...
                                                  colsample_bytree=1.0,
                                                  importance_type='split',
                                                  learning_rate=0.1,
                                                  max_depth=-1,
                                                  min_child_samples=20,
                                                  min_child_weight=0.001,
                                                  min_split_gain=0.0,
                                                  n_estimators=100, n_jobs=-1,
                                                  num_leaves=31, objective=None,
                                                  random_state=123,
                                                  reg_alpha=0.0, reg_lambda=0.0,
                                                  subsample=1.0,
                                                  subsample_for_bin=200000,
                                                  subsample_freq=0),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-09 13:59:22,590:INFO:Finalizing StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=123, reg_alpha=0.0,
                                               re...
                                                  colsample_bytree=1.0,
                                                  importance_type='split',
                                                  learning_rate=0.1,
                                                  max_depth=-1,
                                                  min_child_samples=20,
                                                  min_child_weight=0.001,
                                                  min_split_gain=0.0,
                                                  n_estimators=100, n_jobs=-1,
                                                  num_leaves=31, objective=None,
                                                  random_state=123,
                                                  reg_alpha=0.0, reg_lambda=0.0,
                                                  subsample=1.0,
                                                  subsample_for_bin=200000,
                                                  subsample_freq=0),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-12-09 13:59:22,595:INFO:Initializing create_model()
2024-12-09 13:59:22,595:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=123, reg_alpha=0.0,
                                               re...
                                                  colsample_bytree=1.0,
                                                  importance_type='split',
                                                  learning_rate=0.1,
                                                  max_depth=-1,
                                                  min_child_samples=20,
                                                  min_child_weight=0.001,
                                                  min_split_gain=0.0,
                                                  n_estimators=100, n_jobs=-1,
                                                  num_leaves=31, objective=None,
                                                  random_state=123,
                                                  reg_alpha=0.0, reg_lambda=0.0,
                                                  subsample=1.0,
                                                  subsample_for_bin=200000,
                                                  subsample_freq=0),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 13:59:22,595:INFO:Checking exceptions
2024-12-09 13:59:22,596:INFO:Importing libraries
2024-12-09 13:59:22,596:INFO:Copying training dataset
2024-12-09 13:59:22,596:INFO:Defining folds
2024-12-09 13:59:22,597:INFO:Declaring metric variables
2024-12-09 13:59:22,597:INFO:Importing untrained model
2024-12-09 13:59:22,597:INFO:Declaring custom model
2024-12-09 13:59:22,598:INFO:Stacking Classifier Imported successfully
2024-12-09 13:59:22,599:INFO:Cross validation set to False
2024-12-09 13:59:22,599:INFO:Fitting Model
2024-12-09 13:59:22,943:INFO:[LightGBM] [Info] Number of positive: 342, number of negative: 549
2024-12-09 13:59:22,944:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000223 seconds.
2024-12-09 13:59:22,944:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 13:59:22,944:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 13:59:22,944:INFO:[LightGBM] [Info] Total Bins 479
2024-12-09 13:59:22,944:INFO:[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 10
2024-12-09 13:59:22,944:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288
2024-12-09 13:59:22,944:INFO:[LightGBM] [Info] Start training from score -0.473288
2024-12-09 13:59:23,093:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                                                                   importance_type='split',
                                                                   learning_rate=0.1,
                                                                   max_depth=-1,
                                                                   min_child_samples=20,
                                                                   min_child_weight=0.001,
                                                                   min_split_gain=0.0,
                                                                   n_estimators=100,
                                                                   n_jobs=-1,
                                                                   num_leaves=31,
                                                                   objective=None,
                                                                   random_state=123,
                                                                   reg_alpha=0.0,
                                                                   reg_lambda=0.0,
                                                                   subsample=1.0,
                                                                   subsample_for_bin=200000,
                                                                   subsample_freq=0),
                                    n_jobs=-1, passthrough=True,
                                    stack_method='auto', verbose=0))],
         verbose=False)
2024-12-09 13:59:23,093:INFO:create_model() successfully completed......................................
2024-12-09 13:59:23,152:INFO:_master_model_container: 18
2024-12-09 13:59:23,152:INFO:_display_container: 5
2024-12-09 13:59:23,178:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                                                                   importance_type='split',
                                                                   learning_rate=0.1,
                                                                   max_depth=-1,
                                                                   min_child_samples=20,
                                                                   min_child_weight=0.001,
                                                                   min_split_gain=0.0,
                                                                   n_estimators=100,
                                                                   n_jobs=-1,
                                                                   num_leaves=31,
                                                                   objective=None,
                                                                   random_state=123,
                                                                   reg_alpha=0.0,
                                                                   reg_lambda=0.0,
                                                                   subsample=1.0,
                                                                   subsample_for_bin=200000,
                                                                   subsample_freq=0),
                                    n_jobs=-1, passthrough=True,
                                    stack_method='auto', verbose=0))],
         verbose=False)
2024-12-09 13:59:23,178:INFO:finalize_model() successfully completed......................................
2024-12-09 13:59:23,264:INFO:Initializing predict_model()
2024-12-09 13:59:23,264:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7A3B80>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                                                                   importance_type='split',
                                                                   learning_rate=0.1,
                                                                   max_depth=-1,
                                                                   min_child_samples=20,
                                                                   min_child_weight=0.001,
                                                                   min_split_gain=0.0,
                                                                   n_estimators=100,
                                                                   n_jobs=-1,
                                                                   num_leaves=31,
                                                                   objective=None,
                                                                   random_state=123,
                                                                   reg_alpha=0.0,
                                                                   reg_lambda=0.0,
                                                                   subsample=1.0,
                                                                   subsample_for_bin=200000,
                                                                   subsample_freq=0),
                                    n_jobs=-1, passthrough=True,
                                    stack_method='auto', verbose=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E6BEBF4670>)
2024-12-09 13:59:23,264:INFO:Checking exceptions
2024-12-09 13:59:23,264:INFO:Preloading libraries
2024-12-09 13:59:23,266:INFO:Set up data.
2024-12-09 13:59:23,270:INFO:Set up index.
2024-12-09 14:05:32,753:INFO:PyCaret ClassificationExperiment
2024-12-09 14:05:32,753:INFO:Logging name: clf-default-name
2024-12-09 14:05:32,753:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-09 14:05:32,753:INFO:version 3.2.0
2024-12-09 14:05:32,753:INFO:Initializing setup()
2024-12-09 14:05:32,753:INFO:self.USI: ac0d
2024-12-09 14:05:32,753:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'pipeline', 'X_test', 'html_param', '_ml_usecase', 'seed', 'gpu_param', '_available_plots', 'X', 'X_train', 'fold_shuffle_param', 'y_test', 'log_plots_param', 'y', 'gpu_n_jobs_param', 'target_param', 'USI', 'fix_imbalance', 'n_jobs_param', 'idx', 'logging_param', 'exp_id', 'memory', 'data', 'fold_generator', 'y_train', 'exp_name_log'}
2024-12-09 14:05:32,754:INFO:Checking environment
2024-12-09 14:05:32,754:INFO:python_version: 3.8.20
2024-12-09 14:05:32,754:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2024-12-09 14:05:32,754:INFO:machine: AMD64
2024-12-09 14:05:32,754:INFO:platform: Windows-10-10.0.19041-SP0
2024-12-09 14:05:32,757:INFO:Memory: svmem(total=17054896128, available=5919178752, percent=65.3, used=11135717376, free=5919178752)
2024-12-09 14:05:32,757:INFO:Physical Core: 6
2024-12-09 14:05:32,757:INFO:Logical Core: 6
2024-12-09 14:05:32,757:INFO:Checking libraries
2024-12-09 14:05:32,758:INFO:System:
2024-12-09 14:05:32,758:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2024-12-09 14:05:32,758:INFO:executable: c:\Users\EE715\anaconda3\envs\gym-env\python.exe
2024-12-09 14:05:32,758:INFO:   machine: Windows-10-10.0.19041-SP0
2024-12-09 14:05:32,758:INFO:PyCaret required dependencies:
2024-12-09 14:05:32,758:INFO:                 pip: 24.2
2024-12-09 14:05:32,758:INFO:          setuptools: 75.1.0
2024-12-09 14:05:32,758:INFO:             pycaret: 3.2.0
2024-12-09 14:05:32,758:INFO:             IPython: 8.12.3
2024-12-09 14:05:32,758:INFO:          ipywidgets: 8.1.5
2024-12-09 14:05:32,758:INFO:                tqdm: 4.67.1
2024-12-09 14:05:32,758:INFO:               numpy: 1.24.4
2024-12-09 14:05:32,758:INFO:              pandas: 1.5.3
2024-12-09 14:05:32,758:INFO:              jinja2: 3.1.4
2024-12-09 14:05:32,758:INFO:               scipy: 1.10.1
2024-12-09 14:05:32,759:INFO:              joblib: 1.2.0
2024-12-09 14:05:32,759:INFO:             sklearn: 1.2.2
2024-12-09 14:05:32,759:INFO:                pyod: 2.0.2
2024-12-09 14:05:32,759:INFO:            imblearn: 0.12.4
2024-12-09 14:05:32,759:INFO:   category_encoders: 2.6.4
2024-12-09 14:05:32,759:INFO:            lightgbm: 4.5.0
2024-12-09 14:05:32,759:INFO:               numba: 0.58.1
2024-12-09 14:05:32,759:INFO:            requests: 2.32.3
2024-12-09 14:05:32,759:INFO:          matplotlib: 3.6.0
2024-12-09 14:05:32,759:INFO:          scikitplot: 0.3.7
2024-12-09 14:05:32,759:INFO:         yellowbrick: 1.5
2024-12-09 14:05:32,759:INFO:              plotly: 5.24.1
2024-12-09 14:05:32,759:INFO:    plotly-resampler: Not installed
2024-12-09 14:05:32,759:INFO:             kaleido: 0.2.1
2024-12-09 14:05:32,759:INFO:           schemdraw: 0.15
2024-12-09 14:05:32,759:INFO:         statsmodels: 0.14.1
2024-12-09 14:05:32,759:INFO:              sktime: 0.21.1
2024-12-09 14:05:32,759:INFO:               tbats: 1.1.3
2024-12-09 14:05:32,759:INFO:            pmdarima: 2.0.4
2024-12-09 14:05:32,759:INFO:              psutil: 6.1.0
2024-12-09 14:05:32,759:INFO:          markupsafe: 2.1.5
2024-12-09 14:05:32,760:INFO:             pickle5: Not installed
2024-12-09 14:05:32,760:INFO:         cloudpickle: 3.1.0
2024-12-09 14:05:32,760:INFO:         deprecation: 2.1.0
2024-12-09 14:05:32,760:INFO:              xxhash: 3.5.0
2024-12-09 14:05:32,760:INFO:           wurlitzer: Not installed
2024-12-09 14:05:32,760:INFO:PyCaret optional dependencies:
2024-12-09 14:05:32,760:INFO:                shap: Not installed
2024-12-09 14:05:32,760:INFO:           interpret: Not installed
2024-12-09 14:05:32,760:INFO:                umap: Not installed
2024-12-09 14:05:32,760:INFO:     ydata_profiling: Not installed
2024-12-09 14:05:32,760:INFO:  explainerdashboard: Not installed
2024-12-09 14:05:32,760:INFO:             autoviz: Not installed
2024-12-09 14:05:32,760:INFO:           fairlearn: Not installed
2024-12-09 14:05:32,760:INFO:          deepchecks: Not installed
2024-12-09 14:05:32,760:INFO:             xgboost: Not installed
2024-12-09 14:05:32,760:INFO:            catboost: Not installed
2024-12-09 14:05:32,760:INFO:              kmodes: Not installed
2024-12-09 14:05:32,760:INFO:             mlxtend: Not installed
2024-12-09 14:05:32,760:INFO:       statsforecast: Not installed
2024-12-09 14:05:32,760:INFO:        tune_sklearn: Not installed
2024-12-09 14:05:32,760:INFO:                 ray: Not installed
2024-12-09 14:05:32,760:INFO:            hyperopt: Not installed
2024-12-09 14:05:32,761:INFO:              optuna: 4.1.0
2024-12-09 14:05:32,761:INFO:               skopt: Not installed
2024-12-09 14:05:32,761:INFO:              mlflow: Not installed
2024-12-09 14:05:32,761:INFO:              gradio: Not installed
2024-12-09 14:05:32,761:INFO:             fastapi: Not installed
2024-12-09 14:05:32,761:INFO:             uvicorn: Not installed
2024-12-09 14:05:32,761:INFO:              m2cgen: Not installed
2024-12-09 14:05:32,761:INFO:           evidently: Not installed
2024-12-09 14:05:32,761:INFO:               fugue: Not installed
2024-12-09 14:05:32,761:INFO:           streamlit: Not installed
2024-12-09 14:05:32,761:INFO:             prophet: Not installed
2024-12-09 14:05:32,761:INFO:None
2024-12-09 14:05:32,761:INFO:Set up data.
2024-12-09 14:05:32,767:INFO:Set up folding strategy.
2024-12-09 14:05:32,767:INFO:Set up train/test split.
2024-12-09 14:05:32,773:INFO:Set up index.
2024-12-09 14:05:32,773:INFO:Assigning column types.
2024-12-09 14:05:32,776:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-09 14:05:32,819:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 14:05:32,819:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:05:32,908:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:05:32,908:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:05:32,950:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 14:05:32,950:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:05:32,976:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:05:32,976:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:05:32,976:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-09 14:05:33,019:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:05:33,047:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:05:33,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:05:33,095:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:05:33,124:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:05:33,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:05:33,134:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-09 14:05:33,205:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:05:33,205:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:05:33,275:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:05:33,275:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:05:33,276:INFO:Preparing preprocessing pipeline...
2024-12-09 14:05:33,277:INFO:Set up simple imputation.
2024-12-09 14:05:33,280:INFO:Set up encoding of ordinal features.
2024-12-09 14:05:33,281:INFO:Set up encoding of categorical features.
2024-12-09 14:05:33,352:INFO:Finished creating preprocessing pipeline.
2024-12-09 14:05:33,371:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\EE715\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categ...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-12-09 14:05:33,371:INFO:Creating final display dataframe.
2024-12-09 14:05:33,627:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (623, 10)
6    Transformed test set shape         (268, 10)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              ac0d
2024-12-09 14:05:33,706:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:05:33,706:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:05:33,779:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:05:33,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:05:33,780:INFO:setup() successfully completed in 1.03s...............
2024-12-09 14:05:33,781:INFO:Initializing compare_models()
2024-12-09 14:05:33,781:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6AF250130>, include=['rf', 'gbc', 'xgboost', 'catboost', 'lr', 'et', 'knn', 'lda', 'nb', 'ridge', 'qda', 'dt', 'svm', 'ada', 'lightgbm', 'dummy'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E6AF250130>, 'include': ['rf', 'gbc', 'xgboost', 'catboost', 'lr', 'et', 'knn', 'lda', 'nb', 'ridge', 'qda', 'dt', 'svm', 'ada', 'lightgbm', 'dummy'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-12-09 14:05:33,781:INFO:Checking exceptions
2024-12-09 14:11:12,642:INFO:PyCaret ClassificationExperiment
2024-12-09 14:11:12,642:INFO:Logging name: clf-default-name
2024-12-09 14:11:12,643:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-09 14:11:12,643:INFO:version 3.2.0
2024-12-09 14:11:12,643:INFO:Initializing setup()
2024-12-09 14:11:12,643:INFO:self.USI: cd59
2024-12-09 14:11:12,643:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'pipeline', 'X_test', 'html_param', '_ml_usecase', 'seed', 'gpu_param', '_available_plots', 'X', 'X_train', 'fold_shuffle_param', 'y_test', 'log_plots_param', 'y', 'gpu_n_jobs_param', 'target_param', 'USI', 'fix_imbalance', 'n_jobs_param', 'idx', 'logging_param', 'exp_id', 'memory', 'data', 'fold_generator', 'y_train', 'exp_name_log'}
2024-12-09 14:11:12,643:INFO:Checking environment
2024-12-09 14:11:12,643:INFO:python_version: 3.8.20
2024-12-09 14:11:12,643:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2024-12-09 14:11:12,643:INFO:machine: AMD64
2024-12-09 14:11:12,643:INFO:platform: Windows-10-10.0.19041-SP0
2024-12-09 14:11:12,646:INFO:Memory: svmem(total=17054896128, available=7109160960, percent=58.3, used=9945735168, free=7109160960)
2024-12-09 14:11:12,646:INFO:Physical Core: 6
2024-12-09 14:11:12,646:INFO:Logical Core: 6
2024-12-09 14:11:12,646:INFO:Checking libraries
2024-12-09 14:11:12,646:INFO:System:
2024-12-09 14:11:12,646:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2024-12-09 14:11:12,646:INFO:executable: c:\Users\EE715\anaconda3\envs\gym-env\python.exe
2024-12-09 14:11:12,646:INFO:   machine: Windows-10-10.0.19041-SP0
2024-12-09 14:11:12,646:INFO:PyCaret required dependencies:
2024-12-09 14:11:12,646:INFO:                 pip: 24.2
2024-12-09 14:11:12,646:INFO:          setuptools: 75.1.0
2024-12-09 14:11:12,646:INFO:             pycaret: 3.2.0
2024-12-09 14:11:12,646:INFO:             IPython: 8.12.3
2024-12-09 14:11:12,646:INFO:          ipywidgets: 8.1.5
2024-12-09 14:11:12,646:INFO:                tqdm: 4.67.1
2024-12-09 14:11:12,646:INFO:               numpy: 1.24.4
2024-12-09 14:11:12,647:INFO:              pandas: 1.5.3
2024-12-09 14:11:12,647:INFO:              jinja2: 3.1.4
2024-12-09 14:11:12,647:INFO:               scipy: 1.10.1
2024-12-09 14:11:12,647:INFO:              joblib: 1.2.0
2024-12-09 14:11:12,647:INFO:             sklearn: 1.2.2
2024-12-09 14:11:12,647:INFO:                pyod: 2.0.2
2024-12-09 14:11:12,647:INFO:            imblearn: 0.12.4
2024-12-09 14:11:12,647:INFO:   category_encoders: 2.6.4
2024-12-09 14:11:12,647:INFO:            lightgbm: 4.5.0
2024-12-09 14:11:12,647:INFO:               numba: 0.58.1
2024-12-09 14:11:12,647:INFO:            requests: 2.32.3
2024-12-09 14:11:12,647:INFO:          matplotlib: 3.6.0
2024-12-09 14:11:12,647:INFO:          scikitplot: 0.3.7
2024-12-09 14:11:12,647:INFO:         yellowbrick: 1.5
2024-12-09 14:11:12,647:INFO:              plotly: 5.24.1
2024-12-09 14:11:12,647:INFO:    plotly-resampler: Not installed
2024-12-09 14:11:12,647:INFO:             kaleido: 0.2.1
2024-12-09 14:11:12,647:INFO:           schemdraw: 0.15
2024-12-09 14:11:12,647:INFO:         statsmodels: 0.14.1
2024-12-09 14:11:12,647:INFO:              sktime: 0.21.1
2024-12-09 14:11:12,647:INFO:               tbats: 1.1.3
2024-12-09 14:11:12,647:INFO:            pmdarima: 2.0.4
2024-12-09 14:11:12,648:INFO:              psutil: 6.1.0
2024-12-09 14:11:12,648:INFO:          markupsafe: 2.1.5
2024-12-09 14:11:12,648:INFO:             pickle5: Not installed
2024-12-09 14:11:12,648:INFO:         cloudpickle: 3.1.0
2024-12-09 14:11:12,648:INFO:         deprecation: 2.1.0
2024-12-09 14:11:12,648:INFO:              xxhash: 3.5.0
2024-12-09 14:11:12,648:INFO:           wurlitzer: Not installed
2024-12-09 14:11:12,648:INFO:PyCaret optional dependencies:
2024-12-09 14:11:12,648:INFO:                shap: Not installed
2024-12-09 14:11:12,648:INFO:           interpret: Not installed
2024-12-09 14:11:12,648:INFO:                umap: Not installed
2024-12-09 14:11:12,648:INFO:     ydata_profiling: Not installed
2024-12-09 14:11:12,648:INFO:  explainerdashboard: Not installed
2024-12-09 14:11:12,648:INFO:             autoviz: Not installed
2024-12-09 14:11:12,648:INFO:           fairlearn: Not installed
2024-12-09 14:11:12,648:INFO:          deepchecks: Not installed
2024-12-09 14:11:12,648:INFO:             xgboost: Not installed
2024-12-09 14:11:12,648:INFO:            catboost: Not installed
2024-12-09 14:11:12,648:INFO:              kmodes: Not installed
2024-12-09 14:11:12,648:INFO:             mlxtend: Not installed
2024-12-09 14:11:12,648:INFO:       statsforecast: Not installed
2024-12-09 14:11:12,648:INFO:        tune_sklearn: Not installed
2024-12-09 14:11:12,649:INFO:                 ray: Not installed
2024-12-09 14:11:12,649:INFO:            hyperopt: Not installed
2024-12-09 14:11:12,649:INFO:              optuna: 4.1.0
2024-12-09 14:11:12,649:INFO:               skopt: Not installed
2024-12-09 14:11:12,649:INFO:              mlflow: Not installed
2024-12-09 14:11:12,649:INFO:              gradio: Not installed
2024-12-09 14:11:12,649:INFO:             fastapi: Not installed
2024-12-09 14:11:12,649:INFO:             uvicorn: Not installed
2024-12-09 14:11:12,649:INFO:              m2cgen: Not installed
2024-12-09 14:11:12,649:INFO:           evidently: Not installed
2024-12-09 14:11:12,649:INFO:               fugue: Not installed
2024-12-09 14:11:12,649:INFO:           streamlit: Not installed
2024-12-09 14:11:12,649:INFO:             prophet: Not installed
2024-12-09 14:11:12,649:INFO:None
2024-12-09 14:11:12,649:INFO:Set up data.
2024-12-09 14:11:12,656:INFO:Set up folding strategy.
2024-12-09 14:11:12,656:INFO:Set up train/test split.
2024-12-09 14:11:12,662:INFO:Set up index.
2024-12-09 14:11:12,662:INFO:Assigning column types.
2024-12-09 14:11:12,665:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-09 14:11:12,713:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 14:11:12,714:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:11:12,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:11:12,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:11:12,818:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 14:11:12,819:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:11:12,848:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:11:12,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:11:12,848:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-09 14:11:12,899:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:11:12,930:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:11:12,930:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:11:12,980:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:11:13,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:11:13,012:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:11:13,012:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-09 14:11:13,094:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:11:13,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:11:13,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:11:13,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:11:13,176:INFO:Preparing preprocessing pipeline...
2024-12-09 14:11:13,177:INFO:Set up simple imputation.
2024-12-09 14:11:13,179:INFO:Set up encoding of ordinal features.
2024-12-09 14:11:13,181:INFO:Set up encoding of categorical features.
2024-12-09 14:11:13,246:INFO:Finished creating preprocessing pipeline.
2024-12-09 14:11:13,263:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\EE715\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categ...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-12-09 14:11:13,263:INFO:Creating final display dataframe.
2024-12-09 14:11:13,474:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (623, 10)
6    Transformed test set shape         (268, 10)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              cd59
2024-12-09 14:11:13,563:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:11:13,563:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:11:13,646:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:11:13,646:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:11:13,647:INFO:setup() successfully completed in 1.01s...............
2024-12-09 14:11:13,647:INFO:Initializing compare_models()
2024-12-09 14:11:13,647:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7E9130>, include=['rf', 'gbc', 'xgboost', 'catboost', 'lr', 'et', 'knn', 'lda', 'nb', 'ridge', 'qda', 'dt', 'svm', 'ada', 'lightgbm', 'dummy'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BE7E9130>, 'include': ['rf', 'gbc', 'xgboost', 'catboost', 'lr', 'et', 'knn', 'lda', 'nb', 'ridge', 'qda', 'dt', 'svm', 'ada', 'lightgbm', 'dummy'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-12-09 14:11:13,647:INFO:Checking exceptions
2024-12-09 14:12:09,554:INFO:gpu_param set to False
2024-12-09 14:12:09,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:09,630:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:09,707:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:09,708:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:09,711:INFO:PyCaret ClassificationExperiment
2024-12-09 14:12:09,711:INFO:Logging name: clf-default-name
2024-12-09 14:12:09,711:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-09 14:12:09,711:INFO:version 3.2.0
2024-12-09 14:12:09,711:INFO:Initializing setup()
2024-12-09 14:12:09,711:INFO:self.USI: 0011
2024-12-09 14:12:09,711:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'pipeline', 'X_test', 'html_param', '_ml_usecase', 'seed', 'gpu_param', '_available_plots', 'X', 'X_train', 'fold_shuffle_param', 'y_test', 'log_plots_param', 'y', 'gpu_n_jobs_param', 'target_param', 'USI', 'fix_imbalance', 'n_jobs_param', 'idx', 'logging_param', 'exp_id', 'memory', 'data', 'fold_generator', 'y_train', 'exp_name_log'}
2024-12-09 14:12:09,711:INFO:Checking environment
2024-12-09 14:12:09,711:INFO:python_version: 3.8.20
2024-12-09 14:12:09,711:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2024-12-09 14:12:09,711:INFO:machine: AMD64
2024-12-09 14:12:09,711:INFO:platform: Windows-10-10.0.19041-SP0
2024-12-09 14:12:09,714:INFO:Memory: svmem(total=17054896128, available=7002636288, percent=58.9, used=10052259840, free=7002636288)
2024-12-09 14:12:09,714:INFO:Physical Core: 6
2024-12-09 14:12:09,715:INFO:Logical Core: 6
2024-12-09 14:12:09,715:INFO:Checking libraries
2024-12-09 14:12:09,715:INFO:System:
2024-12-09 14:12:09,716:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2024-12-09 14:12:09,716:INFO:executable: c:\Users\EE715\anaconda3\envs\gym-env\python.exe
2024-12-09 14:12:09,716:INFO:   machine: Windows-10-10.0.19041-SP0
2024-12-09 14:12:09,716:INFO:PyCaret required dependencies:
2024-12-09 14:12:09,716:INFO:                 pip: 24.2
2024-12-09 14:12:09,716:INFO:          setuptools: 75.1.0
2024-12-09 14:12:09,716:INFO:             pycaret: 3.2.0
2024-12-09 14:12:09,716:INFO:             IPython: 8.12.3
2024-12-09 14:12:09,716:INFO:          ipywidgets: 8.1.5
2024-12-09 14:12:09,716:INFO:                tqdm: 4.67.1
2024-12-09 14:12:09,716:INFO:               numpy: 1.24.4
2024-12-09 14:12:09,716:INFO:              pandas: 1.5.3
2024-12-09 14:12:09,716:INFO:              jinja2: 3.1.4
2024-12-09 14:12:09,716:INFO:               scipy: 1.10.1
2024-12-09 14:12:09,716:INFO:              joblib: 1.2.0
2024-12-09 14:12:09,716:INFO:             sklearn: 1.2.2
2024-12-09 14:12:09,716:INFO:                pyod: 2.0.2
2024-12-09 14:12:09,716:INFO:            imblearn: 0.12.4
2024-12-09 14:12:09,716:INFO:   category_encoders: 2.6.4
2024-12-09 14:12:09,716:INFO:            lightgbm: 4.5.0
2024-12-09 14:12:09,716:INFO:               numba: 0.58.1
2024-12-09 14:12:09,717:INFO:            requests: 2.32.3
2024-12-09 14:12:09,717:INFO:          matplotlib: 3.6.0
2024-12-09 14:12:09,717:INFO:          scikitplot: 0.3.7
2024-12-09 14:12:09,717:INFO:         yellowbrick: 1.5
2024-12-09 14:12:09,717:INFO:              plotly: 5.24.1
2024-12-09 14:12:09,717:INFO:    plotly-resampler: Not installed
2024-12-09 14:12:09,717:INFO:             kaleido: 0.2.1
2024-12-09 14:12:09,717:INFO:           schemdraw: 0.15
2024-12-09 14:12:09,717:INFO:         statsmodels: 0.14.1
2024-12-09 14:12:09,717:INFO:              sktime: 0.21.1
2024-12-09 14:12:09,717:INFO:               tbats: 1.1.3
2024-12-09 14:12:09,717:INFO:            pmdarima: 2.0.4
2024-12-09 14:12:09,717:INFO:              psutil: 6.1.0
2024-12-09 14:12:09,717:INFO:          markupsafe: 2.1.5
2024-12-09 14:12:09,717:INFO:             pickle5: Not installed
2024-12-09 14:12:09,717:INFO:         cloudpickle: 3.1.0
2024-12-09 14:12:09,717:INFO:         deprecation: 2.1.0
2024-12-09 14:12:09,717:INFO:              xxhash: 3.5.0
2024-12-09 14:12:09,717:INFO:           wurlitzer: Not installed
2024-12-09 14:12:09,717:INFO:PyCaret optional dependencies:
2024-12-09 14:12:09,717:INFO:                shap: Not installed
2024-12-09 14:12:09,717:INFO:           interpret: Not installed
2024-12-09 14:12:09,718:INFO:                umap: Not installed
2024-12-09 14:12:09,718:INFO:     ydata_profiling: Not installed
2024-12-09 14:12:09,718:INFO:  explainerdashboard: Not installed
2024-12-09 14:12:09,718:INFO:             autoviz: Not installed
2024-12-09 14:12:09,718:INFO:           fairlearn: Not installed
2024-12-09 14:12:09,718:INFO:          deepchecks: Not installed
2024-12-09 14:12:09,718:INFO:             xgboost: Not installed
2024-12-09 14:12:09,718:INFO:            catboost: Not installed
2024-12-09 14:12:09,718:INFO:              kmodes: Not installed
2024-12-09 14:12:09,718:INFO:             mlxtend: Not installed
2024-12-09 14:12:09,718:INFO:       statsforecast: Not installed
2024-12-09 14:12:09,718:INFO:        tune_sklearn: Not installed
2024-12-09 14:12:09,718:INFO:                 ray: Not installed
2024-12-09 14:12:09,718:INFO:            hyperopt: Not installed
2024-12-09 14:12:09,718:INFO:              optuna: 4.1.0
2024-12-09 14:12:09,718:INFO:               skopt: Not installed
2024-12-09 14:12:09,718:INFO:              mlflow: Not installed
2024-12-09 14:12:09,718:INFO:              gradio: Not installed
2024-12-09 14:12:09,718:INFO:             fastapi: Not installed
2024-12-09 14:12:09,718:INFO:             uvicorn: Not installed
2024-12-09 14:12:09,718:INFO:              m2cgen: Not installed
2024-12-09 14:12:09,718:INFO:           evidently: Not installed
2024-12-09 14:12:09,718:INFO:               fugue: Not installed
2024-12-09 14:12:09,719:INFO:           streamlit: Not installed
2024-12-09 14:12:09,719:INFO:             prophet: Not installed
2024-12-09 14:12:09,719:INFO:None
2024-12-09 14:12:09,719:INFO:Set up data.
2024-12-09 14:12:09,724:INFO:Set up folding strategy.
2024-12-09 14:12:09,724:INFO:Set up train/test split.
2024-12-09 14:12:09,728:INFO:Set up index.
2024-12-09 14:12:09,729:INFO:Assigning column types.
2024-12-09 14:12:09,732:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-09 14:12:09,780:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 14:12:09,781:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:12:09,810:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:09,810:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:09,857:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 14:12:09,857:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:12:09,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:09,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:09,888:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-09 14:12:09,937:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:12:09,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:09,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:10,019:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:12:10,050:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:10,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:10,050:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-09 14:12:10,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:10,128:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:10,204:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:10,204:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:10,206:INFO:Preparing preprocessing pipeline...
2024-12-09 14:12:10,207:INFO:Set up simple imputation.
2024-12-09 14:12:10,209:INFO:Set up encoding of ordinal features.
2024-12-09 14:12:10,210:INFO:Set up encoding of categorical features.
2024-12-09 14:12:10,271:INFO:Finished creating preprocessing pipeline.
2024-12-09 14:12:10,288:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\EE715\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categ...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-12-09 14:12:10,288:INFO:Creating final display dataframe.
2024-12-09 14:12:10,495:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (623, 10)
6    Transformed test set shape         (268, 10)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              0011
2024-12-09 14:12:10,583:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:10,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:10,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:10,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:10,661:INFO:setup() successfully completed in 0.95s...............
2024-12-09 14:12:10,661:INFO:Initializing compare_models()
2024-12-09 14:12:10,661:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, include=[], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, 'include': [], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-12-09 14:12:10,661:INFO:Checking exceptions
2024-12-09 14:12:10,664:INFO:Preparing display monitor
2024-12-09 14:12:10,688:INFO:Initializing Logistic Regression
2024-12-09 14:12:10,688:INFO:Total runtime is 0.0 minutes
2024-12-09 14:12:10,693:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:10,693:INFO:Initializing create_model()
2024-12-09 14:12:10,693:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0E37D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:10,693:INFO:Checking exceptions
2024-12-09 14:12:10,693:INFO:Importing libraries
2024-12-09 14:12:10,693:INFO:Copying training dataset
2024-12-09 14:12:10,698:INFO:Defining folds
2024-12-09 14:12:10,698:INFO:Declaring metric variables
2024-12-09 14:12:10,702:INFO:Importing untrained model
2024-12-09 14:12:10,708:INFO:Logistic Regression Imported successfully
2024-12-09 14:12:10,716:INFO:Starting cross validation
2024-12-09 14:12:10,718:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:14,972:INFO:Calculating mean and std
2024-12-09 14:12:14,973:INFO:Creating metrics dataframe
2024-12-09 14:12:14,976:INFO:Uploading results into container
2024-12-09 14:12:14,977:INFO:Uploading model into container now
2024-12-09 14:12:14,978:INFO:_master_model_container: 1
2024-12-09 14:12:14,978:INFO:_display_container: 2
2024-12-09 14:12:14,979:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 14:12:14,979:INFO:create_model() successfully completed......................................
2024-12-09 14:12:15,071:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:15,071:INFO:Creating metrics dataframe
2024-12-09 14:12:15,080:INFO:Initializing K Neighbors Classifier
2024-12-09 14:12:15,080:INFO:Total runtime is 0.07320114771525064 minutes
2024-12-09 14:12:15,083:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:15,083:INFO:Initializing create_model()
2024-12-09 14:12:15,083:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0E37D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:15,083:INFO:Checking exceptions
2024-12-09 14:12:15,084:INFO:Importing libraries
2024-12-09 14:12:15,084:INFO:Copying training dataset
2024-12-09 14:12:15,088:INFO:Defining folds
2024-12-09 14:12:15,088:INFO:Declaring metric variables
2024-12-09 14:12:15,091:INFO:Importing untrained model
2024-12-09 14:12:15,097:INFO:K Neighbors Classifier Imported successfully
2024-12-09 14:12:15,107:INFO:Starting cross validation
2024-12-09 14:12:15,108:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:15,390:INFO:Calculating mean and std
2024-12-09 14:12:15,391:INFO:Creating metrics dataframe
2024-12-09 14:12:15,395:INFO:Uploading results into container
2024-12-09 14:12:15,395:INFO:Uploading model into container now
2024-12-09 14:12:15,396:INFO:_master_model_container: 2
2024-12-09 14:12:15,396:INFO:_display_container: 2
2024-12-09 14:12:15,396:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 14:12:15,397:INFO:create_model() successfully completed......................................
2024-12-09 14:12:15,474:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:15,474:INFO:Creating metrics dataframe
2024-12-09 14:12:15,485:INFO:Initializing Naive Bayes
2024-12-09 14:12:15,485:INFO:Total runtime is 0.07994782129923501 minutes
2024-12-09 14:12:15,489:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:15,490:INFO:Initializing create_model()
2024-12-09 14:12:15,490:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0E37D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:15,490:INFO:Checking exceptions
2024-12-09 14:12:15,490:INFO:Importing libraries
2024-12-09 14:12:15,490:INFO:Copying training dataset
2024-12-09 14:12:15,494:INFO:Defining folds
2024-12-09 14:12:15,494:INFO:Declaring metric variables
2024-12-09 14:12:15,497:INFO:Importing untrained model
2024-12-09 14:12:15,503:INFO:Naive Bayes Imported successfully
2024-12-09 14:12:15,511:INFO:Starting cross validation
2024-12-09 14:12:15,512:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:15,770:INFO:Calculating mean and std
2024-12-09 14:12:15,772:INFO:Creating metrics dataframe
2024-12-09 14:12:15,775:INFO:Uploading results into container
2024-12-09 14:12:15,777:INFO:Uploading model into container now
2024-12-09 14:12:15,777:INFO:_master_model_container: 3
2024-12-09 14:12:15,777:INFO:_display_container: 2
2024-12-09 14:12:15,777:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 14:12:15,777:INFO:create_model() successfully completed......................................
2024-12-09 14:12:15,857:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:15,858:INFO:Creating metrics dataframe
2024-12-09 14:12:15,866:INFO:Initializing Decision Tree Classifier
2024-12-09 14:12:15,866:INFO:Total runtime is 0.08631222248077391 minutes
2024-12-09 14:12:15,871:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:15,871:INFO:Initializing create_model()
2024-12-09 14:12:15,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0E37D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:15,871:INFO:Checking exceptions
2024-12-09 14:12:15,871:INFO:Importing libraries
2024-12-09 14:12:15,871:INFO:Copying training dataset
2024-12-09 14:12:15,876:INFO:Defining folds
2024-12-09 14:12:15,876:INFO:Declaring metric variables
2024-12-09 14:12:15,880:INFO:Importing untrained model
2024-12-09 14:12:15,885:INFO:Decision Tree Classifier Imported successfully
2024-12-09 14:12:15,893:INFO:Starting cross validation
2024-12-09 14:12:15,894:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:16,124:INFO:Calculating mean and std
2024-12-09 14:12:16,126:INFO:Creating metrics dataframe
2024-12-09 14:12:16,129:INFO:Uploading results into container
2024-12-09 14:12:16,129:INFO:Uploading model into container now
2024-12-09 14:12:16,130:INFO:_master_model_container: 4
2024-12-09 14:12:16,130:INFO:_display_container: 2
2024-12-09 14:12:16,130:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 14:12:16,130:INFO:create_model() successfully completed......................................
2024-12-09 14:12:16,207:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:16,207:INFO:Creating metrics dataframe
2024-12-09 14:12:16,217:INFO:Initializing SVM - Linear Kernel
2024-12-09 14:12:16,217:INFO:Total runtime is 0.09216079711914062 minutes
2024-12-09 14:12:16,221:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:16,221:INFO:Initializing create_model()
2024-12-09 14:12:16,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0E37D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:16,221:INFO:Checking exceptions
2024-12-09 14:12:16,221:INFO:Importing libraries
2024-12-09 14:12:16,221:INFO:Copying training dataset
2024-12-09 14:12:16,226:INFO:Defining folds
2024-12-09 14:12:16,226:INFO:Declaring metric variables
2024-12-09 14:12:16,230:INFO:Importing untrained model
2024-12-09 14:12:16,235:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 14:12:16,244:INFO:Starting cross validation
2024-12-09 14:12:16,246:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:16,373:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:16,373:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:16,378:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:16,380:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:16,384:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:12:16,392:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:16,412:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:16,467:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:16,468:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:16,475:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:16,478:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:16,478:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:12:16,485:INFO:Calculating mean and std
2024-12-09 14:12:16,487:INFO:Creating metrics dataframe
2024-12-09 14:12:16,490:INFO:Uploading results into container
2024-12-09 14:12:16,490:INFO:Uploading model into container now
2024-12-09 14:12:16,491:INFO:_master_model_container: 5
2024-12-09 14:12:16,491:INFO:_display_container: 2
2024-12-09 14:12:16,491:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 14:12:16,491:INFO:create_model() successfully completed......................................
2024-12-09 14:12:16,569:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:16,569:INFO:Creating metrics dataframe
2024-12-09 14:12:16,579:INFO:Initializing Ridge Classifier
2024-12-09 14:12:16,579:INFO:Total runtime is 0.09819277127583821 minutes
2024-12-09 14:12:16,582:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:16,583:INFO:Initializing create_model()
2024-12-09 14:12:16,583:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0E37D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:16,583:INFO:Checking exceptions
2024-12-09 14:12:16,583:INFO:Importing libraries
2024-12-09 14:12:16,583:INFO:Copying training dataset
2024-12-09 14:12:16,588:INFO:Defining folds
2024-12-09 14:12:16,588:INFO:Declaring metric variables
2024-12-09 14:12:16,591:INFO:Importing untrained model
2024-12-09 14:12:16,597:INFO:Ridge Classifier Imported successfully
2024-12-09 14:12:16,607:INFO:Starting cross validation
2024-12-09 14:12:16,609:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:16,721:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:16,725:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:16,731:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:16,731:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:16,734:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:16,748:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:16,812:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:16,820:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:16,824:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:16,824:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:16,833:INFO:Calculating mean and std
2024-12-09 14:12:16,834:INFO:Creating metrics dataframe
2024-12-09 14:12:16,838:INFO:Uploading results into container
2024-12-09 14:12:16,839:INFO:Uploading model into container now
2024-12-09 14:12:16,839:INFO:_master_model_container: 6
2024-12-09 14:12:16,839:INFO:_display_container: 2
2024-12-09 14:12:16,840:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 14:12:16,840:INFO:create_model() successfully completed......................................
2024-12-09 14:12:16,913:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:16,913:INFO:Creating metrics dataframe
2024-12-09 14:12:16,923:INFO:Initializing Random Forest Classifier
2024-12-09 14:12:16,923:INFO:Total runtime is 0.10392113924026489 minutes
2024-12-09 14:12:16,927:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:16,928:INFO:Initializing create_model()
2024-12-09 14:12:16,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0E37D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:16,928:INFO:Checking exceptions
2024-12-09 14:12:16,928:INFO:Importing libraries
2024-12-09 14:12:16,928:INFO:Copying training dataset
2024-12-09 14:12:16,932:INFO:Defining folds
2024-12-09 14:12:16,932:INFO:Declaring metric variables
2024-12-09 14:12:16,935:INFO:Importing untrained model
2024-12-09 14:12:16,939:INFO:Random Forest Classifier Imported successfully
2024-12-09 14:12:16,947:INFO:Starting cross validation
2024-12-09 14:12:16,949:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:17,991:INFO:Calculating mean and std
2024-12-09 14:12:17,991:INFO:Creating metrics dataframe
2024-12-09 14:12:17,995:INFO:Uploading results into container
2024-12-09 14:12:17,995:INFO:Uploading model into container now
2024-12-09 14:12:17,996:INFO:_master_model_container: 7
2024-12-09 14:12:17,996:INFO:_display_container: 2
2024-12-09 14:12:17,996:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 14:12:17,997:INFO:create_model() successfully completed......................................
2024-12-09 14:12:18,077:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:18,077:INFO:Creating metrics dataframe
2024-12-09 14:12:18,089:INFO:Initializing Quadratic Discriminant Analysis
2024-12-09 14:12:18,089:INFO:Total runtime is 0.12335620721181233 minutes
2024-12-09 14:12:18,093:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:18,093:INFO:Initializing create_model()
2024-12-09 14:12:18,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0E37D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:18,093:INFO:Checking exceptions
2024-12-09 14:12:18,093:INFO:Importing libraries
2024-12-09 14:12:18,093:INFO:Copying training dataset
2024-12-09 14:12:18,097:INFO:Defining folds
2024-12-09 14:12:18,098:INFO:Declaring metric variables
2024-12-09 14:12:18,101:INFO:Importing untrained model
2024-12-09 14:12:18,104:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 14:12:18,115:INFO:Starting cross validation
2024-12-09 14:12:18,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:18,209:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:18,211:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:18,214:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:18,215:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:18,225:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:18,262:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:18,335:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:18,345:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:18,369:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:18,370:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:18,423:INFO:Calculating mean and std
2024-12-09 14:12:18,423:INFO:Creating metrics dataframe
2024-12-09 14:12:18,427:INFO:Uploading results into container
2024-12-09 14:12:18,428:INFO:Uploading model into container now
2024-12-09 14:12:18,429:INFO:_master_model_container: 8
2024-12-09 14:12:18,429:INFO:_display_container: 2
2024-12-09 14:12:18,429:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 14:12:18,429:INFO:create_model() successfully completed......................................
2024-12-09 14:12:18,515:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:18,515:INFO:Creating metrics dataframe
2024-12-09 14:12:18,527:INFO:Initializing Ada Boost Classifier
2024-12-09 14:12:18,527:INFO:Total runtime is 0.13065711657206217 minutes
2024-12-09 14:12:18,531:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:18,531:INFO:Initializing create_model()
2024-12-09 14:12:18,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0E37D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:18,532:INFO:Checking exceptions
2024-12-09 14:12:18,532:INFO:Importing libraries
2024-12-09 14:12:18,532:INFO:Copying training dataset
2024-12-09 14:12:18,536:INFO:Defining folds
2024-12-09 14:12:18,536:INFO:Declaring metric variables
2024-12-09 14:12:18,541:INFO:Importing untrained model
2024-12-09 14:12:18,545:INFO:Ada Boost Classifier Imported successfully
2024-12-09 14:12:18,557:INFO:Starting cross validation
2024-12-09 14:12:18,562:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:19,064:INFO:Calculating mean and std
2024-12-09 14:12:19,066:INFO:Creating metrics dataframe
2024-12-09 14:12:19,069:INFO:Uploading results into container
2024-12-09 14:12:19,070:INFO:Uploading model into container now
2024-12-09 14:12:19,070:INFO:_master_model_container: 9
2024-12-09 14:12:19,071:INFO:_display_container: 2
2024-12-09 14:12:19,071:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 14:12:19,071:INFO:create_model() successfully completed......................................
2024-12-09 14:12:19,153:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:19,153:INFO:Creating metrics dataframe
2024-12-09 14:12:19,166:INFO:Initializing Gradient Boosting Classifier
2024-12-09 14:12:19,166:INFO:Total runtime is 0.14130316178003946 minutes
2024-12-09 14:12:19,169:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:19,169:INFO:Initializing create_model()
2024-12-09 14:12:19,169:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0E37D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:19,169:INFO:Checking exceptions
2024-12-09 14:12:19,169:INFO:Importing libraries
2024-12-09 14:12:19,170:INFO:Copying training dataset
2024-12-09 14:12:19,175:INFO:Defining folds
2024-12-09 14:12:19,176:INFO:Declaring metric variables
2024-12-09 14:12:19,179:INFO:Importing untrained model
2024-12-09 14:12:19,182:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 14:12:19,191:INFO:Starting cross validation
2024-12-09 14:12:19,194:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:19,783:INFO:Calculating mean and std
2024-12-09 14:12:19,783:INFO:Creating metrics dataframe
2024-12-09 14:12:19,787:INFO:Uploading results into container
2024-12-09 14:12:19,788:INFO:Uploading model into container now
2024-12-09 14:12:19,789:INFO:_master_model_container: 10
2024-12-09 14:12:19,789:INFO:_display_container: 2
2024-12-09 14:12:19,791:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 14:12:19,792:INFO:create_model() successfully completed......................................
2024-12-09 14:12:19,904:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:19,905:INFO:Creating metrics dataframe
2024-12-09 14:12:19,918:INFO:Initializing Linear Discriminant Analysis
2024-12-09 14:12:19,919:INFO:Total runtime is 0.15384827057520548 minutes
2024-12-09 14:12:19,925:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:19,925:INFO:Initializing create_model()
2024-12-09 14:12:19,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0E37D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:19,925:INFO:Checking exceptions
2024-12-09 14:12:19,925:INFO:Importing libraries
2024-12-09 14:12:19,925:INFO:Copying training dataset
2024-12-09 14:12:19,930:INFO:Defining folds
2024-12-09 14:12:19,930:INFO:Declaring metric variables
2024-12-09 14:12:19,936:INFO:Importing untrained model
2024-12-09 14:12:19,943:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 14:12:19,953:INFO:Starting cross validation
2024-12-09 14:12:19,954:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:20,223:INFO:Calculating mean and std
2024-12-09 14:12:20,225:INFO:Creating metrics dataframe
2024-12-09 14:12:20,228:INFO:Uploading results into container
2024-12-09 14:12:20,229:INFO:Uploading model into container now
2024-12-09 14:12:20,230:INFO:_master_model_container: 11
2024-12-09 14:12:20,230:INFO:_display_container: 2
2024-12-09 14:12:20,230:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 14:12:20,231:INFO:create_model() successfully completed......................................
2024-12-09 14:12:20,330:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:20,330:INFO:Creating metrics dataframe
2024-12-09 14:12:20,344:INFO:Initializing Extra Trees Classifier
2024-12-09 14:12:20,344:INFO:Total runtime is 0.16094343662261962 minutes
2024-12-09 14:12:20,348:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:20,348:INFO:Initializing create_model()
2024-12-09 14:12:20,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0E37D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:20,348:INFO:Checking exceptions
2024-12-09 14:12:20,349:INFO:Importing libraries
2024-12-09 14:12:20,349:INFO:Copying training dataset
2024-12-09 14:12:20,353:INFO:Defining folds
2024-12-09 14:12:20,353:INFO:Declaring metric variables
2024-12-09 14:12:20,359:INFO:Importing untrained model
2024-12-09 14:12:20,364:INFO:Extra Trees Classifier Imported successfully
2024-12-09 14:12:20,372:INFO:Starting cross validation
2024-12-09 14:12:20,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:21,287:INFO:Calculating mean and std
2024-12-09 14:12:21,288:INFO:Creating metrics dataframe
2024-12-09 14:12:21,293:INFO:Uploading results into container
2024-12-09 14:12:21,294:INFO:Uploading model into container now
2024-12-09 14:12:21,294:INFO:_master_model_container: 12
2024-12-09 14:12:21,294:INFO:_display_container: 2
2024-12-09 14:12:21,295:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 14:12:21,295:INFO:create_model() successfully completed......................................
2024-12-09 14:12:21,421:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:21,421:INFO:Creating metrics dataframe
2024-12-09 14:12:21,435:INFO:Initializing Light Gradient Boosting Machine
2024-12-09 14:12:21,435:INFO:Total runtime is 0.1791170318921407 minutes
2024-12-09 14:12:21,439:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:21,439:INFO:Initializing create_model()
2024-12-09 14:12:21,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0E37D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:21,439:INFO:Checking exceptions
2024-12-09 14:12:21,439:INFO:Importing libraries
2024-12-09 14:12:21,440:INFO:Copying training dataset
2024-12-09 14:12:21,444:INFO:Defining folds
2024-12-09 14:12:21,444:INFO:Declaring metric variables
2024-12-09 14:12:21,448:INFO:Importing untrained model
2024-12-09 14:12:21,452:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:12:21,462:INFO:Starting cross validation
2024-12-09 14:12:21,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:22,509:INFO:Calculating mean and std
2024-12-09 14:12:22,511:INFO:Creating metrics dataframe
2024-12-09 14:12:22,514:INFO:Uploading results into container
2024-12-09 14:12:22,515:INFO:Uploading model into container now
2024-12-09 14:12:22,516:INFO:_master_model_container: 13
2024-12-09 14:12:22,516:INFO:_display_container: 2
2024-12-09 14:12:22,518:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:12:22,518:INFO:create_model() successfully completed......................................
2024-12-09 14:12:22,598:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:22,599:INFO:Creating metrics dataframe
2024-12-09 14:12:22,612:INFO:Initializing Dummy Classifier
2024-12-09 14:12:22,612:INFO:Total runtime is 0.19873095353444417 minutes
2024-12-09 14:12:22,615:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:22,616:INFO:Initializing create_model()
2024-12-09 14:12:22,616:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0E37D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:22,616:INFO:Checking exceptions
2024-12-09 14:12:22,616:INFO:Importing libraries
2024-12-09 14:12:22,616:INFO:Copying training dataset
2024-12-09 14:12:22,620:INFO:Defining folds
2024-12-09 14:12:22,621:INFO:Declaring metric variables
2024-12-09 14:12:22,624:INFO:Importing untrained model
2024-12-09 14:12:22,629:INFO:Dummy Classifier Imported successfully
2024-12-09 14:12:22,638:INFO:Starting cross validation
2024-12-09 14:12:22,640:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:22,758:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:12:22,760:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:12:22,762:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:12:22,768:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:12:22,779:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:12:22,787:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:12:22,847:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:12:22,847:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:12:22,854:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:12:22,855:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:12:22,859:INFO:Calculating mean and std
2024-12-09 14:12:22,860:INFO:Creating metrics dataframe
2024-12-09 14:12:22,864:INFO:Uploading results into container
2024-12-09 14:12:22,864:INFO:Uploading model into container now
2024-12-09 14:12:22,864:INFO:_master_model_container: 14
2024-12-09 14:12:22,865:INFO:_display_container: 2
2024-12-09 14:12:22,865:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-12-09 14:12:22,865:INFO:create_model() successfully completed......................................
2024-12-09 14:12:22,942:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:22,942:INFO:Creating metrics dataframe
2024-12-09 14:12:22,964:INFO:Initializing create_model()
2024-12-09 14:12:22,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:22,964:INFO:Checking exceptions
2024-12-09 14:12:22,966:INFO:Importing libraries
2024-12-09 14:12:22,966:INFO:Copying training dataset
2024-12-09 14:12:22,969:INFO:Defining folds
2024-12-09 14:12:22,969:INFO:Declaring metric variables
2024-12-09 14:12:22,969:INFO:Importing untrained model
2024-12-09 14:12:22,969:INFO:Declaring custom model
2024-12-09 14:12:22,970:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:12:22,971:INFO:Cross validation set to False
2024-12-09 14:12:22,971:INFO:Fitting Model
2024-12-09 14:12:23,018:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 14:12:23,018:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.
2024-12-09 14:12:23,018:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 14:12:23,018:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 14:12:23,018:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 14:12:23,018:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 14:12:23,019:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 14:12:23,019:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 14:12:23,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:23,054:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:12:23,054:INFO:create_model() successfully completed......................................
2024-12-09 14:12:23,138:INFO:Initializing create_model()
2024-12-09 14:12:23,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:23,139:INFO:Checking exceptions
2024-12-09 14:12:23,141:INFO:Importing libraries
2024-12-09 14:12:23,141:INFO:Copying training dataset
2024-12-09 14:12:23,147:INFO:Defining folds
2024-12-09 14:12:23,148:INFO:Declaring metric variables
2024-12-09 14:12:23,148:INFO:Importing untrained model
2024-12-09 14:12:23,148:INFO:Declaring custom model
2024-12-09 14:12:23,148:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 14:12:23,149:INFO:Cross validation set to False
2024-12-09 14:12:23,149:INFO:Fitting Model
2024-12-09 14:12:23,295:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 14:12:23,295:INFO:create_model() successfully completed......................................
2024-12-09 14:12:23,377:INFO:Initializing create_model()
2024-12-09 14:12:23,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:23,377:INFO:Checking exceptions
2024-12-09 14:12:23,379:INFO:Importing libraries
2024-12-09 14:12:23,379:INFO:Copying training dataset
2024-12-09 14:12:23,383:INFO:Defining folds
2024-12-09 14:12:23,383:INFO:Declaring metric variables
2024-12-09 14:12:23,383:INFO:Importing untrained model
2024-12-09 14:12:23,383:INFO:Declaring custom model
2024-12-09 14:12:23,384:INFO:Random Forest Classifier Imported successfully
2024-12-09 14:12:23,385:INFO:Cross validation set to False
2024-12-09 14:12:23,385:INFO:Fitting Model
2024-12-09 14:12:23,594:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 14:12:23,594:INFO:create_model() successfully completed......................................
2024-12-09 14:12:23,673:INFO:Initializing create_model()
2024-12-09 14:12:23,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:23,674:INFO:Checking exceptions
2024-12-09 14:12:23,678:INFO:Importing libraries
2024-12-09 14:12:23,678:INFO:Copying training dataset
2024-12-09 14:12:23,682:INFO:Defining folds
2024-12-09 14:12:23,682:INFO:Declaring metric variables
2024-12-09 14:12:23,682:INFO:Importing untrained model
2024-12-09 14:12:23,682:INFO:Declaring custom model
2024-12-09 14:12:23,683:INFO:Ada Boost Classifier Imported successfully
2024-12-09 14:12:23,684:INFO:Cross validation set to False
2024-12-09 14:12:23,684:INFO:Fitting Model
2024-12-09 14:12:23,797:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 14:12:23,797:INFO:create_model() successfully completed......................................
2024-12-09 14:12:23,877:INFO:Initializing create_model()
2024-12-09 14:12:23,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:23,878:INFO:Checking exceptions
2024-12-09 14:12:23,880:INFO:Importing libraries
2024-12-09 14:12:23,880:INFO:Copying training dataset
2024-12-09 14:12:23,883:INFO:Defining folds
2024-12-09 14:12:23,883:INFO:Declaring metric variables
2024-12-09 14:12:23,883:INFO:Importing untrained model
2024-12-09 14:12:23,883:INFO:Declaring custom model
2024-12-09 14:12:23,884:INFO:Logistic Regression Imported successfully
2024-12-09 14:12:23,885:INFO:Cross validation set to False
2024-12-09 14:12:23,885:INFO:Fitting Model
2024-12-09 14:12:23,970:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 14:12:23,970:INFO:create_model() successfully completed......................................
2024-12-09 14:12:24,050:INFO:Initializing create_model()
2024-12-09 14:12:24,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:24,050:INFO:Checking exceptions
2024-12-09 14:12:24,053:INFO:Importing libraries
2024-12-09 14:12:24,053:INFO:Copying training dataset
2024-12-09 14:12:24,056:INFO:Defining folds
2024-12-09 14:12:24,056:INFO:Declaring metric variables
2024-12-09 14:12:24,057:INFO:Importing untrained model
2024-12-09 14:12:24,057:INFO:Declaring custom model
2024-12-09 14:12:24,057:INFO:Extra Trees Classifier Imported successfully
2024-12-09 14:12:24,058:INFO:Cross validation set to False
2024-12-09 14:12:24,058:INFO:Fitting Model
2024-12-09 14:12:24,235:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 14:12:24,235:INFO:create_model() successfully completed......................................
2024-12-09 14:12:24,325:INFO:Initializing create_model()
2024-12-09 14:12:24,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:24,326:INFO:Checking exceptions
2024-12-09 14:12:24,330:INFO:Importing libraries
2024-12-09 14:12:24,331:INFO:Copying training dataset
2024-12-09 14:12:24,334:INFO:Defining folds
2024-12-09 14:12:24,334:INFO:Declaring metric variables
2024-12-09 14:12:24,334:INFO:Importing untrained model
2024-12-09 14:12:24,334:INFO:Declaring custom model
2024-12-09 14:12:24,335:INFO:Ridge Classifier Imported successfully
2024-12-09 14:12:24,336:INFO:Cross validation set to False
2024-12-09 14:12:24,336:INFO:Fitting Model
2024-12-09 14:12:24,382:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 14:12:24,382:INFO:create_model() successfully completed......................................
2024-12-09 14:12:24,462:INFO:Initializing create_model()
2024-12-09 14:12:24,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:24,462:INFO:Checking exceptions
2024-12-09 14:12:24,465:INFO:Importing libraries
2024-12-09 14:12:24,465:INFO:Copying training dataset
2024-12-09 14:12:24,468:INFO:Defining folds
2024-12-09 14:12:24,468:INFO:Declaring metric variables
2024-12-09 14:12:24,468:INFO:Importing untrained model
2024-12-09 14:12:24,468:INFO:Declaring custom model
2024-12-09 14:12:24,469:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 14:12:24,469:INFO:Cross validation set to False
2024-12-09 14:12:24,470:INFO:Fitting Model
2024-12-09 14:12:24,515:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 14:12:24,515:INFO:create_model() successfully completed......................................
2024-12-09 14:12:24,596:INFO:Initializing create_model()
2024-12-09 14:12:24,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:24,597:INFO:Checking exceptions
2024-12-09 14:12:24,600:INFO:Importing libraries
2024-12-09 14:12:24,600:INFO:Copying training dataset
2024-12-09 14:12:24,603:INFO:Defining folds
2024-12-09 14:12:24,603:INFO:Declaring metric variables
2024-12-09 14:12:24,603:INFO:Importing untrained model
2024-12-09 14:12:24,603:INFO:Declaring custom model
2024-12-09 14:12:24,604:INFO:Naive Bayes Imported successfully
2024-12-09 14:12:24,605:INFO:Cross validation set to False
2024-12-09 14:12:24,605:INFO:Fitting Model
2024-12-09 14:12:24,657:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 14:12:24,657:INFO:create_model() successfully completed......................................
2024-12-09 14:12:24,738:INFO:Initializing create_model()
2024-12-09 14:12:24,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:24,739:INFO:Checking exceptions
2024-12-09 14:12:24,741:INFO:Importing libraries
2024-12-09 14:12:24,741:INFO:Copying training dataset
2024-12-09 14:12:24,746:INFO:Defining folds
2024-12-09 14:12:24,746:INFO:Declaring metric variables
2024-12-09 14:12:24,746:INFO:Importing untrained model
2024-12-09 14:12:24,746:INFO:Declaring custom model
2024-12-09 14:12:24,747:INFO:Decision Tree Classifier Imported successfully
2024-12-09 14:12:24,748:INFO:Cross validation set to False
2024-12-09 14:12:24,748:INFO:Fitting Model
2024-12-09 14:12:24,792:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 14:12:24,792:INFO:create_model() successfully completed......................................
2024-12-09 14:12:24,872:INFO:Initializing create_model()
2024-12-09 14:12:24,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:24,872:INFO:Checking exceptions
2024-12-09 14:12:24,874:INFO:Importing libraries
2024-12-09 14:12:24,874:INFO:Copying training dataset
2024-12-09 14:12:24,879:INFO:Defining folds
2024-12-09 14:12:24,879:INFO:Declaring metric variables
2024-12-09 14:12:24,880:INFO:Importing untrained model
2024-12-09 14:12:24,880:INFO:Declaring custom model
2024-12-09 14:12:24,880:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 14:12:24,881:INFO:Cross validation set to False
2024-12-09 14:12:24,881:INFO:Fitting Model
2024-12-09 14:12:24,926:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:24,926:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 14:12:24,926:INFO:create_model() successfully completed......................................
2024-12-09 14:12:25,006:INFO:Initializing create_model()
2024-12-09 14:12:25,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:25,006:INFO:Checking exceptions
2024-12-09 14:12:25,009:INFO:Importing libraries
2024-12-09 14:12:25,009:INFO:Copying training dataset
2024-12-09 14:12:25,013:INFO:Defining folds
2024-12-09 14:12:25,013:INFO:Declaring metric variables
2024-12-09 14:12:25,014:INFO:Importing untrained model
2024-12-09 14:12:25,014:INFO:Declaring custom model
2024-12-09 14:12:25,014:INFO:K Neighbors Classifier Imported successfully
2024-12-09 14:12:25,015:INFO:Cross validation set to False
2024-12-09 14:12:25,015:INFO:Fitting Model
2024-12-09 14:12:25,060:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 14:12:25,060:INFO:create_model() successfully completed......................................
2024-12-09 14:12:25,140:INFO:Initializing create_model()
2024-12-09 14:12:25,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:25,140:INFO:Checking exceptions
2024-12-09 14:12:25,142:INFO:Importing libraries
2024-12-09 14:12:25,142:INFO:Copying training dataset
2024-12-09 14:12:25,147:INFO:Defining folds
2024-12-09 14:12:25,147:INFO:Declaring metric variables
2024-12-09 14:12:25,147:INFO:Importing untrained model
2024-12-09 14:12:25,147:INFO:Declaring custom model
2024-12-09 14:12:25,148:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 14:12:25,149:INFO:Cross validation set to False
2024-12-09 14:12:25,149:INFO:Fitting Model
2024-12-09 14:12:25,194:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 14:12:25,194:INFO:create_model() successfully completed......................................
2024-12-09 14:12:25,276:INFO:Initializing create_model()
2024-12-09 14:12:25,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:25,277:INFO:Checking exceptions
2024-12-09 14:12:25,280:INFO:Importing libraries
2024-12-09 14:12:25,281:INFO:Copying training dataset
2024-12-09 14:12:25,284:INFO:Defining folds
2024-12-09 14:12:25,284:INFO:Declaring metric variables
2024-12-09 14:12:25,284:INFO:Importing untrained model
2024-12-09 14:12:25,284:INFO:Declaring custom model
2024-12-09 14:12:25,285:INFO:Dummy Classifier Imported successfully
2024-12-09 14:12:25,286:INFO:Cross validation set to False
2024-12-09 14:12:25,286:INFO:Fitting Model
2024-12-09 14:12:25,330:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-12-09 14:12:25,330:INFO:create_model() successfully completed......................................
2024-12-09 14:12:25,457:INFO:_master_model_container: 14
2024-12-09 14:12:25,458:INFO:_display_container: 2
2024-12-09 14:12:25,460:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')]
2024-12-09 14:12:25,461:INFO:compare_models() successfully completed......................................
2024-12-09 14:12:25,464:INFO:Initializing finalize_model()
2024-12-09 14:12:25,464:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')], fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-09 14:12:25,468:INFO:Finalizing [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')]
2024-12-09 14:12:25,473:INFO:Initializing create_model()
2024-12-09 14:12:25,473:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')], fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:25,473:INFO:Checking exceptions
2024-12-09 14:12:25,484:INFO:Initializing compare_models()
2024-12-09 14:12:25,485:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, 'include': None, 'exclude': ['dummy', [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')]], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['dummy', [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), DummyClassifier(constant=None, random_state=123, strategy='prior')]])
2024-12-09 14:12:25,485:INFO:Checking exceptions
2024-12-09 14:12:25,492:INFO:Preparing display monitor
2024-12-09 14:12:25,532:INFO:Initializing Logistic Regression
2024-12-09 14:12:25,532:INFO:Total runtime is 0.0 minutes
2024-12-09 14:12:25,537:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:25,538:INFO:Initializing create_model()
2024-12-09 14:12:25,538:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C12A9460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:25,538:INFO:Checking exceptions
2024-12-09 14:12:25,539:INFO:Importing libraries
2024-12-09 14:12:25,539:INFO:Copying training dataset
2024-12-09 14:12:25,544:INFO:Defining folds
2024-12-09 14:12:25,544:INFO:Declaring metric variables
2024-12-09 14:12:25,550:INFO:Importing untrained model
2024-12-09 14:12:25,554:INFO:Logistic Regression Imported successfully
2024-12-09 14:12:25,562:INFO:Starting cross validation
2024-12-09 14:12:25,564:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:25,890:INFO:Calculating mean and std
2024-12-09 14:12:25,891:INFO:Creating metrics dataframe
2024-12-09 14:12:25,894:INFO:Uploading results into container
2024-12-09 14:12:25,894:INFO:Uploading model into container now
2024-12-09 14:12:25,895:INFO:_master_model_container: 15
2024-12-09 14:12:25,895:INFO:_display_container: 3
2024-12-09 14:12:25,895:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 14:12:25,895:INFO:create_model() successfully completed......................................
2024-12-09 14:12:25,969:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:25,969:INFO:Creating metrics dataframe
2024-12-09 14:12:25,977:INFO:Initializing K Neighbors Classifier
2024-12-09 14:12:25,977:INFO:Total runtime is 0.007423166433970133 minutes
2024-12-09 14:12:25,981:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:25,981:INFO:Initializing create_model()
2024-12-09 14:12:25,981:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C12A9460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:25,981:INFO:Checking exceptions
2024-12-09 14:12:25,981:INFO:Importing libraries
2024-12-09 14:12:25,981:INFO:Copying training dataset
2024-12-09 14:12:25,985:INFO:Defining folds
2024-12-09 14:12:25,985:INFO:Declaring metric variables
2024-12-09 14:12:25,988:INFO:Importing untrained model
2024-12-09 14:12:25,991:INFO:K Neighbors Classifier Imported successfully
2024-12-09 14:12:26,001:INFO:Starting cross validation
2024-12-09 14:12:26,003:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:26,270:INFO:Calculating mean and std
2024-12-09 14:12:26,271:INFO:Creating metrics dataframe
2024-12-09 14:12:26,274:INFO:Uploading results into container
2024-12-09 14:12:26,274:INFO:Uploading model into container now
2024-12-09 14:12:26,274:INFO:_master_model_container: 16
2024-12-09 14:12:26,275:INFO:_display_container: 3
2024-12-09 14:12:26,275:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 14:12:26,275:INFO:create_model() successfully completed......................................
2024-12-09 14:12:26,353:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:26,353:INFO:Creating metrics dataframe
2024-12-09 14:12:26,362:INFO:Initializing Naive Bayes
2024-12-09 14:12:26,363:INFO:Total runtime is 0.01385648250579834 minutes
2024-12-09 14:12:26,366:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:26,367:INFO:Initializing create_model()
2024-12-09 14:12:26,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C12A9460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:26,367:INFO:Checking exceptions
2024-12-09 14:12:26,367:INFO:Importing libraries
2024-12-09 14:12:26,367:INFO:Copying training dataset
2024-12-09 14:12:26,371:INFO:Defining folds
2024-12-09 14:12:26,371:INFO:Declaring metric variables
2024-12-09 14:12:26,374:INFO:Importing untrained model
2024-12-09 14:12:26,378:INFO:Naive Bayes Imported successfully
2024-12-09 14:12:26,389:INFO:Starting cross validation
2024-12-09 14:12:26,390:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:26,655:INFO:Calculating mean and std
2024-12-09 14:12:26,656:INFO:Creating metrics dataframe
2024-12-09 14:12:26,659:INFO:Uploading results into container
2024-12-09 14:12:26,659:INFO:Uploading model into container now
2024-12-09 14:12:26,660:INFO:_master_model_container: 17
2024-12-09 14:12:26,660:INFO:_display_container: 3
2024-12-09 14:12:26,660:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 14:12:26,660:INFO:create_model() successfully completed......................................
2024-12-09 14:12:26,743:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:26,743:INFO:Creating metrics dataframe
2024-12-09 14:12:26,754:INFO:Initializing Decision Tree Classifier
2024-12-09 14:12:26,754:INFO:Total runtime is 0.02037442127863566 minutes
2024-12-09 14:12:26,758:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:26,759:INFO:Initializing create_model()
2024-12-09 14:12:26,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C12A9460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:26,759:INFO:Checking exceptions
2024-12-09 14:12:26,759:INFO:Importing libraries
2024-12-09 14:12:26,759:INFO:Copying training dataset
2024-12-09 14:12:26,764:INFO:Defining folds
2024-12-09 14:12:26,765:INFO:Declaring metric variables
2024-12-09 14:12:26,768:INFO:Importing untrained model
2024-12-09 14:12:26,772:INFO:Decision Tree Classifier Imported successfully
2024-12-09 14:12:26,780:INFO:Starting cross validation
2024-12-09 14:12:26,783:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:27,086:INFO:Calculating mean and std
2024-12-09 14:12:27,087:INFO:Creating metrics dataframe
2024-12-09 14:12:27,091:INFO:Uploading results into container
2024-12-09 14:12:27,091:INFO:Uploading model into container now
2024-12-09 14:12:27,092:INFO:_master_model_container: 18
2024-12-09 14:12:27,092:INFO:_display_container: 3
2024-12-09 14:12:27,092:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 14:12:27,093:INFO:create_model() successfully completed......................................
2024-12-09 14:12:27,170:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:27,170:INFO:Creating metrics dataframe
2024-12-09 14:12:27,179:INFO:Initializing SVM - Linear Kernel
2024-12-09 14:12:27,179:INFO:Total runtime is 0.027460877100626627 minutes
2024-12-09 14:12:27,183:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:27,183:INFO:Initializing create_model()
2024-12-09 14:12:27,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C12A9460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:27,184:INFO:Checking exceptions
2024-12-09 14:12:27,184:INFO:Importing libraries
2024-12-09 14:12:27,184:INFO:Copying training dataset
2024-12-09 14:12:27,188:INFO:Defining folds
2024-12-09 14:12:27,188:INFO:Declaring metric variables
2024-12-09 14:12:27,191:INFO:Importing untrained model
2024-12-09 14:12:27,196:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 14:12:27,205:INFO:Starting cross validation
2024-12-09 14:12:27,206:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:27,320:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:27,321:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:27,321:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:27,325:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:12:27,327:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:27,338:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:27,346:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:27,412:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:27,414:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:27,417:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:27,418:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:12:27,425:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:27,434:INFO:Calculating mean and std
2024-12-09 14:12:27,435:INFO:Creating metrics dataframe
2024-12-09 14:12:27,440:INFO:Uploading results into container
2024-12-09 14:12:27,440:INFO:Uploading model into container now
2024-12-09 14:12:27,441:INFO:_master_model_container: 19
2024-12-09 14:12:27,441:INFO:_display_container: 3
2024-12-09 14:12:27,442:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 14:12:27,442:INFO:create_model() successfully completed......................................
2024-12-09 14:12:27,523:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:27,523:INFO:Creating metrics dataframe
2024-12-09 14:12:27,535:INFO:Initializing Ridge Classifier
2024-12-09 14:12:27,535:INFO:Total runtime is 0.033383027712504065 minutes
2024-12-09 14:12:27,538:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:27,539:INFO:Initializing create_model()
2024-12-09 14:12:27,539:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C12A9460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:27,539:INFO:Checking exceptions
2024-12-09 14:12:27,539:INFO:Importing libraries
2024-12-09 14:12:27,539:INFO:Copying training dataset
2024-12-09 14:12:27,543:INFO:Defining folds
2024-12-09 14:12:27,543:INFO:Declaring metric variables
2024-12-09 14:12:27,548:INFO:Importing untrained model
2024-12-09 14:12:27,554:INFO:Ridge Classifier Imported successfully
2024-12-09 14:12:27,562:INFO:Starting cross validation
2024-12-09 14:12:27,563:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:27,682:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:27,693:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:27,712:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:27,729:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:27,741:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:27,746:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:27,790:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:27,804:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:27,833:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:27,837:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:27,845:INFO:Calculating mean and std
2024-12-09 14:12:27,846:INFO:Creating metrics dataframe
2024-12-09 14:12:27,849:INFO:Uploading results into container
2024-12-09 14:12:27,850:INFO:Uploading model into container now
2024-12-09 14:12:27,851:INFO:_master_model_container: 20
2024-12-09 14:12:27,851:INFO:_display_container: 3
2024-12-09 14:12:27,851:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 14:12:27,851:INFO:create_model() successfully completed......................................
2024-12-09 14:12:27,927:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:27,927:INFO:Creating metrics dataframe
2024-12-09 14:12:27,938:INFO:Initializing Random Forest Classifier
2024-12-09 14:12:27,938:INFO:Total runtime is 0.04010799328486124 minutes
2024-12-09 14:12:27,941:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:27,941:INFO:Initializing create_model()
2024-12-09 14:12:27,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C12A9460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:27,941:INFO:Checking exceptions
2024-12-09 14:12:27,941:INFO:Importing libraries
2024-12-09 14:12:27,941:INFO:Copying training dataset
2024-12-09 14:12:27,945:INFO:Defining folds
2024-12-09 14:12:27,945:INFO:Declaring metric variables
2024-12-09 14:12:27,949:INFO:Importing untrained model
2024-12-09 14:12:27,953:INFO:Random Forest Classifier Imported successfully
2024-12-09 14:12:27,963:INFO:Starting cross validation
2024-12-09 14:12:27,964:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:28,711:INFO:Calculating mean and std
2024-12-09 14:12:28,711:INFO:Creating metrics dataframe
2024-12-09 14:12:28,716:INFO:Uploading results into container
2024-12-09 14:12:28,717:INFO:Uploading model into container now
2024-12-09 14:12:28,717:INFO:_master_model_container: 21
2024-12-09 14:12:28,717:INFO:_display_container: 3
2024-12-09 14:12:28,718:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 14:12:28,718:INFO:create_model() successfully completed......................................
2024-12-09 14:12:28,806:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:28,807:INFO:Creating metrics dataframe
2024-12-09 14:12:28,820:INFO:Initializing Quadratic Discriminant Analysis
2024-12-09 14:12:28,820:INFO:Total runtime is 0.05480141242345173 minutes
2024-12-09 14:12:28,824:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:28,824:INFO:Initializing create_model()
2024-12-09 14:12:28,824:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C12A9460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:28,824:INFO:Checking exceptions
2024-12-09 14:12:28,824:INFO:Importing libraries
2024-12-09 14:12:28,824:INFO:Copying training dataset
2024-12-09 14:12:28,828:INFO:Defining folds
2024-12-09 14:12:28,829:INFO:Declaring metric variables
2024-12-09 14:12:28,832:INFO:Importing untrained model
2024-12-09 14:12:28,836:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 14:12:28,847:INFO:Starting cross validation
2024-12-09 14:12:28,850:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:28,933:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:28,938:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:28,944:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:28,947:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:28,956:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:28,970:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:29,042:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:29,044:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:29,056:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:29,056:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:12:29,094:INFO:Calculating mean and std
2024-12-09 14:12:29,094:INFO:Creating metrics dataframe
2024-12-09 14:12:29,098:INFO:Uploading results into container
2024-12-09 14:12:29,099:INFO:Uploading model into container now
2024-12-09 14:12:29,100:INFO:_master_model_container: 22
2024-12-09 14:12:29,100:INFO:_display_container: 3
2024-12-09 14:12:29,101:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 14:12:29,101:INFO:create_model() successfully completed......................................
2024-12-09 14:12:29,179:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:29,179:INFO:Creating metrics dataframe
2024-12-09 14:12:29,192:INFO:Initializing Ada Boost Classifier
2024-12-09 14:12:29,192:INFO:Total runtime is 0.06099896430969237 minutes
2024-12-09 14:12:29,196:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:29,196:INFO:Initializing create_model()
2024-12-09 14:12:29,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C12A9460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:29,196:INFO:Checking exceptions
2024-12-09 14:12:29,196:INFO:Importing libraries
2024-12-09 14:12:29,196:INFO:Copying training dataset
2024-12-09 14:12:29,201:INFO:Defining folds
2024-12-09 14:12:29,201:INFO:Declaring metric variables
2024-12-09 14:12:29,204:INFO:Importing untrained model
2024-12-09 14:12:29,209:INFO:Ada Boost Classifier Imported successfully
2024-12-09 14:12:29,223:INFO:Starting cross validation
2024-12-09 14:12:29,225:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:29,659:INFO:Calculating mean and std
2024-12-09 14:12:29,660:INFO:Creating metrics dataframe
2024-12-09 14:12:29,663:INFO:Uploading results into container
2024-12-09 14:12:29,664:INFO:Uploading model into container now
2024-12-09 14:12:29,664:INFO:_master_model_container: 23
2024-12-09 14:12:29,665:INFO:_display_container: 3
2024-12-09 14:12:29,665:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 14:12:29,665:INFO:create_model() successfully completed......................................
2024-12-09 14:12:29,744:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:29,744:INFO:Creating metrics dataframe
2024-12-09 14:12:29,756:INFO:Initializing Gradient Boosting Classifier
2024-12-09 14:12:29,756:INFO:Total runtime is 0.07041233777999877 minutes
2024-12-09 14:12:29,759:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:29,759:INFO:Initializing create_model()
2024-12-09 14:12:29,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C12A9460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:29,759:INFO:Checking exceptions
2024-12-09 14:12:29,759:INFO:Importing libraries
2024-12-09 14:12:29,760:INFO:Copying training dataset
2024-12-09 14:12:29,764:INFO:Defining folds
2024-12-09 14:12:29,764:INFO:Declaring metric variables
2024-12-09 14:12:29,769:INFO:Importing untrained model
2024-12-09 14:12:29,772:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 14:12:29,782:INFO:Starting cross validation
2024-12-09 14:12:29,785:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:30,313:INFO:Calculating mean and std
2024-12-09 14:12:30,314:INFO:Creating metrics dataframe
2024-12-09 14:12:30,318:INFO:Uploading results into container
2024-12-09 14:12:30,319:INFO:Uploading model into container now
2024-12-09 14:12:30,319:INFO:_master_model_container: 24
2024-12-09 14:12:30,319:INFO:_display_container: 3
2024-12-09 14:12:30,320:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 14:12:30,320:INFO:create_model() successfully completed......................................
2024-12-09 14:12:30,396:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:30,396:INFO:Creating metrics dataframe
2024-12-09 14:12:30,408:INFO:Initializing Linear Discriminant Analysis
2024-12-09 14:12:30,408:INFO:Total runtime is 0.08126744429270424 minutes
2024-12-09 14:12:30,411:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:30,411:INFO:Initializing create_model()
2024-12-09 14:12:30,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C12A9460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:30,411:INFO:Checking exceptions
2024-12-09 14:12:30,411:INFO:Importing libraries
2024-12-09 14:12:30,412:INFO:Copying training dataset
2024-12-09 14:12:30,415:INFO:Defining folds
2024-12-09 14:12:30,416:INFO:Declaring metric variables
2024-12-09 14:12:30,419:INFO:Importing untrained model
2024-12-09 14:12:30,423:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 14:12:30,432:INFO:Starting cross validation
2024-12-09 14:12:30,434:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:30,712:INFO:Calculating mean and std
2024-12-09 14:12:30,713:INFO:Creating metrics dataframe
2024-12-09 14:12:30,718:INFO:Uploading results into container
2024-12-09 14:12:30,719:INFO:Uploading model into container now
2024-12-09 14:12:30,719:INFO:_master_model_container: 25
2024-12-09 14:12:30,719:INFO:_display_container: 3
2024-12-09 14:12:30,720:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 14:12:30,720:INFO:create_model() successfully completed......................................
2024-12-09 14:12:30,797:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:30,797:INFO:Creating metrics dataframe
2024-12-09 14:12:30,811:INFO:Initializing Extra Trees Classifier
2024-12-09 14:12:30,811:INFO:Total runtime is 0.08798364400863645 minutes
2024-12-09 14:12:30,814:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:30,814:INFO:Initializing create_model()
2024-12-09 14:12:30,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C12A9460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:30,814:INFO:Checking exceptions
2024-12-09 14:12:30,814:INFO:Importing libraries
2024-12-09 14:12:30,815:INFO:Copying training dataset
2024-12-09 14:12:30,820:INFO:Defining folds
2024-12-09 14:12:30,820:INFO:Declaring metric variables
2024-12-09 14:12:30,824:INFO:Importing untrained model
2024-12-09 14:12:30,827:INFO:Extra Trees Classifier Imported successfully
2024-12-09 14:12:30,837:INFO:Starting cross validation
2024-12-09 14:12:30,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:31,605:INFO:Calculating mean and std
2024-12-09 14:12:31,606:INFO:Creating metrics dataframe
2024-12-09 14:12:31,609:INFO:Uploading results into container
2024-12-09 14:12:31,610:INFO:Uploading model into container now
2024-12-09 14:12:31,610:INFO:_master_model_container: 26
2024-12-09 14:12:31,610:INFO:_display_container: 3
2024-12-09 14:12:31,611:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 14:12:31,611:INFO:create_model() successfully completed......................................
2024-12-09 14:12:31,693:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:31,693:INFO:Creating metrics dataframe
2024-12-09 14:12:31,707:INFO:Initializing Light Gradient Boosting Machine
2024-12-09 14:12:31,707:INFO:Total runtime is 0.1029231270154317 minutes
2024-12-09 14:12:31,710:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:31,710:INFO:Initializing create_model()
2024-12-09 14:12:31,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C12A9460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:31,710:INFO:Checking exceptions
2024-12-09 14:12:31,710:INFO:Importing libraries
2024-12-09 14:12:31,711:INFO:Copying training dataset
2024-12-09 14:12:31,715:INFO:Defining folds
2024-12-09 14:12:31,715:INFO:Declaring metric variables
2024-12-09 14:12:31,720:INFO:Importing untrained model
2024-12-09 14:12:31,724:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:12:31,732:INFO:Starting cross validation
2024-12-09 14:12:31,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:32,628:INFO:Calculating mean and std
2024-12-09 14:12:32,633:INFO:Creating metrics dataframe
2024-12-09 14:12:32,639:INFO:Uploading results into container
2024-12-09 14:12:32,639:INFO:Uploading model into container now
2024-12-09 14:12:32,640:INFO:_master_model_container: 27
2024-12-09 14:12:32,640:INFO:_display_container: 3
2024-12-09 14:12:32,641:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:12:32,641:INFO:create_model() successfully completed......................................
2024-12-09 14:12:32,729:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:32,730:INFO:Creating metrics dataframe
2024-12-09 14:12:32,752:INFO:Initializing create_model()
2024-12-09 14:12:32,752:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:32,752:INFO:Checking exceptions
2024-12-09 14:12:32,754:INFO:Importing libraries
2024-12-09 14:12:32,754:INFO:Copying training dataset
2024-12-09 14:12:32,757:INFO:Defining folds
2024-12-09 14:12:32,758:INFO:Declaring metric variables
2024-12-09 14:12:32,758:INFO:Importing untrained model
2024-12-09 14:12:32,758:INFO:Declaring custom model
2024-12-09 14:12:32,759:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:12:32,761:INFO:Cross validation set to False
2024-12-09 14:12:32,761:INFO:Fitting Model
2024-12-09 14:12:32,814:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 14:12:32,815:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.
2024-12-09 14:12:32,815:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 14:12:32,815:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 14:12:32,815:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 14:12:32,815:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 14:12:32,815:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 14:12:32,815:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 14:12:32,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:32,852:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:12:32,852:INFO:create_model() successfully completed......................................
2024-12-09 14:12:32,952:INFO:_master_model_container: 27
2024-12-09 14:12:32,952:INFO:_display_container: 3
2024-12-09 14:12:32,953:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:12:32,953:INFO:compare_models() successfully completed......................................
2024-12-09 14:12:32,954:INFO:Initializing finalize_model()
2024-12-09 14:12:32,955:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-09 14:12:32,955:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:12:32,958:INFO:Initializing create_model()
2024-12-09 14:12:32,958:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:32,958:INFO:Checking exceptions
2024-12-09 14:12:32,960:INFO:Importing libraries
2024-12-09 14:12:32,960:INFO:Copying training dataset
2024-12-09 14:12:32,961:INFO:Defining folds
2024-12-09 14:12:32,961:INFO:Declaring metric variables
2024-12-09 14:12:32,961:INFO:Importing untrained model
2024-12-09 14:12:32,961:INFO:Declaring custom model
2024-12-09 14:12:32,962:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:12:32,963:INFO:Cross validation set to False
2024-12-09 14:12:32,963:INFO:Fitting Model
2024-12-09 14:12:33,012:INFO:[LightGBM] [Info] Number of positive: 342, number of negative: 549
2024-12-09 14:12:33,012:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.
2024-12-09 14:12:33,012:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 14:12:33,012:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 14:12:33,013:INFO:[LightGBM] [Info] Total Bins 224
2024-12-09 14:12:33,013:INFO:[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 9
2024-12-09 14:12:33,013:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288
2024-12-09 14:12:33,013:INFO:[LightGBM] [Info] Start training from score -0.473288
2024-12-09 14:12:33,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:12:33,064:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-09 14:12:33,064:INFO:create_model() successfully completed......................................
2024-12-09 14:12:33,141:INFO:_master_model_container: 27
2024-12-09 14:12:33,141:INFO:_display_container: 3
2024-12-09 14:12:33,160:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-09 14:12:33,160:INFO:finalize_model() successfully completed......................................
2024-12-09 14:12:33,271:INFO:Initializing predict_model()
2024-12-09 14:12:33,271:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0F91850>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E6C121DC10>)
2024-12-09 14:12:33,271:INFO:Checking exceptions
2024-12-09 14:12:33,271:INFO:Preloading libraries
2024-12-09 14:12:33,275:INFO:Set up data.
2024-12-09 14:12:33,279:INFO:Set up index.
2024-12-09 14:12:55,980:INFO:PyCaret ClassificationExperiment
2024-12-09 14:12:55,980:INFO:Logging name: clf-default-name
2024-12-09 14:12:55,980:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-09 14:12:55,980:INFO:version 3.2.0
2024-12-09 14:12:55,980:INFO:Initializing setup()
2024-12-09 14:12:55,980:INFO:self.USI: 174b
2024-12-09 14:12:55,980:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'pipeline', 'X_test', 'html_param', '_ml_usecase', 'seed', 'gpu_param', '_available_plots', 'X', 'X_train', 'fold_shuffle_param', 'y_test', 'log_plots_param', 'y', 'gpu_n_jobs_param', 'target_param', 'USI', 'fix_imbalance', 'n_jobs_param', 'idx', 'logging_param', 'exp_id', 'memory', 'data', 'fold_generator', 'y_train', 'exp_name_log'}
2024-12-09 14:12:55,980:INFO:Checking environment
2024-12-09 14:12:55,980:INFO:python_version: 3.8.20
2024-12-09 14:12:55,981:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2024-12-09 14:12:55,981:INFO:machine: AMD64
2024-12-09 14:12:55,981:INFO:platform: Windows-10-10.0.19041-SP0
2024-12-09 14:12:55,983:INFO:Memory: svmem(total=17054896128, available=6148820992, percent=63.9, used=10906075136, free=6148820992)
2024-12-09 14:12:55,983:INFO:Physical Core: 6
2024-12-09 14:12:55,983:INFO:Logical Core: 6
2024-12-09 14:12:55,983:INFO:Checking libraries
2024-12-09 14:12:55,983:INFO:System:
2024-12-09 14:12:55,983:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2024-12-09 14:12:55,983:INFO:executable: c:\Users\EE715\anaconda3\envs\gym-env\python.exe
2024-12-09 14:12:55,983:INFO:   machine: Windows-10-10.0.19041-SP0
2024-12-09 14:12:55,984:INFO:PyCaret required dependencies:
2024-12-09 14:12:55,984:INFO:                 pip: 24.2
2024-12-09 14:12:55,984:INFO:          setuptools: 75.1.0
2024-12-09 14:12:55,984:INFO:             pycaret: 3.2.0
2024-12-09 14:12:55,984:INFO:             IPython: 8.12.3
2024-12-09 14:12:55,984:INFO:          ipywidgets: 8.1.5
2024-12-09 14:12:55,984:INFO:                tqdm: 4.67.1
2024-12-09 14:12:55,984:INFO:               numpy: 1.24.4
2024-12-09 14:12:55,984:INFO:              pandas: 1.5.3
2024-12-09 14:12:55,984:INFO:              jinja2: 3.1.4
2024-12-09 14:12:55,984:INFO:               scipy: 1.10.1
2024-12-09 14:12:55,984:INFO:              joblib: 1.2.0
2024-12-09 14:12:55,984:INFO:             sklearn: 1.2.2
2024-12-09 14:12:55,984:INFO:                pyod: 2.0.2
2024-12-09 14:12:55,984:INFO:            imblearn: 0.12.4
2024-12-09 14:12:55,984:INFO:   category_encoders: 2.6.4
2024-12-09 14:12:55,984:INFO:            lightgbm: 4.5.0
2024-12-09 14:12:55,984:INFO:               numba: 0.58.1
2024-12-09 14:12:55,984:INFO:            requests: 2.32.3
2024-12-09 14:12:55,984:INFO:          matplotlib: 3.6.0
2024-12-09 14:12:55,984:INFO:          scikitplot: 0.3.7
2024-12-09 14:12:55,985:INFO:         yellowbrick: 1.5
2024-12-09 14:12:55,985:INFO:              plotly: 5.24.1
2024-12-09 14:12:55,985:INFO:    plotly-resampler: Not installed
2024-12-09 14:12:55,985:INFO:             kaleido: 0.2.1
2024-12-09 14:12:55,985:INFO:           schemdraw: 0.15
2024-12-09 14:12:55,985:INFO:         statsmodels: 0.14.1
2024-12-09 14:12:55,985:INFO:              sktime: 0.21.1
2024-12-09 14:12:55,985:INFO:               tbats: 1.1.3
2024-12-09 14:12:55,985:INFO:            pmdarima: 2.0.4
2024-12-09 14:12:55,985:INFO:              psutil: 6.1.0
2024-12-09 14:12:55,985:INFO:          markupsafe: 2.1.5
2024-12-09 14:12:55,985:INFO:             pickle5: Not installed
2024-12-09 14:12:55,985:INFO:         cloudpickle: 3.1.0
2024-12-09 14:12:55,985:INFO:         deprecation: 2.1.0
2024-12-09 14:12:55,985:INFO:              xxhash: 3.5.0
2024-12-09 14:12:55,985:INFO:           wurlitzer: Not installed
2024-12-09 14:12:55,985:INFO:PyCaret optional dependencies:
2024-12-09 14:12:55,985:INFO:                shap: Not installed
2024-12-09 14:12:55,985:INFO:           interpret: Not installed
2024-12-09 14:12:55,985:INFO:                umap: Not installed
2024-12-09 14:12:55,985:INFO:     ydata_profiling: Not installed
2024-12-09 14:12:55,985:INFO:  explainerdashboard: Not installed
2024-12-09 14:12:55,986:INFO:             autoviz: Not installed
2024-12-09 14:12:55,986:INFO:           fairlearn: Not installed
2024-12-09 14:12:55,986:INFO:          deepchecks: Not installed
2024-12-09 14:12:55,986:INFO:             xgboost: Not installed
2024-12-09 14:12:55,986:INFO:            catboost: Not installed
2024-12-09 14:12:55,986:INFO:              kmodes: Not installed
2024-12-09 14:12:55,986:INFO:             mlxtend: Not installed
2024-12-09 14:12:55,986:INFO:       statsforecast: Not installed
2024-12-09 14:12:55,986:INFO:        tune_sklearn: Not installed
2024-12-09 14:12:55,986:INFO:                 ray: Not installed
2024-12-09 14:12:55,986:INFO:            hyperopt: Not installed
2024-12-09 14:12:55,986:INFO:              optuna: 4.1.0
2024-12-09 14:12:55,986:INFO:               skopt: Not installed
2024-12-09 14:12:55,986:INFO:              mlflow: Not installed
2024-12-09 14:12:55,986:INFO:              gradio: Not installed
2024-12-09 14:12:55,986:INFO:             fastapi: Not installed
2024-12-09 14:12:55,986:INFO:             uvicorn: Not installed
2024-12-09 14:12:55,986:INFO:              m2cgen: Not installed
2024-12-09 14:12:55,986:INFO:           evidently: Not installed
2024-12-09 14:12:55,986:INFO:               fugue: Not installed
2024-12-09 14:12:55,986:INFO:           streamlit: Not installed
2024-12-09 14:12:55,986:INFO:             prophet: Not installed
2024-12-09 14:12:55,986:INFO:None
2024-12-09 14:12:55,987:INFO:Set up data.
2024-12-09 14:12:55,992:INFO:Set up folding strategy.
2024-12-09 14:12:55,992:INFO:Set up train/test split.
2024-12-09 14:12:55,998:INFO:Set up index.
2024-12-09 14:12:55,998:INFO:Assigning column types.
2024-12-09 14:12:56,001:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-09 14:12:56,042:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 14:12:56,043:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:12:56,069:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:56,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:56,108:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 14:12:56,110:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:12:56,135:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:56,135:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:56,135:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-09 14:12:56,175:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:12:56,201:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:56,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:56,243:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:12:56,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:56,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:56,268:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-09 14:12:56,331:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:56,332:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:56,397:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:56,397:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:56,398:INFO:Preparing preprocessing pipeline...
2024-12-09 14:12:56,399:INFO:Set up simple imputation.
2024-12-09 14:12:56,402:INFO:Set up encoding of ordinal features.
2024-12-09 14:12:56,403:INFO:Set up encoding of categorical features.
2024-12-09 14:12:56,466:INFO:Finished creating preprocessing pipeline.
2024-12-09 14:12:56,483:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\EE715\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categ...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-12-09 14:12:56,483:INFO:Creating final display dataframe.
2024-12-09 14:12:56,689:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (623, 10)
6    Transformed test set shape         (268, 10)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              174b
2024-12-09 14:12:56,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:56,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:56,836:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:56,836:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:12:56,836:INFO:setup() successfully completed in 0.86s...............
2024-12-09 14:12:56,838:INFO:Initializing compare_models()
2024-12-09 14:12:56,838:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['dummy'])
2024-12-09 14:12:56,838:INFO:Checking exceptions
2024-12-09 14:12:56,840:INFO:Preparing display monitor
2024-12-09 14:12:56,866:INFO:Initializing Logistic Regression
2024-12-09 14:12:56,866:INFO:Total runtime is 3.0676523844401043e-06 minutes
2024-12-09 14:12:56,871:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:56,871:INFO:Initializing create_model()
2024-12-09 14:12:56,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0444CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:56,872:INFO:Checking exceptions
2024-12-09 14:12:56,872:INFO:Importing libraries
2024-12-09 14:12:56,872:INFO:Copying training dataset
2024-12-09 14:12:56,878:INFO:Defining folds
2024-12-09 14:12:56,878:INFO:Declaring metric variables
2024-12-09 14:12:56,881:INFO:Importing untrained model
2024-12-09 14:12:56,885:INFO:Logistic Regression Imported successfully
2024-12-09 14:12:56,893:INFO:Starting cross validation
2024-12-09 14:12:56,895:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:57,266:INFO:Calculating mean and std
2024-12-09 14:12:57,267:INFO:Creating metrics dataframe
2024-12-09 14:12:57,270:INFO:Uploading results into container
2024-12-09 14:12:57,270:INFO:Uploading model into container now
2024-12-09 14:12:57,270:INFO:_master_model_container: 1
2024-12-09 14:12:57,271:INFO:_display_container: 2
2024-12-09 14:12:57,271:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 14:12:57,271:INFO:create_model() successfully completed......................................
2024-12-09 14:12:57,349:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:57,349:INFO:Creating metrics dataframe
2024-12-09 14:12:57,357:INFO:Initializing K Neighbors Classifier
2024-12-09 14:12:57,357:INFO:Total runtime is 0.008175186316172282 minutes
2024-12-09 14:12:57,361:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:57,362:INFO:Initializing create_model()
2024-12-09 14:12:57,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0444CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:57,362:INFO:Checking exceptions
2024-12-09 14:12:57,362:INFO:Importing libraries
2024-12-09 14:12:57,362:INFO:Copying training dataset
2024-12-09 14:12:57,365:INFO:Defining folds
2024-12-09 14:12:57,365:INFO:Declaring metric variables
2024-12-09 14:12:57,368:INFO:Importing untrained model
2024-12-09 14:12:57,372:INFO:K Neighbors Classifier Imported successfully
2024-12-09 14:12:57,381:INFO:Starting cross validation
2024-12-09 14:12:57,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:57,731:INFO:Calculating mean and std
2024-12-09 14:12:57,731:INFO:Creating metrics dataframe
2024-12-09 14:12:57,735:INFO:Uploading results into container
2024-12-09 14:12:57,735:INFO:Uploading model into container now
2024-12-09 14:12:57,735:INFO:_master_model_container: 2
2024-12-09 14:12:57,735:INFO:_display_container: 2
2024-12-09 14:12:57,736:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 14:12:57,736:INFO:create_model() successfully completed......................................
2024-12-09 14:12:57,814:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:57,814:INFO:Creating metrics dataframe
2024-12-09 14:12:57,823:INFO:Initializing Naive Bayes
2024-12-09 14:12:57,823:INFO:Total runtime is 0.015953675905863444 minutes
2024-12-09 14:12:57,826:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:57,826:INFO:Initializing create_model()
2024-12-09 14:12:57,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0444CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:57,827:INFO:Checking exceptions
2024-12-09 14:12:57,828:INFO:Importing libraries
2024-12-09 14:12:57,828:INFO:Copying training dataset
2024-12-09 14:12:57,832:INFO:Defining folds
2024-12-09 14:12:57,832:INFO:Declaring metric variables
2024-12-09 14:12:57,836:INFO:Importing untrained model
2024-12-09 14:12:57,839:INFO:Naive Bayes Imported successfully
2024-12-09 14:12:57,848:INFO:Starting cross validation
2024-12-09 14:12:57,850:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:58,143:INFO:Calculating mean and std
2024-12-09 14:12:58,145:INFO:Creating metrics dataframe
2024-12-09 14:12:58,149:INFO:Uploading results into container
2024-12-09 14:12:58,149:INFO:Uploading model into container now
2024-12-09 14:12:58,150:INFO:_master_model_container: 3
2024-12-09 14:12:58,150:INFO:_display_container: 2
2024-12-09 14:12:58,150:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 14:12:58,150:INFO:create_model() successfully completed......................................
2024-12-09 14:12:58,231:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:58,231:INFO:Creating metrics dataframe
2024-12-09 14:12:58,241:INFO:Initializing Decision Tree Classifier
2024-12-09 14:12:58,241:INFO:Total runtime is 0.022910869121551512 minutes
2024-12-09 14:12:58,244:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:58,244:INFO:Initializing create_model()
2024-12-09 14:12:58,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0444CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:58,245:INFO:Checking exceptions
2024-12-09 14:12:58,245:INFO:Importing libraries
2024-12-09 14:12:58,245:INFO:Copying training dataset
2024-12-09 14:12:58,250:INFO:Defining folds
2024-12-09 14:12:58,250:INFO:Declaring metric variables
2024-12-09 14:12:58,253:INFO:Importing untrained model
2024-12-09 14:12:58,258:INFO:Decision Tree Classifier Imported successfully
2024-12-09 14:12:58,266:INFO:Starting cross validation
2024-12-09 14:12:58,267:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:58,505:INFO:Calculating mean and std
2024-12-09 14:12:58,506:INFO:Creating metrics dataframe
2024-12-09 14:12:58,509:INFO:Uploading results into container
2024-12-09 14:12:58,510:INFO:Uploading model into container now
2024-12-09 14:12:58,510:INFO:_master_model_container: 4
2024-12-09 14:12:58,510:INFO:_display_container: 2
2024-12-09 14:12:58,511:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 14:12:58,511:INFO:create_model() successfully completed......................................
2024-12-09 14:12:58,589:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:58,589:INFO:Creating metrics dataframe
2024-12-09 14:12:58,600:INFO:Initializing SVM - Linear Kernel
2024-12-09 14:12:58,600:INFO:Total runtime is 0.02890039285024007 minutes
2024-12-09 14:12:58,603:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:58,604:INFO:Initializing create_model()
2024-12-09 14:12:58,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0444CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:58,604:INFO:Checking exceptions
2024-12-09 14:12:58,604:INFO:Importing libraries
2024-12-09 14:12:58,604:INFO:Copying training dataset
2024-12-09 14:12:58,608:INFO:Defining folds
2024-12-09 14:12:58,609:INFO:Declaring metric variables
2024-12-09 14:12:58,614:INFO:Importing untrained model
2024-12-09 14:12:58,619:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 14:12:58,627:INFO:Starting cross validation
2024-12-09 14:12:58,628:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:58,737:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:58,739:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:58,744:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:58,753:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:12:58,761:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:58,765:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:58,787:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:58,832:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:58,837:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:58,852:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:58,855:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:12:58,857:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:12:58,866:INFO:Calculating mean and std
2024-12-09 14:12:58,867:INFO:Creating metrics dataframe
2024-12-09 14:12:58,870:INFO:Uploading results into container
2024-12-09 14:12:58,871:INFO:Uploading model into container now
2024-12-09 14:12:58,871:INFO:_master_model_container: 5
2024-12-09 14:12:58,871:INFO:_display_container: 2
2024-12-09 14:12:58,872:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 14:12:58,872:INFO:create_model() successfully completed......................................
2024-12-09 14:12:58,948:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:58,949:INFO:Creating metrics dataframe
2024-12-09 14:12:58,959:INFO:Initializing Ridge Classifier
2024-12-09 14:12:58,960:INFO:Total runtime is 0.03489647308985392 minutes
2024-12-09 14:12:58,964:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:58,964:INFO:Initializing create_model()
2024-12-09 14:12:58,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0444CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:58,964:INFO:Checking exceptions
2024-12-09 14:12:58,964:INFO:Importing libraries
2024-12-09 14:12:58,965:INFO:Copying training dataset
2024-12-09 14:12:58,969:INFO:Defining folds
2024-12-09 14:12:58,969:INFO:Declaring metric variables
2024-12-09 14:12:58,973:INFO:Importing untrained model
2024-12-09 14:12:58,977:INFO:Ridge Classifier Imported successfully
2024-12-09 14:12:58,985:INFO:Starting cross validation
2024-12-09 14:12:58,987:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:12:59,122:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:59,125:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:59,150:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:59,158:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:59,159:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:59,180:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:59,234:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:59,234:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:59,251:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:59,256:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:12:59,264:INFO:Calculating mean and std
2024-12-09 14:12:59,265:INFO:Creating metrics dataframe
2024-12-09 14:12:59,269:INFO:Uploading results into container
2024-12-09 14:12:59,269:INFO:Uploading model into container now
2024-12-09 14:12:59,269:INFO:_master_model_container: 6
2024-12-09 14:12:59,270:INFO:_display_container: 2
2024-12-09 14:12:59,270:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 14:12:59,271:INFO:create_model() successfully completed......................................
2024-12-09 14:12:59,349:INFO:SubProcess create_model() end ==================================
2024-12-09 14:12:59,349:INFO:Creating metrics dataframe
2024-12-09 14:12:59,359:INFO:Initializing Random Forest Classifier
2024-12-09 14:12:59,360:INFO:Total runtime is 0.041559414068857825 minutes
2024-12-09 14:12:59,363:INFO:SubProcess create_model() called ==================================
2024-12-09 14:12:59,364:INFO:Initializing create_model()
2024-12-09 14:12:59,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0444CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:12:59,364:INFO:Checking exceptions
2024-12-09 14:12:59,364:INFO:Importing libraries
2024-12-09 14:12:59,364:INFO:Copying training dataset
2024-12-09 14:12:59,369:INFO:Defining folds
2024-12-09 14:12:59,369:INFO:Declaring metric variables
2024-12-09 14:12:59,372:INFO:Importing untrained model
2024-12-09 14:12:59,376:INFO:Random Forest Classifier Imported successfully
2024-12-09 14:12:59,385:INFO:Starting cross validation
2024-12-09 14:12:59,387:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:00,257:INFO:Calculating mean and std
2024-12-09 14:13:00,258:INFO:Creating metrics dataframe
2024-12-09 14:13:00,261:INFO:Uploading results into container
2024-12-09 14:13:00,262:INFO:Uploading model into container now
2024-12-09 14:13:00,262:INFO:_master_model_container: 7
2024-12-09 14:13:00,262:INFO:_display_container: 2
2024-12-09 14:13:00,263:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 14:13:00,263:INFO:create_model() successfully completed......................................
2024-12-09 14:13:00,341:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:00,341:INFO:Creating metrics dataframe
2024-12-09 14:13:00,353:INFO:Initializing Quadratic Discriminant Analysis
2024-12-09 14:13:00,353:INFO:Total runtime is 0.058111317952473956 minutes
2024-12-09 14:13:00,356:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:00,356:INFO:Initializing create_model()
2024-12-09 14:13:00,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0444CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:00,356:INFO:Checking exceptions
2024-12-09 14:13:00,356:INFO:Importing libraries
2024-12-09 14:13:00,356:INFO:Copying training dataset
2024-12-09 14:13:00,361:INFO:Defining folds
2024-12-09 14:13:00,361:INFO:Declaring metric variables
2024-12-09 14:13:00,365:INFO:Importing untrained model
2024-12-09 14:13:00,370:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 14:13:00,377:INFO:Starting cross validation
2024-12-09 14:13:00,379:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:00,451:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:00,452:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:00,454:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:00,469:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:00,493:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:00,592:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:00,605:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:00,608:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:00,654:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:00,678:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:00,717:INFO:Calculating mean and std
2024-12-09 14:13:00,718:INFO:Creating metrics dataframe
2024-12-09 14:13:00,721:INFO:Uploading results into container
2024-12-09 14:13:00,721:INFO:Uploading model into container now
2024-12-09 14:13:00,722:INFO:_master_model_container: 8
2024-12-09 14:13:00,722:INFO:_display_container: 2
2024-12-09 14:13:00,722:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 14:13:00,722:INFO:create_model() successfully completed......................................
2024-12-09 14:13:00,796:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:00,796:INFO:Creating metrics dataframe
2024-12-09 14:13:00,809:INFO:Initializing Ada Boost Classifier
2024-12-09 14:13:00,810:INFO:Total runtime is 0.06572246551513672 minutes
2024-12-09 14:13:00,816:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:00,817:INFO:Initializing create_model()
2024-12-09 14:13:00,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0444CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:00,817:INFO:Checking exceptions
2024-12-09 14:13:00,818:INFO:Importing libraries
2024-12-09 14:13:00,818:INFO:Copying training dataset
2024-12-09 14:13:00,824:INFO:Defining folds
2024-12-09 14:13:00,825:INFO:Declaring metric variables
2024-12-09 14:13:00,829:INFO:Importing untrained model
2024-12-09 14:13:00,837:INFO:Ada Boost Classifier Imported successfully
2024-12-09 14:13:00,849:INFO:Starting cross validation
2024-12-09 14:13:00,851:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:01,369:INFO:Calculating mean and std
2024-12-09 14:13:01,370:INFO:Creating metrics dataframe
2024-12-09 14:13:01,373:INFO:Uploading results into container
2024-12-09 14:13:01,374:INFO:Uploading model into container now
2024-12-09 14:13:01,374:INFO:_master_model_container: 9
2024-12-09 14:13:01,374:INFO:_display_container: 2
2024-12-09 14:13:01,374:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 14:13:01,375:INFO:create_model() successfully completed......................................
2024-12-09 14:13:01,457:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:01,457:INFO:Creating metrics dataframe
2024-12-09 14:13:01,471:INFO:Initializing Gradient Boosting Classifier
2024-12-09 14:13:01,471:INFO:Total runtime is 0.07674989302953084 minutes
2024-12-09 14:13:01,474:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:01,474:INFO:Initializing create_model()
2024-12-09 14:13:01,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0444CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:01,474:INFO:Checking exceptions
2024-12-09 14:13:01,474:INFO:Importing libraries
2024-12-09 14:13:01,474:INFO:Copying training dataset
2024-12-09 14:13:01,478:INFO:Defining folds
2024-12-09 14:13:01,478:INFO:Declaring metric variables
2024-12-09 14:13:01,485:INFO:Importing untrained model
2024-12-09 14:13:01,491:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 14:13:01,499:INFO:Starting cross validation
2024-12-09 14:13:01,501:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:01,969:INFO:Calculating mean and std
2024-12-09 14:13:01,971:INFO:Creating metrics dataframe
2024-12-09 14:13:01,974:INFO:Uploading results into container
2024-12-09 14:13:01,974:INFO:Uploading model into container now
2024-12-09 14:13:01,974:INFO:_master_model_container: 10
2024-12-09 14:13:01,975:INFO:_display_container: 2
2024-12-09 14:13:01,975:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 14:13:01,975:INFO:create_model() successfully completed......................................
2024-12-09 14:13:02,053:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:02,053:INFO:Creating metrics dataframe
2024-12-09 14:13:02,064:INFO:Initializing Linear Discriminant Analysis
2024-12-09 14:13:02,064:INFO:Total runtime is 0.08662668069203694 minutes
2024-12-09 14:13:02,068:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:02,069:INFO:Initializing create_model()
2024-12-09 14:13:02,069:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0444CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:02,069:INFO:Checking exceptions
2024-12-09 14:13:02,069:INFO:Importing libraries
2024-12-09 14:13:02,069:INFO:Copying training dataset
2024-12-09 14:13:02,073:INFO:Defining folds
2024-12-09 14:13:02,073:INFO:Declaring metric variables
2024-12-09 14:13:02,077:INFO:Importing untrained model
2024-12-09 14:13:02,080:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 14:13:02,089:INFO:Starting cross validation
2024-12-09 14:13:02,091:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:02,352:INFO:Calculating mean and std
2024-12-09 14:13:02,354:INFO:Creating metrics dataframe
2024-12-09 14:13:02,357:INFO:Uploading results into container
2024-12-09 14:13:02,358:INFO:Uploading model into container now
2024-12-09 14:13:02,358:INFO:_master_model_container: 11
2024-12-09 14:13:02,358:INFO:_display_container: 2
2024-12-09 14:13:02,359:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 14:13:02,359:INFO:create_model() successfully completed......................................
2024-12-09 14:13:02,443:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:02,443:INFO:Creating metrics dataframe
2024-12-09 14:13:02,455:INFO:Initializing Extra Trees Classifier
2024-12-09 14:13:02,455:INFO:Total runtime is 0.09315352042516072 minutes
2024-12-09 14:13:02,459:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:02,459:INFO:Initializing create_model()
2024-12-09 14:13:02,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0444CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:02,459:INFO:Checking exceptions
2024-12-09 14:13:02,460:INFO:Importing libraries
2024-12-09 14:13:02,460:INFO:Copying training dataset
2024-12-09 14:13:02,464:INFO:Defining folds
2024-12-09 14:13:02,464:INFO:Declaring metric variables
2024-12-09 14:13:02,469:INFO:Importing untrained model
2024-12-09 14:13:02,473:INFO:Extra Trees Classifier Imported successfully
2024-12-09 14:13:02,480:INFO:Starting cross validation
2024-12-09 14:13:02,482:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:03,134:INFO:Calculating mean and std
2024-12-09 14:13:03,135:INFO:Creating metrics dataframe
2024-12-09 14:13:03,138:INFO:Uploading results into container
2024-12-09 14:13:03,139:INFO:Uploading model into container now
2024-12-09 14:13:03,139:INFO:_master_model_container: 12
2024-12-09 14:13:03,139:INFO:_display_container: 2
2024-12-09 14:13:03,140:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 14:13:03,140:INFO:create_model() successfully completed......................................
2024-12-09 14:13:03,220:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:03,221:INFO:Creating metrics dataframe
2024-12-09 14:13:03,232:INFO:Initializing Light Gradient Boosting Machine
2024-12-09 14:13:03,233:INFO:Total runtime is 0.10611009995142617 minutes
2024-12-09 14:13:03,236:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:03,237:INFO:Initializing create_model()
2024-12-09 14:13:03,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0444CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:03,237:INFO:Checking exceptions
2024-12-09 14:13:03,237:INFO:Importing libraries
2024-12-09 14:13:03,237:INFO:Copying training dataset
2024-12-09 14:13:03,241:INFO:Defining folds
2024-12-09 14:13:03,241:INFO:Declaring metric variables
2024-12-09 14:13:03,245:INFO:Importing untrained model
2024-12-09 14:13:03,250:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:13:03,259:INFO:Starting cross validation
2024-12-09 14:13:03,261:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:04,096:INFO:Calculating mean and std
2024-12-09 14:13:04,097:INFO:Creating metrics dataframe
2024-12-09 14:13:04,101:INFO:Uploading results into container
2024-12-09 14:13:04,102:INFO:Uploading model into container now
2024-12-09 14:13:04,103:INFO:_master_model_container: 13
2024-12-09 14:13:04,104:INFO:_display_container: 2
2024-12-09 14:13:04,104:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:13:04,105:INFO:create_model() successfully completed......................................
2024-12-09 14:13:04,184:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:04,184:INFO:Creating metrics dataframe
2024-12-09 14:13:04,209:INFO:Initializing create_model()
2024-12-09 14:13:04,209:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:04,210:INFO:Checking exceptions
2024-12-09 14:13:04,212:INFO:Importing libraries
2024-12-09 14:13:04,212:INFO:Copying training dataset
2024-12-09 14:13:04,215:INFO:Defining folds
2024-12-09 14:13:04,215:INFO:Declaring metric variables
2024-12-09 14:13:04,215:INFO:Importing untrained model
2024-12-09 14:13:04,215:INFO:Declaring custom model
2024-12-09 14:13:04,216:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:13:04,217:INFO:Cross validation set to False
2024-12-09 14:13:04,218:INFO:Fitting Model
2024-12-09 14:13:04,266:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 14:13:04,266:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000070 seconds.
2024-12-09 14:13:04,266:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 14:13:04,266:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 14:13:04,266:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 14:13:04,266:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 14:13:04,267:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 14:13:04,267:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 14:13:04,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:04,301:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:13:04,301:INFO:create_model() successfully completed......................................
2024-12-09 14:13:04,381:INFO:Initializing create_model()
2024-12-09 14:13:04,381:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:04,381:INFO:Checking exceptions
2024-12-09 14:13:04,384:INFO:Importing libraries
2024-12-09 14:13:04,384:INFO:Copying training dataset
2024-12-09 14:13:04,388:INFO:Defining folds
2024-12-09 14:13:04,388:INFO:Declaring metric variables
2024-12-09 14:13:04,388:INFO:Importing untrained model
2024-12-09 14:13:04,388:INFO:Declaring custom model
2024-12-09 14:13:04,388:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 14:13:04,389:INFO:Cross validation set to False
2024-12-09 14:13:04,389:INFO:Fitting Model
2024-12-09 14:13:04,540:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 14:13:04,540:INFO:create_model() successfully completed......................................
2024-12-09 14:13:04,620:INFO:Initializing create_model()
2024-12-09 14:13:04,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:04,620:INFO:Checking exceptions
2024-12-09 14:13:04,621:INFO:Importing libraries
2024-12-09 14:13:04,621:INFO:Copying training dataset
2024-12-09 14:13:04,625:INFO:Defining folds
2024-12-09 14:13:04,625:INFO:Declaring metric variables
2024-12-09 14:13:04,625:INFO:Importing untrained model
2024-12-09 14:13:04,625:INFO:Declaring custom model
2024-12-09 14:13:04,626:INFO:Random Forest Classifier Imported successfully
2024-12-09 14:13:04,627:INFO:Cross validation set to False
2024-12-09 14:13:04,627:INFO:Fitting Model
2024-12-09 14:13:04,829:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 14:13:04,829:INFO:create_model() successfully completed......................................
2024-12-09 14:13:04,908:INFO:Initializing create_model()
2024-12-09 14:13:04,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:04,908:INFO:Checking exceptions
2024-12-09 14:13:04,910:INFO:Importing libraries
2024-12-09 14:13:04,911:INFO:Copying training dataset
2024-12-09 14:13:04,914:INFO:Defining folds
2024-12-09 14:13:04,914:INFO:Declaring metric variables
2024-12-09 14:13:04,914:INFO:Importing untrained model
2024-12-09 14:13:04,915:INFO:Declaring custom model
2024-12-09 14:13:04,915:INFO:Ada Boost Classifier Imported successfully
2024-12-09 14:13:04,916:INFO:Cross validation set to False
2024-12-09 14:13:04,916:INFO:Fitting Model
2024-12-09 14:13:05,049:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 14:13:05,049:INFO:create_model() successfully completed......................................
2024-12-09 14:13:05,128:INFO:Initializing create_model()
2024-12-09 14:13:05,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:05,129:INFO:Checking exceptions
2024-12-09 14:13:05,131:INFO:Importing libraries
2024-12-09 14:13:05,131:INFO:Copying training dataset
2024-12-09 14:13:05,134:INFO:Defining folds
2024-12-09 14:13:05,135:INFO:Declaring metric variables
2024-12-09 14:13:05,135:INFO:Importing untrained model
2024-12-09 14:13:05,135:INFO:Declaring custom model
2024-12-09 14:13:05,136:INFO:Logistic Regression Imported successfully
2024-12-09 14:13:05,137:INFO:Cross validation set to False
2024-12-09 14:13:05,137:INFO:Fitting Model
2024-12-09 14:13:05,225:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 14:13:05,225:INFO:create_model() successfully completed......................................
2024-12-09 14:13:05,304:INFO:Initializing create_model()
2024-12-09 14:13:05,304:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:05,304:INFO:Checking exceptions
2024-12-09 14:13:05,306:INFO:Importing libraries
2024-12-09 14:13:05,306:INFO:Copying training dataset
2024-12-09 14:13:05,309:INFO:Defining folds
2024-12-09 14:13:05,310:INFO:Declaring metric variables
2024-12-09 14:13:05,310:INFO:Importing untrained model
2024-12-09 14:13:05,310:INFO:Declaring custom model
2024-12-09 14:13:05,310:INFO:Extra Trees Classifier Imported successfully
2024-12-09 14:13:05,311:INFO:Cross validation set to False
2024-12-09 14:13:05,311:INFO:Fitting Model
2024-12-09 14:13:05,491:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 14:13:05,492:INFO:create_model() successfully completed......................................
2024-12-09 14:13:05,580:INFO:Initializing create_model()
2024-12-09 14:13:05,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:05,581:INFO:Checking exceptions
2024-12-09 14:13:05,582:INFO:Importing libraries
2024-12-09 14:13:05,582:INFO:Copying training dataset
2024-12-09 14:13:05,586:INFO:Defining folds
2024-12-09 14:13:05,586:INFO:Declaring metric variables
2024-12-09 14:13:05,586:INFO:Importing untrained model
2024-12-09 14:13:05,586:INFO:Declaring custom model
2024-12-09 14:13:05,587:INFO:Ridge Classifier Imported successfully
2024-12-09 14:13:05,588:INFO:Cross validation set to False
2024-12-09 14:13:05,589:INFO:Fitting Model
2024-12-09 14:13:05,634:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 14:13:05,634:INFO:create_model() successfully completed......................................
2024-12-09 14:13:05,720:INFO:Initializing create_model()
2024-12-09 14:13:05,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:05,720:INFO:Checking exceptions
2024-12-09 14:13:05,722:INFO:Importing libraries
2024-12-09 14:13:05,723:INFO:Copying training dataset
2024-12-09 14:13:05,727:INFO:Defining folds
2024-12-09 14:13:05,727:INFO:Declaring metric variables
2024-12-09 14:13:05,727:INFO:Importing untrained model
2024-12-09 14:13:05,727:INFO:Declaring custom model
2024-12-09 14:13:05,728:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 14:13:05,728:INFO:Cross validation set to False
2024-12-09 14:13:05,729:INFO:Fitting Model
2024-12-09 14:13:05,774:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 14:13:05,774:INFO:create_model() successfully completed......................................
2024-12-09 14:13:05,854:INFO:Initializing create_model()
2024-12-09 14:13:05,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:05,855:INFO:Checking exceptions
2024-12-09 14:13:05,857:INFO:Importing libraries
2024-12-09 14:13:05,857:INFO:Copying training dataset
2024-12-09 14:13:05,860:INFO:Defining folds
2024-12-09 14:13:05,860:INFO:Declaring metric variables
2024-12-09 14:13:05,860:INFO:Importing untrained model
2024-12-09 14:13:05,860:INFO:Declaring custom model
2024-12-09 14:13:05,861:INFO:Naive Bayes Imported successfully
2024-12-09 14:13:05,862:INFO:Cross validation set to False
2024-12-09 14:13:05,862:INFO:Fitting Model
2024-12-09 14:13:05,908:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 14:13:05,908:INFO:create_model() successfully completed......................................
2024-12-09 14:13:05,989:INFO:Initializing create_model()
2024-12-09 14:13:05,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:05,990:INFO:Checking exceptions
2024-12-09 14:13:05,992:INFO:Importing libraries
2024-12-09 14:13:05,992:INFO:Copying training dataset
2024-12-09 14:13:05,996:INFO:Defining folds
2024-12-09 14:13:05,996:INFO:Declaring metric variables
2024-12-09 14:13:05,996:INFO:Importing untrained model
2024-12-09 14:13:05,996:INFO:Declaring custom model
2024-12-09 14:13:05,996:INFO:Decision Tree Classifier Imported successfully
2024-12-09 14:13:05,997:INFO:Cross validation set to False
2024-12-09 14:13:05,997:INFO:Fitting Model
2024-12-09 14:13:06,044:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 14:13:06,045:INFO:create_model() successfully completed......................................
2024-12-09 14:13:06,125:INFO:Initializing create_model()
2024-12-09 14:13:06,125:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:06,125:INFO:Checking exceptions
2024-12-09 14:13:06,129:INFO:Importing libraries
2024-12-09 14:13:06,129:INFO:Copying training dataset
2024-12-09 14:13:06,132:INFO:Defining folds
2024-12-09 14:13:06,132:INFO:Declaring metric variables
2024-12-09 14:13:06,132:INFO:Importing untrained model
2024-12-09 14:13:06,132:INFO:Declaring custom model
2024-12-09 14:13:06,132:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 14:13:06,133:INFO:Cross validation set to False
2024-12-09 14:13:06,133:INFO:Fitting Model
2024-12-09 14:13:06,179:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:06,180:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 14:13:06,180:INFO:create_model() successfully completed......................................
2024-12-09 14:13:06,263:INFO:Initializing create_model()
2024-12-09 14:13:06,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:06,263:INFO:Checking exceptions
2024-12-09 14:13:06,266:INFO:Importing libraries
2024-12-09 14:13:06,266:INFO:Copying training dataset
2024-12-09 14:13:06,269:INFO:Defining folds
2024-12-09 14:13:06,269:INFO:Declaring metric variables
2024-12-09 14:13:06,269:INFO:Importing untrained model
2024-12-09 14:13:06,270:INFO:Declaring custom model
2024-12-09 14:13:06,270:INFO:K Neighbors Classifier Imported successfully
2024-12-09 14:13:06,271:INFO:Cross validation set to False
2024-12-09 14:13:06,272:INFO:Fitting Model
2024-12-09 14:13:06,323:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 14:13:06,323:INFO:create_model() successfully completed......................................
2024-12-09 14:13:06,415:INFO:Initializing create_model()
2024-12-09 14:13:06,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:06,415:INFO:Checking exceptions
2024-12-09 14:13:06,417:INFO:Importing libraries
2024-12-09 14:13:06,417:INFO:Copying training dataset
2024-12-09 14:13:06,421:INFO:Defining folds
2024-12-09 14:13:06,422:INFO:Declaring metric variables
2024-12-09 14:13:06,422:INFO:Importing untrained model
2024-12-09 14:13:06,422:INFO:Declaring custom model
2024-12-09 14:13:06,424:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 14:13:06,425:INFO:Cross validation set to False
2024-12-09 14:13:06,425:INFO:Fitting Model
2024-12-09 14:13:06,477:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 14:13:06,477:INFO:create_model() successfully completed......................................
2024-12-09 14:13:06,584:INFO:_master_model_container: 13
2024-12-09 14:13:06,585:INFO:_display_container: 2
2024-12-09 14:13:06,589:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-12-09 14:13:06,589:INFO:compare_models() successfully completed......................................
2024-12-09 14:13:06,592:INFO:Initializing finalize_model()
2024-12-09 14:13:06,592:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)], fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-09 14:13:06,595:INFO:Finalizing [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-12-09 14:13:06,601:INFO:Initializing create_model()
2024-12-09 14:13:06,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)], fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:06,601:INFO:Checking exceptions
2024-12-09 14:13:06,614:INFO:Initializing compare_models()
2024-12-09 14:13:06,614:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, 'include': None, 'exclude': ['dummy', [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['dummy', [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]])
2024-12-09 14:13:06,614:INFO:Checking exceptions
2024-12-09 14:13:06,623:INFO:Preparing display monitor
2024-12-09 14:13:06,664:INFO:Initializing Logistic Regression
2024-12-09 14:13:06,664:INFO:Total runtime is 0.0 minutes
2024-12-09 14:13:06,675:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:06,676:INFO:Initializing create_model()
2024-12-09 14:13:06,676:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE973E80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:06,676:INFO:Checking exceptions
2024-12-09 14:13:06,676:INFO:Importing libraries
2024-12-09 14:13:06,676:INFO:Copying training dataset
2024-12-09 14:13:06,682:INFO:Defining folds
2024-12-09 14:13:06,682:INFO:Declaring metric variables
2024-12-09 14:13:06,689:INFO:Importing untrained model
2024-12-09 14:13:06,697:INFO:Logistic Regression Imported successfully
2024-12-09 14:13:06,714:INFO:Starting cross validation
2024-12-09 14:13:06,716:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:07,110:INFO:Calculating mean and std
2024-12-09 14:13:07,110:INFO:Creating metrics dataframe
2024-12-09 14:13:07,113:INFO:Uploading results into container
2024-12-09 14:13:07,114:INFO:Uploading model into container now
2024-12-09 14:13:07,114:INFO:_master_model_container: 14
2024-12-09 14:13:07,114:INFO:_display_container: 3
2024-12-09 14:13:07,114:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 14:13:07,115:INFO:create_model() successfully completed......................................
2024-12-09 14:13:07,189:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:07,190:INFO:Creating metrics dataframe
2024-12-09 14:13:07,198:INFO:Initializing K Neighbors Classifier
2024-12-09 14:13:07,198:INFO:Total runtime is 0.008904357751210531 minutes
2024-12-09 14:13:07,201:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:07,201:INFO:Initializing create_model()
2024-12-09 14:13:07,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE973E80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:07,201:INFO:Checking exceptions
2024-12-09 14:13:07,202:INFO:Importing libraries
2024-12-09 14:13:07,202:INFO:Copying training dataset
2024-12-09 14:13:07,206:INFO:Defining folds
2024-12-09 14:13:07,206:INFO:Declaring metric variables
2024-12-09 14:13:07,211:INFO:Importing untrained model
2024-12-09 14:13:07,213:INFO:K Neighbors Classifier Imported successfully
2024-12-09 14:13:07,224:INFO:Starting cross validation
2024-12-09 14:13:07,226:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:07,506:INFO:Calculating mean and std
2024-12-09 14:13:07,506:INFO:Creating metrics dataframe
2024-12-09 14:13:07,509:INFO:Uploading results into container
2024-12-09 14:13:07,510:INFO:Uploading model into container now
2024-12-09 14:13:07,510:INFO:_master_model_container: 15
2024-12-09 14:13:07,510:INFO:_display_container: 3
2024-12-09 14:13:07,510:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 14:13:07,511:INFO:create_model() successfully completed......................................
2024-12-09 14:13:07,596:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:07,596:INFO:Creating metrics dataframe
2024-12-09 14:13:07,607:INFO:Initializing Naive Bayes
2024-12-09 14:13:07,607:INFO:Total runtime is 0.015711494286855063 minutes
2024-12-09 14:13:07,611:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:07,611:INFO:Initializing create_model()
2024-12-09 14:13:07,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE973E80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:07,612:INFO:Checking exceptions
2024-12-09 14:13:07,612:INFO:Importing libraries
2024-12-09 14:13:07,612:INFO:Copying training dataset
2024-12-09 14:13:07,615:INFO:Defining folds
2024-12-09 14:13:07,616:INFO:Declaring metric variables
2024-12-09 14:13:07,619:INFO:Importing untrained model
2024-12-09 14:13:07,623:INFO:Naive Bayes Imported successfully
2024-12-09 14:13:07,635:INFO:Starting cross validation
2024-12-09 14:13:07,637:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:07,907:INFO:Calculating mean and std
2024-12-09 14:13:07,908:INFO:Creating metrics dataframe
2024-12-09 14:13:07,911:INFO:Uploading results into container
2024-12-09 14:13:07,911:INFO:Uploading model into container now
2024-12-09 14:13:07,912:INFO:_master_model_container: 16
2024-12-09 14:13:07,912:INFO:_display_container: 3
2024-12-09 14:13:07,912:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 14:13:07,912:INFO:create_model() successfully completed......................................
2024-12-09 14:13:08,000:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:08,001:INFO:Creating metrics dataframe
2024-12-09 14:13:08,012:INFO:Initializing Decision Tree Classifier
2024-12-09 14:13:08,012:INFO:Total runtime is 0.022464871406555176 minutes
2024-12-09 14:13:08,016:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:08,016:INFO:Initializing create_model()
2024-12-09 14:13:08,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE973E80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:08,016:INFO:Checking exceptions
2024-12-09 14:13:08,017:INFO:Importing libraries
2024-12-09 14:13:08,017:INFO:Copying training dataset
2024-12-09 14:13:08,022:INFO:Defining folds
2024-12-09 14:13:08,022:INFO:Declaring metric variables
2024-12-09 14:13:08,026:INFO:Importing untrained model
2024-12-09 14:13:08,032:INFO:Decision Tree Classifier Imported successfully
2024-12-09 14:13:08,040:INFO:Starting cross validation
2024-12-09 14:13:08,043:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:08,317:INFO:Calculating mean and std
2024-12-09 14:13:08,318:INFO:Creating metrics dataframe
2024-12-09 14:13:08,321:INFO:Uploading results into container
2024-12-09 14:13:08,322:INFO:Uploading model into container now
2024-12-09 14:13:08,323:INFO:_master_model_container: 17
2024-12-09 14:13:08,323:INFO:_display_container: 3
2024-12-09 14:13:08,324:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 14:13:08,325:INFO:create_model() successfully completed......................................
2024-12-09 14:13:08,419:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:08,419:INFO:Creating metrics dataframe
2024-12-09 14:13:08,430:INFO:Initializing SVM - Linear Kernel
2024-12-09 14:13:08,430:INFO:Total runtime is 0.029425688584645587 minutes
2024-12-09 14:13:08,434:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:08,435:INFO:Initializing create_model()
2024-12-09 14:13:08,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE973E80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:08,435:INFO:Checking exceptions
2024-12-09 14:13:08,435:INFO:Importing libraries
2024-12-09 14:13:08,435:INFO:Copying training dataset
2024-12-09 14:13:08,440:INFO:Defining folds
2024-12-09 14:13:08,440:INFO:Declaring metric variables
2024-12-09 14:13:08,446:INFO:Importing untrained model
2024-12-09 14:13:08,451:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 14:13:08,461:INFO:Starting cross validation
2024-12-09 14:13:08,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:08,583:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:08,584:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:08,588:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:13:08,591:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:08,593:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:08,612:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:08,627:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:08,698:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:08,703:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:08,710:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:08,717:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:08,723:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:13:08,727:INFO:Calculating mean and std
2024-12-09 14:13:08,729:INFO:Creating metrics dataframe
2024-12-09 14:13:08,732:INFO:Uploading results into container
2024-12-09 14:13:08,733:INFO:Uploading model into container now
2024-12-09 14:13:08,734:INFO:_master_model_container: 18
2024-12-09 14:13:08,734:INFO:_display_container: 3
2024-12-09 14:13:08,734:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 14:13:08,735:INFO:create_model() successfully completed......................................
2024-12-09 14:13:08,826:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:08,826:INFO:Creating metrics dataframe
2024-12-09 14:13:08,838:INFO:Initializing Ridge Classifier
2024-12-09 14:13:08,838:INFO:Total runtime is 0.03624034722646077 minutes
2024-12-09 14:13:08,843:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:08,843:INFO:Initializing create_model()
2024-12-09 14:13:08,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE973E80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:08,843:INFO:Checking exceptions
2024-12-09 14:13:08,843:INFO:Importing libraries
2024-12-09 14:13:08,843:INFO:Copying training dataset
2024-12-09 14:13:08,850:INFO:Defining folds
2024-12-09 14:13:08,850:INFO:Declaring metric variables
2024-12-09 14:13:08,854:INFO:Importing untrained model
2024-12-09 14:13:08,861:INFO:Ridge Classifier Imported successfully
2024-12-09 14:13:08,870:INFO:Starting cross validation
2024-12-09 14:13:08,872:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:08,998:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:09,009:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:09,010:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:09,014:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:09,017:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:09,029:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:09,128:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:09,131:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:09,146:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:09,153:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:09,162:INFO:Calculating mean and std
2024-12-09 14:13:09,163:INFO:Creating metrics dataframe
2024-12-09 14:13:09,167:INFO:Uploading results into container
2024-12-09 14:13:09,167:INFO:Uploading model into container now
2024-12-09 14:13:09,168:INFO:_master_model_container: 19
2024-12-09 14:13:09,168:INFO:_display_container: 3
2024-12-09 14:13:09,168:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 14:13:09,168:INFO:create_model() successfully completed......................................
2024-12-09 14:13:09,255:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:09,256:INFO:Creating metrics dataframe
2024-12-09 14:13:09,266:INFO:Initializing Random Forest Classifier
2024-12-09 14:13:09,266:INFO:Total runtime is 0.04336707989374797 minutes
2024-12-09 14:13:09,270:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:09,270:INFO:Initializing create_model()
2024-12-09 14:13:09,270:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE973E80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:09,270:INFO:Checking exceptions
2024-12-09 14:13:09,271:INFO:Importing libraries
2024-12-09 14:13:09,271:INFO:Copying training dataset
2024-12-09 14:13:09,276:INFO:Defining folds
2024-12-09 14:13:09,277:INFO:Declaring metric variables
2024-12-09 14:13:09,281:INFO:Importing untrained model
2024-12-09 14:13:09,284:INFO:Random Forest Classifier Imported successfully
2024-12-09 14:13:09,294:INFO:Starting cross validation
2024-12-09 14:13:09,295:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:10,226:INFO:Calculating mean and std
2024-12-09 14:13:10,227:INFO:Creating metrics dataframe
2024-12-09 14:13:10,231:INFO:Uploading results into container
2024-12-09 14:13:10,232:INFO:Uploading model into container now
2024-12-09 14:13:10,232:INFO:_master_model_container: 20
2024-12-09 14:13:10,232:INFO:_display_container: 3
2024-12-09 14:13:10,233:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 14:13:10,233:INFO:create_model() successfully completed......................................
2024-12-09 14:13:10,331:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:10,331:INFO:Creating metrics dataframe
2024-12-09 14:13:10,344:INFO:Initializing Quadratic Discriminant Analysis
2024-12-09 14:13:10,344:INFO:Total runtime is 0.061324497063954674 minutes
2024-12-09 14:13:10,348:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:10,348:INFO:Initializing create_model()
2024-12-09 14:13:10,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE973E80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:10,348:INFO:Checking exceptions
2024-12-09 14:13:10,348:INFO:Importing libraries
2024-12-09 14:13:10,349:INFO:Copying training dataset
2024-12-09 14:13:10,353:INFO:Defining folds
2024-12-09 14:13:10,353:INFO:Declaring metric variables
2024-12-09 14:13:10,357:INFO:Importing untrained model
2024-12-09 14:13:10,362:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 14:13:10,369:INFO:Starting cross validation
2024-12-09 14:13:10,371:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:10,448:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:10,448:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:10,451:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:10,451:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:10,455:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:10,466:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:10,549:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:10,550:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:10,550:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:10,553:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:10,592:INFO:Calculating mean and std
2024-12-09 14:13:10,593:INFO:Creating metrics dataframe
2024-12-09 14:13:10,596:INFO:Uploading results into container
2024-12-09 14:13:10,597:INFO:Uploading model into container now
2024-12-09 14:13:10,597:INFO:_master_model_container: 21
2024-12-09 14:13:10,597:INFO:_display_container: 3
2024-12-09 14:13:10,598:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 14:13:10,598:INFO:create_model() successfully completed......................................
2024-12-09 14:13:10,689:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:10,689:INFO:Creating metrics dataframe
2024-12-09 14:13:10,704:INFO:Initializing Ada Boost Classifier
2024-12-09 14:13:10,704:INFO:Total runtime is 0.06733073393503824 minutes
2024-12-09 14:13:10,708:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:10,708:INFO:Initializing create_model()
2024-12-09 14:13:10,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE973E80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:10,708:INFO:Checking exceptions
2024-12-09 14:13:10,708:INFO:Importing libraries
2024-12-09 14:13:10,708:INFO:Copying training dataset
2024-12-09 14:13:10,713:INFO:Defining folds
2024-12-09 14:13:10,713:INFO:Declaring metric variables
2024-12-09 14:13:10,718:INFO:Importing untrained model
2024-12-09 14:13:10,721:INFO:Ada Boost Classifier Imported successfully
2024-12-09 14:13:10,729:INFO:Starting cross validation
2024-12-09 14:13:10,730:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:11,155:INFO:Calculating mean and std
2024-12-09 14:13:11,156:INFO:Creating metrics dataframe
2024-12-09 14:13:11,160:INFO:Uploading results into container
2024-12-09 14:13:11,161:INFO:Uploading model into container now
2024-12-09 14:13:11,161:INFO:_master_model_container: 22
2024-12-09 14:13:11,161:INFO:_display_container: 3
2024-12-09 14:13:11,162:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 14:13:11,162:INFO:create_model() successfully completed......................................
2024-12-09 14:13:11,237:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:11,237:INFO:Creating metrics dataframe
2024-12-09 14:13:11,249:INFO:Initializing Gradient Boosting Classifier
2024-12-09 14:13:11,249:INFO:Total runtime is 0.07641030152638753 minutes
2024-12-09 14:13:11,254:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:11,254:INFO:Initializing create_model()
2024-12-09 14:13:11,254:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE973E80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:11,254:INFO:Checking exceptions
2024-12-09 14:13:11,254:INFO:Importing libraries
2024-12-09 14:13:11,254:INFO:Copying training dataset
2024-12-09 14:13:11,260:INFO:Defining folds
2024-12-09 14:13:11,260:INFO:Declaring metric variables
2024-12-09 14:13:11,265:INFO:Importing untrained model
2024-12-09 14:13:11,269:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 14:13:11,279:INFO:Starting cross validation
2024-12-09 14:13:11,281:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:11,773:INFO:Calculating mean and std
2024-12-09 14:13:11,775:INFO:Creating metrics dataframe
2024-12-09 14:13:11,779:INFO:Uploading results into container
2024-12-09 14:13:11,780:INFO:Uploading model into container now
2024-12-09 14:13:11,780:INFO:_master_model_container: 23
2024-12-09 14:13:11,780:INFO:_display_container: 3
2024-12-09 14:13:11,781:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 14:13:11,781:INFO:create_model() successfully completed......................................
2024-12-09 14:13:11,854:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:11,854:INFO:Creating metrics dataframe
2024-12-09 14:13:11,867:INFO:Initializing Linear Discriminant Analysis
2024-12-09 14:13:11,867:INFO:Total runtime is 0.08670826355616251 minutes
2024-12-09 14:13:11,871:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:11,871:INFO:Initializing create_model()
2024-12-09 14:13:11,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE973E80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:11,871:INFO:Checking exceptions
2024-12-09 14:13:11,871:INFO:Importing libraries
2024-12-09 14:13:11,871:INFO:Copying training dataset
2024-12-09 14:13:11,876:INFO:Defining folds
2024-12-09 14:13:11,876:INFO:Declaring metric variables
2024-12-09 14:13:11,880:INFO:Importing untrained model
2024-12-09 14:13:11,884:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 14:13:11,891:INFO:Starting cross validation
2024-12-09 14:13:11,893:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:12,147:INFO:Calculating mean and std
2024-12-09 14:13:12,148:INFO:Creating metrics dataframe
2024-12-09 14:13:12,152:INFO:Uploading results into container
2024-12-09 14:13:12,152:INFO:Uploading model into container now
2024-12-09 14:13:12,153:INFO:_master_model_container: 24
2024-12-09 14:13:12,153:INFO:_display_container: 3
2024-12-09 14:13:12,153:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 14:13:12,153:INFO:create_model() successfully completed......................................
2024-12-09 14:13:12,229:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:12,229:INFO:Creating metrics dataframe
2024-12-09 14:13:12,241:INFO:Initializing Extra Trees Classifier
2024-12-09 14:13:12,241:INFO:Total runtime is 0.09295285940170288 minutes
2024-12-09 14:13:12,245:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:12,245:INFO:Initializing create_model()
2024-12-09 14:13:12,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE973E80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:12,245:INFO:Checking exceptions
2024-12-09 14:13:12,245:INFO:Importing libraries
2024-12-09 14:13:12,246:INFO:Copying training dataset
2024-12-09 14:13:12,250:INFO:Defining folds
2024-12-09 14:13:12,250:INFO:Declaring metric variables
2024-12-09 14:13:12,253:INFO:Importing untrained model
2024-12-09 14:13:12,257:INFO:Extra Trees Classifier Imported successfully
2024-12-09 14:13:12,266:INFO:Starting cross validation
2024-12-09 14:13:12,267:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:13,064:INFO:Calculating mean and std
2024-12-09 14:13:13,065:INFO:Creating metrics dataframe
2024-12-09 14:13:13,068:INFO:Uploading results into container
2024-12-09 14:13:13,068:INFO:Uploading model into container now
2024-12-09 14:13:13,068:INFO:_master_model_container: 25
2024-12-09 14:13:13,068:INFO:_display_container: 3
2024-12-09 14:13:13,069:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 14:13:13,069:INFO:create_model() successfully completed......................................
2024-12-09 14:13:13,144:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:13,144:INFO:Creating metrics dataframe
2024-12-09 14:13:13,158:INFO:Initializing Light Gradient Boosting Machine
2024-12-09 14:13:13,158:INFO:Total runtime is 0.10822731653849284 minutes
2024-12-09 14:13:13,162:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:13,163:INFO:Initializing create_model()
2024-12-09 14:13:13,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE973E80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:13,163:INFO:Checking exceptions
2024-12-09 14:13:13,163:INFO:Importing libraries
2024-12-09 14:13:13,163:INFO:Copying training dataset
2024-12-09 14:13:13,167:INFO:Defining folds
2024-12-09 14:13:13,168:INFO:Declaring metric variables
2024-12-09 14:13:13,171:INFO:Importing untrained model
2024-12-09 14:13:13,175:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:13:13,185:INFO:Starting cross validation
2024-12-09 14:13:13,186:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:13,985:INFO:Calculating mean and std
2024-12-09 14:13:13,989:INFO:Creating metrics dataframe
2024-12-09 14:13:13,992:INFO:Uploading results into container
2024-12-09 14:13:13,992:INFO:Uploading model into container now
2024-12-09 14:13:13,993:INFO:_master_model_container: 26
2024-12-09 14:13:13,993:INFO:_display_container: 3
2024-12-09 14:13:13,994:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:13:13,994:INFO:create_model() successfully completed......................................
2024-12-09 14:13:14,092:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:14,092:INFO:Creating metrics dataframe
2024-12-09 14:13:14,118:INFO:Initializing create_model()
2024-12-09 14:13:14,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:14,118:INFO:Checking exceptions
2024-12-09 14:13:14,120:INFO:Importing libraries
2024-12-09 14:13:14,120:INFO:Copying training dataset
2024-12-09 14:13:14,125:INFO:Defining folds
2024-12-09 14:13:14,125:INFO:Declaring metric variables
2024-12-09 14:13:14,125:INFO:Importing untrained model
2024-12-09 14:13:14,125:INFO:Declaring custom model
2024-12-09 14:13:14,127:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:13:14,129:INFO:Cross validation set to False
2024-12-09 14:13:14,129:INFO:Fitting Model
2024-12-09 14:13:14,188:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 14:13:14,188:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.
2024-12-09 14:13:14,188:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 14:13:14,188:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 14:13:14,188:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 14:13:14,188:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 14:13:14,188:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 14:13:14,189:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 14:13:14,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,222:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:13:14,222:INFO:create_model() successfully completed......................................
2024-12-09 14:13:14,322:INFO:_master_model_container: 26
2024-12-09 14:13:14,323:INFO:_display_container: 3
2024-12-09 14:13:14,323:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:13:14,323:INFO:compare_models() successfully completed......................................
2024-12-09 14:13:14,324:INFO:Initializing finalize_model()
2024-12-09 14:13:14,324:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-09 14:13:14,325:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:13:14,328:INFO:Initializing create_model()
2024-12-09 14:13:14,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:14,328:INFO:Checking exceptions
2024-12-09 14:13:14,330:INFO:Importing libraries
2024-12-09 14:13:14,330:INFO:Copying training dataset
2024-12-09 14:13:14,330:INFO:Defining folds
2024-12-09 14:13:14,330:INFO:Declaring metric variables
2024-12-09 14:13:14,330:INFO:Importing untrained model
2024-12-09 14:13:14,330:INFO:Declaring custom model
2024-12-09 14:13:14,331:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:13:14,332:INFO:Cross validation set to False
2024-12-09 14:13:14,332:INFO:Fitting Model
2024-12-09 14:13:14,382:INFO:[LightGBM] [Info] Number of positive: 342, number of negative: 549
2024-12-09 14:13:14,382:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.
2024-12-09 14:13:14,382:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 14:13:14,382:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 14:13:14,382:INFO:[LightGBM] [Info] Total Bins 224
2024-12-09 14:13:14,382:INFO:[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 9
2024-12-09 14:13:14,383:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288
2024-12-09 14:13:14,383:INFO:[LightGBM] [Info] Start training from score -0.473288
2024-12-09 14:13:14,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:14,433:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-09 14:13:14,433:INFO:create_model() successfully completed......................................
2024-12-09 14:13:14,508:INFO:_master_model_container: 26
2024-12-09 14:13:14,508:INFO:_display_container: 3
2024-12-09 14:13:14,527:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-09 14:13:14,527:INFO:finalize_model() successfully completed......................................
2024-12-09 14:13:14,619:INFO:Initializing predict_model()
2024-12-09 14:13:14,619:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C1364070>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E6BEDDA0D0>)
2024-12-09 14:13:14,620:INFO:Checking exceptions
2024-12-09 14:13:14,620:INFO:Preloading libraries
2024-12-09 14:13:14,621:INFO:Set up data.
2024-12-09 14:13:14,625:INFO:Set up index.
2024-12-09 14:13:23,273:INFO:PyCaret ClassificationExperiment
2024-12-09 14:13:23,273:INFO:Logging name: clf-default-name
2024-12-09 14:13:23,274:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-09 14:13:23,274:INFO:version 3.2.0
2024-12-09 14:13:23,274:INFO:Initializing setup()
2024-12-09 14:13:23,274:INFO:self.USI: d582
2024-12-09 14:13:23,274:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'pipeline', 'X_test', 'html_param', '_ml_usecase', 'seed', 'gpu_param', '_available_plots', 'X', 'X_train', 'fold_shuffle_param', 'y_test', 'log_plots_param', 'y', 'gpu_n_jobs_param', 'target_param', 'USI', 'fix_imbalance', 'n_jobs_param', 'idx', 'logging_param', 'exp_id', 'memory', 'data', 'fold_generator', 'y_train', 'exp_name_log'}
2024-12-09 14:13:23,274:INFO:Checking environment
2024-12-09 14:13:23,274:INFO:python_version: 3.8.20
2024-12-09 14:13:23,274:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2024-12-09 14:13:23,274:INFO:machine: AMD64
2024-12-09 14:13:23,274:INFO:platform: Windows-10-10.0.19041-SP0
2024-12-09 14:13:23,277:INFO:Memory: svmem(total=17054896128, available=6242172928, percent=63.4, used=10812723200, free=6242172928)
2024-12-09 14:13:23,277:INFO:Physical Core: 6
2024-12-09 14:13:23,277:INFO:Logical Core: 6
2024-12-09 14:13:23,277:INFO:Checking libraries
2024-12-09 14:13:23,277:INFO:System:
2024-12-09 14:13:23,277:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2024-12-09 14:13:23,277:INFO:executable: c:\Users\EE715\anaconda3\envs\gym-env\python.exe
2024-12-09 14:13:23,277:INFO:   machine: Windows-10-10.0.19041-SP0
2024-12-09 14:13:23,277:INFO:PyCaret required dependencies:
2024-12-09 14:13:23,277:INFO:                 pip: 24.2
2024-12-09 14:13:23,277:INFO:          setuptools: 75.1.0
2024-12-09 14:13:23,277:INFO:             pycaret: 3.2.0
2024-12-09 14:13:23,277:INFO:             IPython: 8.12.3
2024-12-09 14:13:23,277:INFO:          ipywidgets: 8.1.5
2024-12-09 14:13:23,277:INFO:                tqdm: 4.67.1
2024-12-09 14:13:23,278:INFO:               numpy: 1.24.4
2024-12-09 14:13:23,278:INFO:              pandas: 1.5.3
2024-12-09 14:13:23,278:INFO:              jinja2: 3.1.4
2024-12-09 14:13:23,278:INFO:               scipy: 1.10.1
2024-12-09 14:13:23,278:INFO:              joblib: 1.2.0
2024-12-09 14:13:23,278:INFO:             sklearn: 1.2.2
2024-12-09 14:13:23,278:INFO:                pyod: 2.0.2
2024-12-09 14:13:23,278:INFO:            imblearn: 0.12.4
2024-12-09 14:13:23,278:INFO:   category_encoders: 2.6.4
2024-12-09 14:13:23,278:INFO:            lightgbm: 4.5.0
2024-12-09 14:13:23,278:INFO:               numba: 0.58.1
2024-12-09 14:13:23,278:INFO:            requests: 2.32.3
2024-12-09 14:13:23,278:INFO:          matplotlib: 3.6.0
2024-12-09 14:13:23,278:INFO:          scikitplot: 0.3.7
2024-12-09 14:13:23,278:INFO:         yellowbrick: 1.5
2024-12-09 14:13:23,278:INFO:              plotly: 5.24.1
2024-12-09 14:13:23,278:INFO:    plotly-resampler: Not installed
2024-12-09 14:13:23,278:INFO:             kaleido: 0.2.1
2024-12-09 14:13:23,278:INFO:           schemdraw: 0.15
2024-12-09 14:13:23,278:INFO:         statsmodels: 0.14.1
2024-12-09 14:13:23,278:INFO:              sktime: 0.21.1
2024-12-09 14:13:23,278:INFO:               tbats: 1.1.3
2024-12-09 14:13:23,279:INFO:            pmdarima: 2.0.4
2024-12-09 14:13:23,279:INFO:              psutil: 6.1.0
2024-12-09 14:13:23,279:INFO:          markupsafe: 2.1.5
2024-12-09 14:13:23,279:INFO:             pickle5: Not installed
2024-12-09 14:13:23,279:INFO:         cloudpickle: 3.1.0
2024-12-09 14:13:23,279:INFO:         deprecation: 2.1.0
2024-12-09 14:13:23,279:INFO:              xxhash: 3.5.0
2024-12-09 14:13:23,279:INFO:           wurlitzer: Not installed
2024-12-09 14:13:23,279:INFO:PyCaret optional dependencies:
2024-12-09 14:13:23,279:INFO:                shap: Not installed
2024-12-09 14:13:23,279:INFO:           interpret: Not installed
2024-12-09 14:13:23,279:INFO:                umap: Not installed
2024-12-09 14:13:23,279:INFO:     ydata_profiling: Not installed
2024-12-09 14:13:23,279:INFO:  explainerdashboard: Not installed
2024-12-09 14:13:23,279:INFO:             autoviz: Not installed
2024-12-09 14:13:23,279:INFO:           fairlearn: Not installed
2024-12-09 14:13:23,279:INFO:          deepchecks: Not installed
2024-12-09 14:13:23,279:INFO:             xgboost: Not installed
2024-12-09 14:13:23,279:INFO:            catboost: Not installed
2024-12-09 14:13:23,279:INFO:              kmodes: Not installed
2024-12-09 14:13:23,279:INFO:             mlxtend: Not installed
2024-12-09 14:13:23,279:INFO:       statsforecast: Not installed
2024-12-09 14:13:23,280:INFO:        tune_sklearn: Not installed
2024-12-09 14:13:23,280:INFO:                 ray: Not installed
2024-12-09 14:13:23,280:INFO:            hyperopt: Not installed
2024-12-09 14:13:23,280:INFO:              optuna: 4.1.0
2024-12-09 14:13:23,280:INFO:               skopt: Not installed
2024-12-09 14:13:23,280:INFO:              mlflow: Not installed
2024-12-09 14:13:23,280:INFO:              gradio: Not installed
2024-12-09 14:13:23,280:INFO:             fastapi: Not installed
2024-12-09 14:13:23,280:INFO:             uvicorn: Not installed
2024-12-09 14:13:23,280:INFO:              m2cgen: Not installed
2024-12-09 14:13:23,280:INFO:           evidently: Not installed
2024-12-09 14:13:23,280:INFO:               fugue: Not installed
2024-12-09 14:13:23,280:INFO:           streamlit: Not installed
2024-12-09 14:13:23,280:INFO:             prophet: Not installed
2024-12-09 14:13:23,280:INFO:None
2024-12-09 14:13:23,280:INFO:Set up data.
2024-12-09 14:13:23,289:INFO:Set up folding strategy.
2024-12-09 14:13:23,289:INFO:Set up train/test split.
2024-12-09 14:13:23,294:INFO:Set up index.
2024-12-09 14:13:23,294:INFO:Assigning column types.
2024-12-09 14:13:23,297:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-09 14:13:23,344:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 14:13:23,345:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:13:23,372:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:23,372:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:23,414:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 14:13:23,416:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:13:23,440:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:23,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:23,441:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-09 14:13:23,483:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:13:23,508:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:23,509:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:23,551:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:13:23,577:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:23,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:23,577:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-09 14:13:23,643:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:23,644:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:23,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:23,710:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:23,711:INFO:Preparing preprocessing pipeline...
2024-12-09 14:13:23,712:INFO:Set up simple imputation.
2024-12-09 14:13:23,714:INFO:Set up encoding of ordinal features.
2024-12-09 14:13:23,716:INFO:Set up encoding of categorical features.
2024-12-09 14:13:23,783:INFO:Finished creating preprocessing pipeline.
2024-12-09 14:13:23,800:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\EE715\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categ...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-12-09 14:13:23,800:INFO:Creating final display dataframe.
2024-12-09 14:13:24,032:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (623, 10)
6    Transformed test set shape         (268, 10)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              d582
2024-12-09 14:13:24,109:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:24,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:24,178:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:24,178:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:24,180:INFO:setup() successfully completed in 0.91s...............
2024-12-09 14:13:24,180:INFO:Initializing compare_models()
2024-12-09 14:13:24,180:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['dummy'])
2024-12-09 14:13:24,180:INFO:Checking exceptions
2024-12-09 14:13:24,183:INFO:Preparing display monitor
2024-12-09 14:13:24,208:INFO:Initializing Logistic Regression
2024-12-09 14:13:24,208:INFO:Total runtime is 0.0 minutes
2024-12-09 14:13:24,212:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:24,212:INFO:Initializing create_model()
2024-12-09 14:13:24,212:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0BFB700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:24,212:INFO:Checking exceptions
2024-12-09 14:13:24,212:INFO:Importing libraries
2024-12-09 14:13:24,213:INFO:Copying training dataset
2024-12-09 14:13:24,217:INFO:Defining folds
2024-12-09 14:13:24,217:INFO:Declaring metric variables
2024-12-09 14:13:24,222:INFO:Importing untrained model
2024-12-09 14:13:24,226:INFO:Logistic Regression Imported successfully
2024-12-09 14:13:24,233:INFO:Starting cross validation
2024-12-09 14:13:24,234:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:24,671:INFO:Calculating mean and std
2024-12-09 14:13:24,672:INFO:Creating metrics dataframe
2024-12-09 14:13:24,675:INFO:Uploading results into container
2024-12-09 14:13:24,676:INFO:Uploading model into container now
2024-12-09 14:13:24,676:INFO:_master_model_container: 1
2024-12-09 14:13:24,676:INFO:_display_container: 2
2024-12-09 14:13:24,677:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 14:13:24,677:INFO:create_model() successfully completed......................................
2024-12-09 14:13:24,768:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:24,768:INFO:Creating metrics dataframe
2024-12-09 14:13:24,778:INFO:Initializing K Neighbors Classifier
2024-12-09 14:13:24,778:INFO:Total runtime is 0.009485435485839844 minutes
2024-12-09 14:13:24,782:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:24,782:INFO:Initializing create_model()
2024-12-09 14:13:24,782:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0BFB700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:24,782:INFO:Checking exceptions
2024-12-09 14:13:24,783:INFO:Importing libraries
2024-12-09 14:13:24,783:INFO:Copying training dataset
2024-12-09 14:13:24,786:INFO:Defining folds
2024-12-09 14:13:24,786:INFO:Declaring metric variables
2024-12-09 14:13:24,791:INFO:Importing untrained model
2024-12-09 14:13:24,795:INFO:K Neighbors Classifier Imported successfully
2024-12-09 14:13:24,803:INFO:Starting cross validation
2024-12-09 14:13:24,804:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:25,095:INFO:Calculating mean and std
2024-12-09 14:13:25,095:INFO:Creating metrics dataframe
2024-12-09 14:13:25,098:INFO:Uploading results into container
2024-12-09 14:13:25,099:INFO:Uploading model into container now
2024-12-09 14:13:25,099:INFO:_master_model_container: 2
2024-12-09 14:13:25,099:INFO:_display_container: 2
2024-12-09 14:13:25,099:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 14:13:25,099:INFO:create_model() successfully completed......................................
2024-12-09 14:13:25,179:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:25,179:INFO:Creating metrics dataframe
2024-12-09 14:13:25,188:INFO:Initializing Naive Bayes
2024-12-09 14:13:25,188:INFO:Total runtime is 0.01632371743520101 minutes
2024-12-09 14:13:25,191:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:25,192:INFO:Initializing create_model()
2024-12-09 14:13:25,192:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0BFB700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:25,192:INFO:Checking exceptions
2024-12-09 14:13:25,192:INFO:Importing libraries
2024-12-09 14:13:25,192:INFO:Copying training dataset
2024-12-09 14:13:25,196:INFO:Defining folds
2024-12-09 14:13:25,197:INFO:Declaring metric variables
2024-12-09 14:13:25,200:INFO:Importing untrained model
2024-12-09 14:13:25,204:INFO:Naive Bayes Imported successfully
2024-12-09 14:13:25,210:INFO:Starting cross validation
2024-12-09 14:13:25,211:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:25,421:INFO:Calculating mean and std
2024-12-09 14:13:25,423:INFO:Creating metrics dataframe
2024-12-09 14:13:25,426:INFO:Uploading results into container
2024-12-09 14:13:25,427:INFO:Uploading model into container now
2024-12-09 14:13:25,427:INFO:_master_model_container: 3
2024-12-09 14:13:25,428:INFO:_display_container: 2
2024-12-09 14:13:25,428:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 14:13:25,428:INFO:create_model() successfully completed......................................
2024-12-09 14:13:25,507:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:25,507:INFO:Creating metrics dataframe
2024-12-09 14:13:25,517:INFO:Initializing Decision Tree Classifier
2024-12-09 14:13:25,517:INFO:Total runtime is 0.021809891859690348 minutes
2024-12-09 14:13:25,520:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:25,520:INFO:Initializing create_model()
2024-12-09 14:13:25,521:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0BFB700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:25,521:INFO:Checking exceptions
2024-12-09 14:13:25,521:INFO:Importing libraries
2024-12-09 14:13:25,521:INFO:Copying training dataset
2024-12-09 14:13:25,526:INFO:Defining folds
2024-12-09 14:13:25,526:INFO:Declaring metric variables
2024-12-09 14:13:25,529:INFO:Importing untrained model
2024-12-09 14:13:25,533:INFO:Decision Tree Classifier Imported successfully
2024-12-09 14:13:25,541:INFO:Starting cross validation
2024-12-09 14:13:25,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:25,754:INFO:Calculating mean and std
2024-12-09 14:13:25,755:INFO:Creating metrics dataframe
2024-12-09 14:13:25,759:INFO:Uploading results into container
2024-12-09 14:13:25,760:INFO:Uploading model into container now
2024-12-09 14:13:25,760:INFO:_master_model_container: 4
2024-12-09 14:13:25,760:INFO:_display_container: 2
2024-12-09 14:13:25,760:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 14:13:25,761:INFO:create_model() successfully completed......................................
2024-12-09 14:13:25,836:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:25,837:INFO:Creating metrics dataframe
2024-12-09 14:13:25,847:INFO:Initializing SVM - Linear Kernel
2024-12-09 14:13:25,847:INFO:Total runtime is 0.027307764689127604 minutes
2024-12-09 14:13:25,851:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:25,851:INFO:Initializing create_model()
2024-12-09 14:13:25,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0BFB700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:25,851:INFO:Checking exceptions
2024-12-09 14:13:25,851:INFO:Importing libraries
2024-12-09 14:13:25,852:INFO:Copying training dataset
2024-12-09 14:13:25,856:INFO:Defining folds
2024-12-09 14:13:25,857:INFO:Declaring metric variables
2024-12-09 14:13:25,861:INFO:Importing untrained model
2024-12-09 14:13:25,865:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 14:13:25,871:INFO:Starting cross validation
2024-12-09 14:13:25,874:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:25,975:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:25,980:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:25,984:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:13:25,995:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:26,011:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:26,016:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:26,016:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:26,072:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:26,091:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:26,095:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:13:26,101:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:26,103:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:26,111:INFO:Calculating mean and std
2024-12-09 14:13:26,112:INFO:Creating metrics dataframe
2024-12-09 14:13:26,115:INFO:Uploading results into container
2024-12-09 14:13:26,116:INFO:Uploading model into container now
2024-12-09 14:13:26,116:INFO:_master_model_container: 5
2024-12-09 14:13:26,116:INFO:_display_container: 2
2024-12-09 14:13:26,116:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 14:13:26,116:INFO:create_model() successfully completed......................................
2024-12-09 14:13:26,192:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:26,192:INFO:Creating metrics dataframe
2024-12-09 14:13:26,202:INFO:Initializing Ridge Classifier
2024-12-09 14:13:26,202:INFO:Total runtime is 0.033230729897816974 minutes
2024-12-09 14:13:26,205:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:26,206:INFO:Initializing create_model()
2024-12-09 14:13:26,206:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0BFB700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:26,206:INFO:Checking exceptions
2024-12-09 14:13:26,206:INFO:Importing libraries
2024-12-09 14:13:26,206:INFO:Copying training dataset
2024-12-09 14:13:26,210:INFO:Defining folds
2024-12-09 14:13:26,210:INFO:Declaring metric variables
2024-12-09 14:13:26,214:INFO:Importing untrained model
2024-12-09 14:13:26,217:INFO:Ridge Classifier Imported successfully
2024-12-09 14:13:26,226:INFO:Starting cross validation
2024-12-09 14:13:26,227:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:26,335:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:26,346:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:26,369:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:26,374:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:26,377:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:26,413:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:26,441:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:26,451:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:26,477:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:26,478:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:26,486:INFO:Calculating mean and std
2024-12-09 14:13:26,486:INFO:Creating metrics dataframe
2024-12-09 14:13:26,490:INFO:Uploading results into container
2024-12-09 14:13:26,492:INFO:Uploading model into container now
2024-12-09 14:13:26,492:INFO:_master_model_container: 6
2024-12-09 14:13:26,492:INFO:_display_container: 2
2024-12-09 14:13:26,492:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 14:13:26,493:INFO:create_model() successfully completed......................................
2024-12-09 14:13:26,566:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:26,566:INFO:Creating metrics dataframe
2024-12-09 14:13:26,576:INFO:Initializing Random Forest Classifier
2024-12-09 14:13:26,576:INFO:Total runtime is 0.03945653835932414 minutes
2024-12-09 14:13:26,580:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:26,580:INFO:Initializing create_model()
2024-12-09 14:13:26,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0BFB700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:26,580:INFO:Checking exceptions
2024-12-09 14:13:26,581:INFO:Importing libraries
2024-12-09 14:13:26,581:INFO:Copying training dataset
2024-12-09 14:13:26,584:INFO:Defining folds
2024-12-09 14:13:26,584:INFO:Declaring metric variables
2024-12-09 14:13:26,588:INFO:Importing untrained model
2024-12-09 14:13:26,591:INFO:Random Forest Classifier Imported successfully
2024-12-09 14:13:26,599:INFO:Starting cross validation
2024-12-09 14:13:26,600:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:27,295:INFO:Calculating mean and std
2024-12-09 14:13:27,295:INFO:Creating metrics dataframe
2024-12-09 14:13:27,299:INFO:Uploading results into container
2024-12-09 14:13:27,300:INFO:Uploading model into container now
2024-12-09 14:13:27,300:INFO:_master_model_container: 7
2024-12-09 14:13:27,300:INFO:_display_container: 2
2024-12-09 14:13:27,301:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 14:13:27,301:INFO:create_model() successfully completed......................................
2024-12-09 14:13:27,382:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:27,382:INFO:Creating metrics dataframe
2024-12-09 14:13:27,393:INFO:Initializing Quadratic Discriminant Analysis
2024-12-09 14:13:27,393:INFO:Total runtime is 0.053074669837951664 minutes
2024-12-09 14:13:27,396:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:27,396:INFO:Initializing create_model()
2024-12-09 14:13:27,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0BFB700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:27,397:INFO:Checking exceptions
2024-12-09 14:13:27,397:INFO:Importing libraries
2024-12-09 14:13:27,397:INFO:Copying training dataset
2024-12-09 14:13:27,400:INFO:Defining folds
2024-12-09 14:13:27,400:INFO:Declaring metric variables
2024-12-09 14:13:27,404:INFO:Importing untrained model
2024-12-09 14:13:27,407:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 14:13:27,415:INFO:Starting cross validation
2024-12-09 14:13:27,417:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:27,488:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:27,488:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:27,488:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:27,489:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:27,502:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:27,512:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:27,584:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:27,584:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:27,587:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:27,589:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:27,628:INFO:Calculating mean and std
2024-12-09 14:13:27,629:INFO:Creating metrics dataframe
2024-12-09 14:13:27,632:INFO:Uploading results into container
2024-12-09 14:13:27,633:INFO:Uploading model into container now
2024-12-09 14:13:27,633:INFO:_master_model_container: 8
2024-12-09 14:13:27,633:INFO:_display_container: 2
2024-12-09 14:13:27,634:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 14:13:27,634:INFO:create_model() successfully completed......................................
2024-12-09 14:13:27,707:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:27,708:INFO:Creating metrics dataframe
2024-12-09 14:13:27,718:INFO:Initializing Ada Boost Classifier
2024-12-09 14:13:27,718:INFO:Total runtime is 0.058498891194661465 minutes
2024-12-09 14:13:27,723:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:27,723:INFO:Initializing create_model()
2024-12-09 14:13:27,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0BFB700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:27,723:INFO:Checking exceptions
2024-12-09 14:13:27,723:INFO:Importing libraries
2024-12-09 14:13:27,723:INFO:Copying training dataset
2024-12-09 14:13:27,728:INFO:Defining folds
2024-12-09 14:13:27,728:INFO:Declaring metric variables
2024-12-09 14:13:27,732:INFO:Importing untrained model
2024-12-09 14:13:27,735:INFO:Ada Boost Classifier Imported successfully
2024-12-09 14:13:27,745:INFO:Starting cross validation
2024-12-09 14:13:27,746:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:28,154:INFO:Calculating mean and std
2024-12-09 14:13:28,154:INFO:Creating metrics dataframe
2024-12-09 14:13:28,158:INFO:Uploading results into container
2024-12-09 14:13:28,159:INFO:Uploading model into container now
2024-12-09 14:13:28,159:INFO:_master_model_container: 9
2024-12-09 14:13:28,159:INFO:_display_container: 2
2024-12-09 14:13:28,160:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 14:13:28,160:INFO:create_model() successfully completed......................................
2024-12-09 14:13:28,236:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:28,236:INFO:Creating metrics dataframe
2024-12-09 14:13:28,248:INFO:Initializing Gradient Boosting Classifier
2024-12-09 14:13:28,249:INFO:Total runtime is 0.06734333435694377 minutes
2024-12-09 14:13:28,252:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:28,253:INFO:Initializing create_model()
2024-12-09 14:13:28,253:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0BFB700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:28,253:INFO:Checking exceptions
2024-12-09 14:13:28,253:INFO:Importing libraries
2024-12-09 14:13:28,253:INFO:Copying training dataset
2024-12-09 14:13:28,257:INFO:Defining folds
2024-12-09 14:13:28,257:INFO:Declaring metric variables
2024-12-09 14:13:28,261:INFO:Importing untrained model
2024-12-09 14:13:28,265:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 14:13:28,273:INFO:Starting cross validation
2024-12-09 14:13:28,274:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:28,748:INFO:Calculating mean and std
2024-12-09 14:13:28,748:INFO:Creating metrics dataframe
2024-12-09 14:13:28,753:INFO:Uploading results into container
2024-12-09 14:13:28,753:INFO:Uploading model into container now
2024-12-09 14:13:28,754:INFO:_master_model_container: 10
2024-12-09 14:13:28,754:INFO:_display_container: 2
2024-12-09 14:13:28,754:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 14:13:28,754:INFO:create_model() successfully completed......................................
2024-12-09 14:13:28,828:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:28,829:INFO:Creating metrics dataframe
2024-12-09 14:13:28,840:INFO:Initializing Linear Discriminant Analysis
2024-12-09 14:13:28,840:INFO:Total runtime is 0.07719036340713502 minutes
2024-12-09 14:13:28,844:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:28,845:INFO:Initializing create_model()
2024-12-09 14:13:28,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0BFB700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:28,845:INFO:Checking exceptions
2024-12-09 14:13:28,845:INFO:Importing libraries
2024-12-09 14:13:28,845:INFO:Copying training dataset
2024-12-09 14:13:28,849:INFO:Defining folds
2024-12-09 14:13:28,849:INFO:Declaring metric variables
2024-12-09 14:13:28,852:INFO:Importing untrained model
2024-12-09 14:13:28,855:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 14:13:28,863:INFO:Starting cross validation
2024-12-09 14:13:28,865:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:29,078:INFO:Calculating mean and std
2024-12-09 14:13:29,079:INFO:Creating metrics dataframe
2024-12-09 14:13:29,082:INFO:Uploading results into container
2024-12-09 14:13:29,083:INFO:Uploading model into container now
2024-12-09 14:13:29,083:INFO:_master_model_container: 11
2024-12-09 14:13:29,083:INFO:_display_container: 2
2024-12-09 14:13:29,084:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 14:13:29,084:INFO:create_model() successfully completed......................................
2024-12-09 14:13:29,158:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:29,158:INFO:Creating metrics dataframe
2024-12-09 14:13:29,171:INFO:Initializing Extra Trees Classifier
2024-12-09 14:13:29,171:INFO:Total runtime is 0.08270486990610759 minutes
2024-12-09 14:13:29,174:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:29,174:INFO:Initializing create_model()
2024-12-09 14:13:29,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0BFB700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:29,174:INFO:Checking exceptions
2024-12-09 14:13:29,174:INFO:Importing libraries
2024-12-09 14:13:29,174:INFO:Copying training dataset
2024-12-09 14:13:29,179:INFO:Defining folds
2024-12-09 14:13:29,179:INFO:Declaring metric variables
2024-12-09 14:13:29,182:INFO:Importing untrained model
2024-12-09 14:13:29,186:INFO:Extra Trees Classifier Imported successfully
2024-12-09 14:13:29,194:INFO:Starting cross validation
2024-12-09 14:13:29,196:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:29,866:INFO:Calculating mean and std
2024-12-09 14:13:29,867:INFO:Creating metrics dataframe
2024-12-09 14:13:29,871:INFO:Uploading results into container
2024-12-09 14:13:29,871:INFO:Uploading model into container now
2024-12-09 14:13:29,872:INFO:_master_model_container: 12
2024-12-09 14:13:29,872:INFO:_display_container: 2
2024-12-09 14:13:29,872:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 14:13:29,872:INFO:create_model() successfully completed......................................
2024-12-09 14:13:29,949:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:29,949:INFO:Creating metrics dataframe
2024-12-09 14:13:29,961:INFO:Initializing Light Gradient Boosting Machine
2024-12-09 14:13:29,961:INFO:Total runtime is 0.09588228464126587 minutes
2024-12-09 14:13:29,964:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:29,965:INFO:Initializing create_model()
2024-12-09 14:13:29,965:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0BFB700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:29,965:INFO:Checking exceptions
2024-12-09 14:13:29,965:INFO:Importing libraries
2024-12-09 14:13:29,965:INFO:Copying training dataset
2024-12-09 14:13:29,970:INFO:Defining folds
2024-12-09 14:13:29,970:INFO:Declaring metric variables
2024-12-09 14:13:29,973:INFO:Importing untrained model
2024-12-09 14:13:29,977:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:13:29,985:INFO:Starting cross validation
2024-12-09 14:13:29,986:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:30,762:INFO:Calculating mean and std
2024-12-09 14:13:30,763:INFO:Creating metrics dataframe
2024-12-09 14:13:30,767:INFO:Uploading results into container
2024-12-09 14:13:30,767:INFO:Uploading model into container now
2024-12-09 14:13:30,767:INFO:_master_model_container: 13
2024-12-09 14:13:30,768:INFO:_display_container: 2
2024-12-09 14:13:30,769:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:13:30,769:INFO:create_model() successfully completed......................................
2024-12-09 14:13:30,846:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:30,846:INFO:Creating metrics dataframe
2024-12-09 14:13:30,868:INFO:Initializing create_model()
2024-12-09 14:13:30,869:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:30,869:INFO:Checking exceptions
2024-12-09 14:13:30,871:INFO:Importing libraries
2024-12-09 14:13:30,872:INFO:Copying training dataset
2024-12-09 14:13:30,875:INFO:Defining folds
2024-12-09 14:13:30,875:INFO:Declaring metric variables
2024-12-09 14:13:30,875:INFO:Importing untrained model
2024-12-09 14:13:30,875:INFO:Declaring custom model
2024-12-09 14:13:30,876:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:13:30,877:INFO:Cross validation set to False
2024-12-09 14:13:30,877:INFO:Fitting Model
2024-12-09 14:13:30,919:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 14:13:30,920:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000071 seconds.
2024-12-09 14:13:30,920:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 14:13:30,920:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 14:13:30,920:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 14:13:30,920:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 14:13:30,920:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 14:13:30,920:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 14:13:30,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:30,952:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:13:30,953:INFO:create_model() successfully completed......................................
2024-12-09 14:13:31,032:INFO:Initializing create_model()
2024-12-09 14:13:31,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:31,032:INFO:Checking exceptions
2024-12-09 14:13:31,034:INFO:Importing libraries
2024-12-09 14:13:31,034:INFO:Copying training dataset
2024-12-09 14:13:31,038:INFO:Defining folds
2024-12-09 14:13:31,038:INFO:Declaring metric variables
2024-12-09 14:13:31,038:INFO:Importing untrained model
2024-12-09 14:13:31,038:INFO:Declaring custom model
2024-12-09 14:13:31,039:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 14:13:31,041:INFO:Cross validation set to False
2024-12-09 14:13:31,041:INFO:Fitting Model
2024-12-09 14:13:31,207:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 14:13:31,207:INFO:create_model() successfully completed......................................
2024-12-09 14:13:31,285:INFO:Initializing create_model()
2024-12-09 14:13:31,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:31,285:INFO:Checking exceptions
2024-12-09 14:13:31,286:INFO:Importing libraries
2024-12-09 14:13:31,287:INFO:Copying training dataset
2024-12-09 14:13:31,290:INFO:Defining folds
2024-12-09 14:13:31,290:INFO:Declaring metric variables
2024-12-09 14:13:31,290:INFO:Importing untrained model
2024-12-09 14:13:31,290:INFO:Declaring custom model
2024-12-09 14:13:31,291:INFO:Random Forest Classifier Imported successfully
2024-12-09 14:13:31,292:INFO:Cross validation set to False
2024-12-09 14:13:31,292:INFO:Fitting Model
2024-12-09 14:13:31,493:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 14:13:31,493:INFO:create_model() successfully completed......................................
2024-12-09 14:13:31,573:INFO:Initializing create_model()
2024-12-09 14:13:31,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:31,574:INFO:Checking exceptions
2024-12-09 14:13:31,576:INFO:Importing libraries
2024-12-09 14:13:31,576:INFO:Copying training dataset
2024-12-09 14:13:31,580:INFO:Defining folds
2024-12-09 14:13:31,580:INFO:Declaring metric variables
2024-12-09 14:13:31,580:INFO:Importing untrained model
2024-12-09 14:13:31,580:INFO:Declaring custom model
2024-12-09 14:13:31,580:INFO:Ada Boost Classifier Imported successfully
2024-12-09 14:13:31,581:INFO:Cross validation set to False
2024-12-09 14:13:31,581:INFO:Fitting Model
2024-12-09 14:13:31,693:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 14:13:31,693:INFO:create_model() successfully completed......................................
2024-12-09 14:13:31,771:INFO:Initializing create_model()
2024-12-09 14:13:31,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:31,772:INFO:Checking exceptions
2024-12-09 14:13:31,774:INFO:Importing libraries
2024-12-09 14:13:31,774:INFO:Copying training dataset
2024-12-09 14:13:31,777:INFO:Defining folds
2024-12-09 14:13:31,777:INFO:Declaring metric variables
2024-12-09 14:13:31,777:INFO:Importing untrained model
2024-12-09 14:13:31,777:INFO:Declaring custom model
2024-12-09 14:13:31,778:INFO:Logistic Regression Imported successfully
2024-12-09 14:13:31,779:INFO:Cross validation set to False
2024-12-09 14:13:31,779:INFO:Fitting Model
2024-12-09 14:13:31,861:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 14:13:31,861:INFO:create_model() successfully completed......................................
2024-12-09 14:13:31,951:INFO:Initializing create_model()
2024-12-09 14:13:31,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:31,952:INFO:Checking exceptions
2024-12-09 14:13:31,954:INFO:Importing libraries
2024-12-09 14:13:31,954:INFO:Copying training dataset
2024-12-09 14:13:31,957:INFO:Defining folds
2024-12-09 14:13:31,957:INFO:Declaring metric variables
2024-12-09 14:13:31,957:INFO:Importing untrained model
2024-12-09 14:13:31,957:INFO:Declaring custom model
2024-12-09 14:13:31,958:INFO:Extra Trees Classifier Imported successfully
2024-12-09 14:13:31,959:INFO:Cross validation set to False
2024-12-09 14:13:31,959:INFO:Fitting Model
2024-12-09 14:13:32,130:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 14:13:32,130:INFO:create_model() successfully completed......................................
2024-12-09 14:13:32,209:INFO:Initializing create_model()
2024-12-09 14:13:32,209:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:32,209:INFO:Checking exceptions
2024-12-09 14:13:32,211:INFO:Importing libraries
2024-12-09 14:13:32,211:INFO:Copying training dataset
2024-12-09 14:13:32,214:INFO:Defining folds
2024-12-09 14:13:32,215:INFO:Declaring metric variables
2024-12-09 14:13:32,215:INFO:Importing untrained model
2024-12-09 14:13:32,215:INFO:Declaring custom model
2024-12-09 14:13:32,215:INFO:Ridge Classifier Imported successfully
2024-12-09 14:13:32,216:INFO:Cross validation set to False
2024-12-09 14:13:32,216:INFO:Fitting Model
2024-12-09 14:13:32,257:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 14:13:32,258:INFO:create_model() successfully completed......................................
2024-12-09 14:13:32,337:INFO:Initializing create_model()
2024-12-09 14:13:32,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:32,337:INFO:Checking exceptions
2024-12-09 14:13:32,339:INFO:Importing libraries
2024-12-09 14:13:32,339:INFO:Copying training dataset
2024-12-09 14:13:32,342:INFO:Defining folds
2024-12-09 14:13:32,342:INFO:Declaring metric variables
2024-12-09 14:13:32,342:INFO:Importing untrained model
2024-12-09 14:13:32,343:INFO:Declaring custom model
2024-12-09 14:13:32,343:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 14:13:32,344:INFO:Cross validation set to False
2024-12-09 14:13:32,344:INFO:Fitting Model
2024-12-09 14:13:32,387:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 14:13:32,387:INFO:create_model() successfully completed......................................
2024-12-09 14:13:32,466:INFO:Initializing create_model()
2024-12-09 14:13:32,466:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:32,466:INFO:Checking exceptions
2024-12-09 14:13:32,468:INFO:Importing libraries
2024-12-09 14:13:32,468:INFO:Copying training dataset
2024-12-09 14:13:32,471:INFO:Defining folds
2024-12-09 14:13:32,471:INFO:Declaring metric variables
2024-12-09 14:13:32,472:INFO:Importing untrained model
2024-12-09 14:13:32,472:INFO:Declaring custom model
2024-12-09 14:13:32,472:INFO:Naive Bayes Imported successfully
2024-12-09 14:13:32,473:INFO:Cross validation set to False
2024-12-09 14:13:32,473:INFO:Fitting Model
2024-12-09 14:13:32,514:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 14:13:32,514:INFO:create_model() successfully completed......................................
2024-12-09 14:13:32,593:INFO:Initializing create_model()
2024-12-09 14:13:32,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:32,593:INFO:Checking exceptions
2024-12-09 14:13:32,595:INFO:Importing libraries
2024-12-09 14:13:32,595:INFO:Copying training dataset
2024-12-09 14:13:32,599:INFO:Defining folds
2024-12-09 14:13:32,599:INFO:Declaring metric variables
2024-12-09 14:13:32,599:INFO:Importing untrained model
2024-12-09 14:13:32,599:INFO:Declaring custom model
2024-12-09 14:13:32,600:INFO:Decision Tree Classifier Imported successfully
2024-12-09 14:13:32,601:INFO:Cross validation set to False
2024-12-09 14:13:32,601:INFO:Fitting Model
2024-12-09 14:13:32,642:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 14:13:32,642:INFO:create_model() successfully completed......................................
2024-12-09 14:13:32,721:INFO:Initializing create_model()
2024-12-09 14:13:32,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:32,721:INFO:Checking exceptions
2024-12-09 14:13:32,723:INFO:Importing libraries
2024-12-09 14:13:32,723:INFO:Copying training dataset
2024-12-09 14:13:32,726:INFO:Defining folds
2024-12-09 14:13:32,726:INFO:Declaring metric variables
2024-12-09 14:13:32,726:INFO:Importing untrained model
2024-12-09 14:13:32,726:INFO:Declaring custom model
2024-12-09 14:13:32,727:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 14:13:32,728:INFO:Cross validation set to False
2024-12-09 14:13:32,728:INFO:Fitting Model
2024-12-09 14:13:32,768:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:32,769:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 14:13:32,769:INFO:create_model() successfully completed......................................
2024-12-09 14:13:32,848:INFO:Initializing create_model()
2024-12-09 14:13:32,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:32,848:INFO:Checking exceptions
2024-12-09 14:13:32,850:INFO:Importing libraries
2024-12-09 14:13:32,851:INFO:Copying training dataset
2024-12-09 14:13:32,854:INFO:Defining folds
2024-12-09 14:13:32,854:INFO:Declaring metric variables
2024-12-09 14:13:32,854:INFO:Importing untrained model
2024-12-09 14:13:32,854:INFO:Declaring custom model
2024-12-09 14:13:32,854:INFO:K Neighbors Classifier Imported successfully
2024-12-09 14:13:32,855:INFO:Cross validation set to False
2024-12-09 14:13:32,855:INFO:Fitting Model
2024-12-09 14:13:32,898:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 14:13:32,898:INFO:create_model() successfully completed......................................
2024-12-09 14:13:32,982:INFO:Initializing create_model()
2024-12-09 14:13:32,983:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:32,983:INFO:Checking exceptions
2024-12-09 14:13:32,985:INFO:Importing libraries
2024-12-09 14:13:32,985:INFO:Copying training dataset
2024-12-09 14:13:32,988:INFO:Defining folds
2024-12-09 14:13:32,988:INFO:Declaring metric variables
2024-12-09 14:13:32,989:INFO:Importing untrained model
2024-12-09 14:13:32,989:INFO:Declaring custom model
2024-12-09 14:13:32,989:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 14:13:32,990:INFO:Cross validation set to False
2024-12-09 14:13:32,990:INFO:Fitting Model
2024-12-09 14:13:33,033:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 14:13:33,033:INFO:create_model() successfully completed......................................
2024-12-09 14:13:33,130:INFO:_master_model_container: 13
2024-12-09 14:13:33,131:INFO:_display_container: 2
2024-12-09 14:13:33,134:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-12-09 14:13:33,134:INFO:compare_models() successfully completed......................................
2024-12-09 14:13:33,137:INFO:Initializing finalize_model()
2024-12-09 14:13:33,137:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)], fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-09 14:13:33,139:INFO:Finalizing [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-12-09 14:13:33,145:INFO:Initializing create_model()
2024-12-09 14:13:33,145:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)], fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:33,145:INFO:Checking exceptions
2024-12-09 14:13:33,153:INFO:Initializing compare_models()
2024-12-09 14:13:33,153:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, 'include': None, 'exclude': ['dummy', [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['dummy', [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]])
2024-12-09 14:13:33,153:INFO:Checking exceptions
2024-12-09 14:13:33,155:INFO:Preparing display monitor
2024-12-09 14:13:33,180:INFO:Initializing Logistic Regression
2024-12-09 14:13:33,180:INFO:Total runtime is 0.0 minutes
2024-12-09 14:13:33,184:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:33,185:INFO:Initializing create_model()
2024-12-09 14:13:33,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BECEA0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:33,185:INFO:Checking exceptions
2024-12-09 14:13:33,185:INFO:Importing libraries
2024-12-09 14:13:33,185:INFO:Copying training dataset
2024-12-09 14:13:33,189:INFO:Defining folds
2024-12-09 14:13:33,189:INFO:Declaring metric variables
2024-12-09 14:13:33,193:INFO:Importing untrained model
2024-12-09 14:13:33,196:INFO:Logistic Regression Imported successfully
2024-12-09 14:13:33,204:INFO:Starting cross validation
2024-12-09 14:13:33,205:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:33,501:INFO:Calculating mean and std
2024-12-09 14:13:33,501:INFO:Creating metrics dataframe
2024-12-09 14:13:33,505:INFO:Uploading results into container
2024-12-09 14:13:33,505:INFO:Uploading model into container now
2024-12-09 14:13:33,505:INFO:_master_model_container: 14
2024-12-09 14:13:33,505:INFO:_display_container: 3
2024-12-09 14:13:33,506:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 14:13:33,506:INFO:create_model() successfully completed......................................
2024-12-09 14:13:33,579:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:33,579:INFO:Creating metrics dataframe
2024-12-09 14:13:33,587:INFO:Initializing K Neighbors Classifier
2024-12-09 14:13:33,587:INFO:Total runtime is 0.006797262032826741 minutes
2024-12-09 14:13:33,591:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:33,591:INFO:Initializing create_model()
2024-12-09 14:13:33,591:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BECEA0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:33,591:INFO:Checking exceptions
2024-12-09 14:13:33,592:INFO:Importing libraries
2024-12-09 14:13:33,592:INFO:Copying training dataset
2024-12-09 14:13:33,595:INFO:Defining folds
2024-12-09 14:13:33,595:INFO:Declaring metric variables
2024-12-09 14:13:33,598:INFO:Importing untrained model
2024-12-09 14:13:33,601:INFO:K Neighbors Classifier Imported successfully
2024-12-09 14:13:33,608:INFO:Starting cross validation
2024-12-09 14:13:33,609:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:33,857:INFO:Calculating mean and std
2024-12-09 14:13:33,858:INFO:Creating metrics dataframe
2024-12-09 14:13:33,861:INFO:Uploading results into container
2024-12-09 14:13:33,861:INFO:Uploading model into container now
2024-12-09 14:13:33,861:INFO:_master_model_container: 15
2024-12-09 14:13:33,861:INFO:_display_container: 3
2024-12-09 14:13:33,862:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 14:13:33,862:INFO:create_model() successfully completed......................................
2024-12-09 14:13:33,935:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:33,935:INFO:Creating metrics dataframe
2024-12-09 14:13:33,945:INFO:Initializing Naive Bayes
2024-12-09 14:13:33,945:INFO:Total runtime is 0.012755068143208821 minutes
2024-12-09 14:13:33,952:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:33,952:INFO:Initializing create_model()
2024-12-09 14:13:33,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BECEA0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:33,952:INFO:Checking exceptions
2024-12-09 14:13:33,952:INFO:Importing libraries
2024-12-09 14:13:33,952:INFO:Copying training dataset
2024-12-09 14:13:33,977:INFO:Defining folds
2024-12-09 14:13:33,977:INFO:Declaring metric variables
2024-12-09 14:13:33,986:INFO:Importing untrained model
2024-12-09 14:13:33,990:INFO:Naive Bayes Imported successfully
2024-12-09 14:13:33,997:INFO:Starting cross validation
2024-12-09 14:13:33,998:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:34,227:INFO:Calculating mean and std
2024-12-09 14:13:34,228:INFO:Creating metrics dataframe
2024-12-09 14:13:34,233:INFO:Uploading results into container
2024-12-09 14:13:34,233:INFO:Uploading model into container now
2024-12-09 14:13:34,234:INFO:_master_model_container: 16
2024-12-09 14:13:34,234:INFO:_display_container: 3
2024-12-09 14:13:34,234:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 14:13:34,234:INFO:create_model() successfully completed......................................
2024-12-09 14:13:34,314:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:34,315:INFO:Creating metrics dataframe
2024-12-09 14:13:34,325:INFO:Initializing Decision Tree Classifier
2024-12-09 14:13:34,325:INFO:Total runtime is 0.019087743759155274 minutes
2024-12-09 14:13:34,328:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:34,329:INFO:Initializing create_model()
2024-12-09 14:13:34,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BECEA0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:34,329:INFO:Checking exceptions
2024-12-09 14:13:34,329:INFO:Importing libraries
2024-12-09 14:13:34,329:INFO:Copying training dataset
2024-12-09 14:13:34,335:INFO:Defining folds
2024-12-09 14:13:34,335:INFO:Declaring metric variables
2024-12-09 14:13:34,338:INFO:Importing untrained model
2024-12-09 14:13:34,343:INFO:Decision Tree Classifier Imported successfully
2024-12-09 14:13:34,351:INFO:Starting cross validation
2024-12-09 14:13:34,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:34,608:INFO:Calculating mean and std
2024-12-09 14:13:34,609:INFO:Creating metrics dataframe
2024-12-09 14:13:34,612:INFO:Uploading results into container
2024-12-09 14:13:34,613:INFO:Uploading model into container now
2024-12-09 14:13:34,613:INFO:_master_model_container: 17
2024-12-09 14:13:34,613:INFO:_display_container: 3
2024-12-09 14:13:34,614:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 14:13:34,614:INFO:create_model() successfully completed......................................
2024-12-09 14:13:34,706:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:34,706:INFO:Creating metrics dataframe
2024-12-09 14:13:34,717:INFO:Initializing SVM - Linear Kernel
2024-12-09 14:13:34,717:INFO:Total runtime is 0.02562795082728068 minutes
2024-12-09 14:13:34,721:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:34,722:INFO:Initializing create_model()
2024-12-09 14:13:34,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BECEA0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:34,722:INFO:Checking exceptions
2024-12-09 14:13:34,722:INFO:Importing libraries
2024-12-09 14:13:34,722:INFO:Copying training dataset
2024-12-09 14:13:34,726:INFO:Defining folds
2024-12-09 14:13:34,726:INFO:Declaring metric variables
2024-12-09 14:13:34,731:INFO:Importing untrained model
2024-12-09 14:13:34,737:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 14:13:34,745:INFO:Starting cross validation
2024-12-09 14:13:34,747:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:34,879:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:34,892:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:34,903:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:13:34,907:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:34,910:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:34,912:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:34,913:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:35,047:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:35,061:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:35,068:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:35,083:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:35,087:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:13:35,092:INFO:Calculating mean and std
2024-12-09 14:13:35,093:INFO:Creating metrics dataframe
2024-12-09 14:13:35,096:INFO:Uploading results into container
2024-12-09 14:13:35,097:INFO:Uploading model into container now
2024-12-09 14:13:35,097:INFO:_master_model_container: 18
2024-12-09 14:13:35,098:INFO:_display_container: 3
2024-12-09 14:13:35,099:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 14:13:35,099:INFO:create_model() successfully completed......................................
2024-12-09 14:13:35,197:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:35,197:INFO:Creating metrics dataframe
2024-12-09 14:13:35,211:INFO:Initializing Ridge Classifier
2024-12-09 14:13:35,211:INFO:Total runtime is 0.033859570821126304 minutes
2024-12-09 14:13:35,217:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:35,218:INFO:Initializing create_model()
2024-12-09 14:13:35,218:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BECEA0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:35,219:INFO:Checking exceptions
2024-12-09 14:13:35,219:INFO:Importing libraries
2024-12-09 14:13:35,219:INFO:Copying training dataset
2024-12-09 14:13:35,224:INFO:Defining folds
2024-12-09 14:13:35,224:INFO:Declaring metric variables
2024-12-09 14:13:35,228:INFO:Importing untrained model
2024-12-09 14:13:35,235:INFO:Ridge Classifier Imported successfully
2024-12-09 14:13:35,242:INFO:Starting cross validation
2024-12-09 14:13:35,244:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:35,369:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:35,406:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:35,411:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:35,446:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:35,458:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:35,495:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:35,514:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:35,536:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:35,548:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:35,560:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:35,569:INFO:Calculating mean and std
2024-12-09 14:13:35,570:INFO:Creating metrics dataframe
2024-12-09 14:13:35,573:INFO:Uploading results into container
2024-12-09 14:13:35,574:INFO:Uploading model into container now
2024-12-09 14:13:35,574:INFO:_master_model_container: 19
2024-12-09 14:13:35,574:INFO:_display_container: 3
2024-12-09 14:13:35,575:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 14:13:35,575:INFO:create_model() successfully completed......................................
2024-12-09 14:13:35,657:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:35,658:INFO:Creating metrics dataframe
2024-12-09 14:13:35,671:INFO:Initializing Random Forest Classifier
2024-12-09 14:13:35,671:INFO:Total runtime is 0.04151831467946371 minutes
2024-12-09 14:13:35,676:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:35,676:INFO:Initializing create_model()
2024-12-09 14:13:35,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BECEA0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:35,677:INFO:Checking exceptions
2024-12-09 14:13:35,677:INFO:Importing libraries
2024-12-09 14:13:35,677:INFO:Copying training dataset
2024-12-09 14:13:35,684:INFO:Defining folds
2024-12-09 14:13:35,685:INFO:Declaring metric variables
2024-12-09 14:13:35,691:INFO:Importing untrained model
2024-12-09 14:13:35,694:INFO:Random Forest Classifier Imported successfully
2024-12-09 14:13:35,705:INFO:Starting cross validation
2024-12-09 14:13:35,707:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:36,584:INFO:Calculating mean and std
2024-12-09 14:13:36,585:INFO:Creating metrics dataframe
2024-12-09 14:13:36,589:INFO:Uploading results into container
2024-12-09 14:13:36,589:INFO:Uploading model into container now
2024-12-09 14:13:36,590:INFO:_master_model_container: 20
2024-12-09 14:13:36,590:INFO:_display_container: 3
2024-12-09 14:13:36,590:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 14:13:36,590:INFO:create_model() successfully completed......................................
2024-12-09 14:13:36,669:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:36,669:INFO:Creating metrics dataframe
2024-12-09 14:13:36,681:INFO:Initializing Quadratic Discriminant Analysis
2024-12-09 14:13:36,681:INFO:Total runtime is 0.058348647753397626 minutes
2024-12-09 14:13:36,685:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:36,685:INFO:Initializing create_model()
2024-12-09 14:13:36,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BECEA0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:36,686:INFO:Checking exceptions
2024-12-09 14:13:36,686:INFO:Importing libraries
2024-12-09 14:13:36,686:INFO:Copying training dataset
2024-12-09 14:13:36,692:INFO:Defining folds
2024-12-09 14:13:36,692:INFO:Declaring metric variables
2024-12-09 14:13:36,695:INFO:Importing untrained model
2024-12-09 14:13:36,699:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 14:13:36,709:INFO:Starting cross validation
2024-12-09 14:13:36,711:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:36,791:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:36,792:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:36,795:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:36,796:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:36,797:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:36,837:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:36,909:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:36,910:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:36,911:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:36,913:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:36,957:INFO:Calculating mean and std
2024-12-09 14:13:36,958:INFO:Creating metrics dataframe
2024-12-09 14:13:36,961:INFO:Uploading results into container
2024-12-09 14:13:36,962:INFO:Uploading model into container now
2024-12-09 14:13:36,962:INFO:_master_model_container: 21
2024-12-09 14:13:36,962:INFO:_display_container: 3
2024-12-09 14:13:36,963:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 14:13:36,963:INFO:create_model() successfully completed......................................
2024-12-09 14:13:37,051:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:37,051:INFO:Creating metrics dataframe
2024-12-09 14:13:37,063:INFO:Initializing Ada Boost Classifier
2024-12-09 14:13:37,063:INFO:Total runtime is 0.06472351153691609 minutes
2024-12-09 14:13:37,067:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:37,068:INFO:Initializing create_model()
2024-12-09 14:13:37,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BECEA0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:37,068:INFO:Checking exceptions
2024-12-09 14:13:37,068:INFO:Importing libraries
2024-12-09 14:13:37,068:INFO:Copying training dataset
2024-12-09 14:13:37,073:INFO:Defining folds
2024-12-09 14:13:37,074:INFO:Declaring metric variables
2024-12-09 14:13:37,078:INFO:Importing untrained model
2024-12-09 14:13:37,081:INFO:Ada Boost Classifier Imported successfully
2024-12-09 14:13:37,089:INFO:Starting cross validation
2024-12-09 14:13:37,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:37,724:INFO:Calculating mean and std
2024-12-09 14:13:37,725:INFO:Creating metrics dataframe
2024-12-09 14:13:37,729:INFO:Uploading results into container
2024-12-09 14:13:37,730:INFO:Uploading model into container now
2024-12-09 14:13:37,730:INFO:_master_model_container: 22
2024-12-09 14:13:37,730:INFO:_display_container: 3
2024-12-09 14:13:37,731:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 14:13:37,731:INFO:create_model() successfully completed......................................
2024-12-09 14:13:37,811:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:37,811:INFO:Creating metrics dataframe
2024-12-09 14:13:37,824:INFO:Initializing Gradient Boosting Classifier
2024-12-09 14:13:37,824:INFO:Total runtime is 0.07740999857584635 minutes
2024-12-09 14:13:37,827:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:37,828:INFO:Initializing create_model()
2024-12-09 14:13:37,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BECEA0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:37,828:INFO:Checking exceptions
2024-12-09 14:13:37,828:INFO:Importing libraries
2024-12-09 14:13:37,828:INFO:Copying training dataset
2024-12-09 14:13:37,832:INFO:Defining folds
2024-12-09 14:13:37,832:INFO:Declaring metric variables
2024-12-09 14:13:37,836:INFO:Importing untrained model
2024-12-09 14:13:37,841:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 14:13:37,848:INFO:Starting cross validation
2024-12-09 14:13:37,849:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:38,316:INFO:Calculating mean and std
2024-12-09 14:13:38,317:INFO:Creating metrics dataframe
2024-12-09 14:13:38,321:INFO:Uploading results into container
2024-12-09 14:13:38,322:INFO:Uploading model into container now
2024-12-09 14:13:38,323:INFO:_master_model_container: 23
2024-12-09 14:13:38,323:INFO:_display_container: 3
2024-12-09 14:13:38,323:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 14:13:38,324:INFO:create_model() successfully completed......................................
2024-12-09 14:13:38,433:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:38,433:INFO:Creating metrics dataframe
2024-12-09 14:13:38,446:INFO:Initializing Linear Discriminant Analysis
2024-12-09 14:13:38,447:INFO:Total runtime is 0.08779376745223999 minutes
2024-12-09 14:13:38,451:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:38,452:INFO:Initializing create_model()
2024-12-09 14:13:38,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BECEA0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:38,452:INFO:Checking exceptions
2024-12-09 14:13:38,452:INFO:Importing libraries
2024-12-09 14:13:38,452:INFO:Copying training dataset
2024-12-09 14:13:38,457:INFO:Defining folds
2024-12-09 14:13:38,457:INFO:Declaring metric variables
2024-12-09 14:13:38,461:INFO:Importing untrained model
2024-12-09 14:13:38,465:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 14:13:38,474:INFO:Starting cross validation
2024-12-09 14:13:38,476:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:38,768:INFO:Calculating mean and std
2024-12-09 14:13:38,769:INFO:Creating metrics dataframe
2024-12-09 14:13:38,773:INFO:Uploading results into container
2024-12-09 14:13:38,774:INFO:Uploading model into container now
2024-12-09 14:13:38,774:INFO:_master_model_container: 24
2024-12-09 14:13:38,775:INFO:_display_container: 3
2024-12-09 14:13:38,775:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 14:13:38,776:INFO:create_model() successfully completed......................................
2024-12-09 14:13:38,864:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:38,864:INFO:Creating metrics dataframe
2024-12-09 14:13:38,877:INFO:Initializing Extra Trees Classifier
2024-12-09 14:13:38,877:INFO:Total runtime is 0.0949537714322408 minutes
2024-12-09 14:13:38,880:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:38,880:INFO:Initializing create_model()
2024-12-09 14:13:38,881:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BECEA0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:38,881:INFO:Checking exceptions
2024-12-09 14:13:38,881:INFO:Importing libraries
2024-12-09 14:13:38,881:INFO:Copying training dataset
2024-12-09 14:13:38,886:INFO:Defining folds
2024-12-09 14:13:38,886:INFO:Declaring metric variables
2024-12-09 14:13:38,889:INFO:Importing untrained model
2024-12-09 14:13:38,893:INFO:Extra Trees Classifier Imported successfully
2024-12-09 14:13:38,901:INFO:Starting cross validation
2024-12-09 14:13:38,903:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:39,688:INFO:Calculating mean and std
2024-12-09 14:13:39,689:INFO:Creating metrics dataframe
2024-12-09 14:13:39,693:INFO:Uploading results into container
2024-12-09 14:13:39,694:INFO:Uploading model into container now
2024-12-09 14:13:39,694:INFO:_master_model_container: 25
2024-12-09 14:13:39,694:INFO:_display_container: 3
2024-12-09 14:13:39,695:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 14:13:39,695:INFO:create_model() successfully completed......................................
2024-12-09 14:13:39,776:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:39,776:INFO:Creating metrics dataframe
2024-12-09 14:13:39,789:INFO:Initializing Light Gradient Boosting Machine
2024-12-09 14:13:39,789:INFO:Total runtime is 0.11015409628550211 minutes
2024-12-09 14:13:39,793:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:39,793:INFO:Initializing create_model()
2024-12-09 14:13:39,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BECEA0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:39,794:INFO:Checking exceptions
2024-12-09 14:13:39,794:INFO:Importing libraries
2024-12-09 14:13:39,794:INFO:Copying training dataset
2024-12-09 14:13:39,798:INFO:Defining folds
2024-12-09 14:13:39,798:INFO:Declaring metric variables
2024-12-09 14:13:39,803:INFO:Importing untrained model
2024-12-09 14:13:39,807:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:13:39,814:INFO:Starting cross validation
2024-12-09 14:13:39,816:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:41,030:INFO:Calculating mean and std
2024-12-09 14:13:41,036:INFO:Creating metrics dataframe
2024-12-09 14:13:41,040:INFO:Uploading results into container
2024-12-09 14:13:41,041:INFO:Uploading model into container now
2024-12-09 14:13:41,042:INFO:_master_model_container: 26
2024-12-09 14:13:41,042:INFO:_display_container: 3
2024-12-09 14:13:41,042:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:13:41,042:INFO:create_model() successfully completed......................................
2024-12-09 14:13:41,125:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:41,125:INFO:Creating metrics dataframe
2024-12-09 14:13:41,157:INFO:Initializing create_model()
2024-12-09 14:13:41,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:41,157:INFO:Checking exceptions
2024-12-09 14:13:41,161:INFO:Importing libraries
2024-12-09 14:13:41,161:INFO:Copying training dataset
2024-12-09 14:13:41,166:INFO:Defining folds
2024-12-09 14:13:41,166:INFO:Declaring metric variables
2024-12-09 14:13:41,167:INFO:Importing untrained model
2024-12-09 14:13:41,167:INFO:Declaring custom model
2024-12-09 14:13:41,167:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:13:41,168:INFO:Cross validation set to False
2024-12-09 14:13:41,169:INFO:Fitting Model
2024-12-09 14:13:41,242:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 14:13:41,242:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.
2024-12-09 14:13:41,242:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 14:13:41,242:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 14:13:41,242:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 14:13:41,242:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 14:13:41,243:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 14:13:41,243:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 14:13:41,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,313:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:13:41,313:INFO:create_model() successfully completed......................................
2024-12-09 14:13:41,446:INFO:_master_model_container: 26
2024-12-09 14:13:41,446:INFO:_display_container: 3
2024-12-09 14:13:41,447:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:13:41,447:INFO:compare_models() successfully completed......................................
2024-12-09 14:13:41,448:INFO:Initializing finalize_model()
2024-12-09 14:13:41,448:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-09 14:13:41,448:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:13:41,451:INFO:Initializing create_model()
2024-12-09 14:13:41,451:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:41,451:INFO:Checking exceptions
2024-12-09 14:13:41,453:INFO:Importing libraries
2024-12-09 14:13:41,453:INFO:Copying training dataset
2024-12-09 14:13:41,453:INFO:Defining folds
2024-12-09 14:13:41,453:INFO:Declaring metric variables
2024-12-09 14:13:41,453:INFO:Importing untrained model
2024-12-09 14:13:41,453:INFO:Declaring custom model
2024-12-09 14:13:41,455:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:13:41,456:INFO:Cross validation set to False
2024-12-09 14:13:41,456:INFO:Fitting Model
2024-12-09 14:13:41,503:INFO:[LightGBM] [Info] Number of positive: 342, number of negative: 549
2024-12-09 14:13:41,504:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000748 seconds.
2024-12-09 14:13:41,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 14:13:41,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 14:13:41,505:INFO:[LightGBM] [Info] Total Bins 224
2024-12-09 14:13:41,505:INFO:[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 9
2024-12-09 14:13:41,505:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288
2024-12-09 14:13:41,505:INFO:[LightGBM] [Info] Start training from score -0.473288
2024-12-09 14:13:41,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:41,585:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-09 14:13:41,585:INFO:create_model() successfully completed......................................
2024-12-09 14:13:41,669:INFO:_master_model_container: 26
2024-12-09 14:13:41,669:INFO:_display_container: 3
2024-12-09 14:13:41,689:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-12-09 14:13:41,689:INFO:finalize_model() successfully completed......................................
2024-12-09 14:13:41,796:INFO:Initializing predict_model()
2024-12-09 14:13:41,796:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6BFF650D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E6C0101D30>)
2024-12-09 14:13:41,797:INFO:Checking exceptions
2024-12-09 14:13:41,797:INFO:Preloading libraries
2024-12-09 14:13:41,799:INFO:Set up data.
2024-12-09 14:13:41,803:INFO:Set up index.
2024-12-09 14:13:41,986:INFO:PyCaret ClassificationExperiment
2024-12-09 14:13:41,986:INFO:Logging name: clf-default-name
2024-12-09 14:13:41,987:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-09 14:13:41,987:INFO:version 3.2.0
2024-12-09 14:13:41,987:INFO:Initializing setup()
2024-12-09 14:13:41,987:INFO:self.USI: 9a0a
2024-12-09 14:13:41,987:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'pipeline', 'X_test', 'html_param', '_ml_usecase', 'seed', 'gpu_param', '_available_plots', 'X', 'X_train', 'fold_shuffle_param', 'y_test', 'log_plots_param', 'y', 'gpu_n_jobs_param', 'target_param', 'USI', 'fix_imbalance', 'n_jobs_param', 'idx', 'logging_param', 'exp_id', 'memory', 'data', 'fold_generator', 'y_train', 'exp_name_log'}
2024-12-09 14:13:41,987:INFO:Checking environment
2024-12-09 14:13:41,987:INFO:python_version: 3.8.20
2024-12-09 14:13:41,987:INFO:python_build: ('default', 'Oct  3 2024 15:19:54')
2024-12-09 14:13:41,987:INFO:machine: AMD64
2024-12-09 14:13:41,987:INFO:platform: Windows-10-10.0.19041-SP0
2024-12-09 14:13:41,990:INFO:Memory: svmem(total=17054896128, available=6192295936, percent=63.7, used=10862600192, free=6192295936)
2024-12-09 14:13:41,990:INFO:Physical Core: 6
2024-12-09 14:13:41,990:INFO:Logical Core: 6
2024-12-09 14:13:41,990:INFO:Checking libraries
2024-12-09 14:13:41,990:INFO:System:
2024-12-09 14:13:41,990:INFO:    python: 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]
2024-12-09 14:13:41,990:INFO:executable: c:\Users\EE715\anaconda3\envs\gym-env\python.exe
2024-12-09 14:13:41,990:INFO:   machine: Windows-10-10.0.19041-SP0
2024-12-09 14:13:41,990:INFO:PyCaret required dependencies:
2024-12-09 14:13:41,990:INFO:                 pip: 24.2
2024-12-09 14:13:41,990:INFO:          setuptools: 75.1.0
2024-12-09 14:13:41,990:INFO:             pycaret: 3.2.0
2024-12-09 14:13:41,990:INFO:             IPython: 8.12.3
2024-12-09 14:13:41,990:INFO:          ipywidgets: 8.1.5
2024-12-09 14:13:41,990:INFO:                tqdm: 4.67.1
2024-12-09 14:13:41,990:INFO:               numpy: 1.24.4
2024-12-09 14:13:41,991:INFO:              pandas: 1.5.3
2024-12-09 14:13:41,991:INFO:              jinja2: 3.1.4
2024-12-09 14:13:41,991:INFO:               scipy: 1.10.1
2024-12-09 14:13:41,991:INFO:              joblib: 1.2.0
2024-12-09 14:13:41,991:INFO:             sklearn: 1.2.2
2024-12-09 14:13:41,991:INFO:                pyod: 2.0.2
2024-12-09 14:13:41,991:INFO:            imblearn: 0.12.4
2024-12-09 14:13:41,991:INFO:   category_encoders: 2.6.4
2024-12-09 14:13:41,991:INFO:            lightgbm: 4.5.0
2024-12-09 14:13:41,991:INFO:               numba: 0.58.1
2024-12-09 14:13:41,991:INFO:            requests: 2.32.3
2024-12-09 14:13:41,991:INFO:          matplotlib: 3.6.0
2024-12-09 14:13:41,991:INFO:          scikitplot: 0.3.7
2024-12-09 14:13:41,991:INFO:         yellowbrick: 1.5
2024-12-09 14:13:41,991:INFO:              plotly: 5.24.1
2024-12-09 14:13:41,991:INFO:    plotly-resampler: Not installed
2024-12-09 14:13:41,991:INFO:             kaleido: 0.2.1
2024-12-09 14:13:41,991:INFO:           schemdraw: 0.15
2024-12-09 14:13:41,991:INFO:         statsmodels: 0.14.1
2024-12-09 14:13:41,991:INFO:              sktime: 0.21.1
2024-12-09 14:13:41,991:INFO:               tbats: 1.1.3
2024-12-09 14:13:41,991:INFO:            pmdarima: 2.0.4
2024-12-09 14:13:41,992:INFO:              psutil: 6.1.0
2024-12-09 14:13:41,992:INFO:          markupsafe: 2.1.5
2024-12-09 14:13:41,992:INFO:             pickle5: Not installed
2024-12-09 14:13:41,992:INFO:         cloudpickle: 3.1.0
2024-12-09 14:13:41,992:INFO:         deprecation: 2.1.0
2024-12-09 14:13:41,992:INFO:              xxhash: 3.5.0
2024-12-09 14:13:41,992:INFO:           wurlitzer: Not installed
2024-12-09 14:13:41,992:INFO:PyCaret optional dependencies:
2024-12-09 14:13:41,992:INFO:                shap: Not installed
2024-12-09 14:13:41,992:INFO:           interpret: Not installed
2024-12-09 14:13:41,992:INFO:                umap: Not installed
2024-12-09 14:13:41,992:INFO:     ydata_profiling: Not installed
2024-12-09 14:13:41,992:INFO:  explainerdashboard: Not installed
2024-12-09 14:13:41,992:INFO:             autoviz: Not installed
2024-12-09 14:13:41,992:INFO:           fairlearn: Not installed
2024-12-09 14:13:41,992:INFO:          deepchecks: Not installed
2024-12-09 14:13:41,992:INFO:             xgboost: Not installed
2024-12-09 14:13:41,992:INFO:            catboost: Not installed
2024-12-09 14:13:41,993:INFO:              kmodes: Not installed
2024-12-09 14:13:41,993:INFO:             mlxtend: Not installed
2024-12-09 14:13:41,993:INFO:       statsforecast: Not installed
2024-12-09 14:13:41,993:INFO:        tune_sklearn: Not installed
2024-12-09 14:13:41,993:INFO:                 ray: Not installed
2024-12-09 14:13:41,993:INFO:            hyperopt: Not installed
2024-12-09 14:13:41,993:INFO:              optuna: 4.1.0
2024-12-09 14:13:41,993:INFO:               skopt: Not installed
2024-12-09 14:13:41,993:INFO:              mlflow: Not installed
2024-12-09 14:13:41,993:INFO:              gradio: Not installed
2024-12-09 14:13:41,993:INFO:             fastapi: Not installed
2024-12-09 14:13:41,993:INFO:             uvicorn: Not installed
2024-12-09 14:13:41,993:INFO:              m2cgen: Not installed
2024-12-09 14:13:41,993:INFO:           evidently: Not installed
2024-12-09 14:13:41,993:INFO:               fugue: Not installed
2024-12-09 14:13:41,993:INFO:           streamlit: Not installed
2024-12-09 14:13:41,993:INFO:             prophet: Not installed
2024-12-09 14:13:41,993:INFO:None
2024-12-09 14:13:41,993:INFO:Set up data.
2024-12-09 14:13:41,999:INFO:Set up folding strategy.
2024-12-09 14:13:41,999:INFO:Set up train/test split.
2024-12-09 14:13:42,003:INFO:Set up index.
2024-12-09 14:13:42,003:INFO:Assigning column types.
2024-12-09 14:13:42,006:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-09 14:13:42,046:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 14:13:42,047:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:13:42,071:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:42,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:42,112:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-09 14:13:42,113:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:13:42,138:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:42,138:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:42,139:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-09 14:13:42,178:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:13:42,203:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:42,203:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:42,243:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-09 14:13:42,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:42,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:42,268:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-09 14:13:42,334:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:42,334:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:42,399:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:42,400:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:42,401:INFO:Preparing preprocessing pipeline...
2024-12-09 14:13:42,402:INFO:Set up simple imputation.
2024-12-09 14:13:42,404:INFO:Set up encoding of ordinal features.
2024-12-09 14:13:42,406:INFO:Set up encoding of categorical features.
2024-12-09 14:13:42,474:INFO:Finished creating preprocessing pipeline.
2024-12-09 14:13:42,492:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\EE715\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categ...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-12-09 14:13:42,492:INFO:Creating final display dataframe.
2024-12-09 14:13:42,688:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (623, 10)
6    Transformed test set shape         (268, 10)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              9a0a
2024-12-09 14:13:42,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:42,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:42,838:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:42,839:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-12-09 14:13:42,840:INFO:setup() successfully completed in 0.85s...............
2024-12-09 14:13:42,841:INFO:Initializing compare_models()
2024-12-09 14:13:42,841:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-12-09 14:13:42,841:INFO:Checking exceptions
2024-12-09 14:13:42,844:INFO:Preparing display monitor
2024-12-09 14:13:42,885:INFO:Initializing Logistic Regression
2024-12-09 14:13:42,885:INFO:Total runtime is 0.0 minutes
2024-12-09 14:13:42,890:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:42,891:INFO:Initializing create_model()
2024-12-09 14:13:42,891:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C1371430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:42,891:INFO:Checking exceptions
2024-12-09 14:13:42,891:INFO:Importing libraries
2024-12-09 14:13:42,891:INFO:Copying training dataset
2024-12-09 14:13:42,910:INFO:Defining folds
2024-12-09 14:13:42,910:INFO:Declaring metric variables
2024-12-09 14:13:42,917:INFO:Importing untrained model
2024-12-09 14:13:42,925:INFO:Logistic Regression Imported successfully
2024-12-09 14:13:42,934:INFO:Starting cross validation
2024-12-09 14:13:42,935:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:43,331:INFO:Calculating mean and std
2024-12-09 14:13:43,332:INFO:Creating metrics dataframe
2024-12-09 14:13:43,336:INFO:Uploading results into container
2024-12-09 14:13:43,336:INFO:Uploading model into container now
2024-12-09 14:13:43,337:INFO:_master_model_container: 1
2024-12-09 14:13:43,337:INFO:_display_container: 2
2024-12-09 14:13:43,337:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-09 14:13:43,337:INFO:create_model() successfully completed......................................
2024-12-09 14:13:43,419:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:43,419:INFO:Creating metrics dataframe
2024-12-09 14:13:43,429:INFO:Initializing K Neighbors Classifier
2024-12-09 14:13:43,429:INFO:Total runtime is 0.009069577852884928 minutes
2024-12-09 14:13:43,432:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:43,433:INFO:Initializing create_model()
2024-12-09 14:13:43,433:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C1371430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:43,433:INFO:Checking exceptions
2024-12-09 14:13:43,433:INFO:Importing libraries
2024-12-09 14:13:43,433:INFO:Copying training dataset
2024-12-09 14:13:43,437:INFO:Defining folds
2024-12-09 14:13:43,437:INFO:Declaring metric variables
2024-12-09 14:13:43,442:INFO:Importing untrained model
2024-12-09 14:13:43,447:INFO:K Neighbors Classifier Imported successfully
2024-12-09 14:13:43,458:INFO:Starting cross validation
2024-12-09 14:13:43,460:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:43,769:INFO:Calculating mean and std
2024-12-09 14:13:43,770:INFO:Creating metrics dataframe
2024-12-09 14:13:43,774:INFO:Uploading results into container
2024-12-09 14:13:43,775:INFO:Uploading model into container now
2024-12-09 14:13:43,776:INFO:_master_model_container: 2
2024-12-09 14:13:43,776:INFO:_display_container: 2
2024-12-09 14:13:43,776:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-09 14:13:43,776:INFO:create_model() successfully completed......................................
2024-12-09 14:13:43,862:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:43,862:INFO:Creating metrics dataframe
2024-12-09 14:13:43,872:INFO:Initializing Naive Bayes
2024-12-09 14:13:43,872:INFO:Total runtime is 0.01644831895828247 minutes
2024-12-09 14:13:43,877:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:43,877:INFO:Initializing create_model()
2024-12-09 14:13:43,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C1371430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:43,878:INFO:Checking exceptions
2024-12-09 14:13:43,878:INFO:Importing libraries
2024-12-09 14:13:43,878:INFO:Copying training dataset
2024-12-09 14:13:43,882:INFO:Defining folds
2024-12-09 14:13:43,882:INFO:Declaring metric variables
2024-12-09 14:13:43,885:INFO:Importing untrained model
2024-12-09 14:13:43,889:INFO:Naive Bayes Imported successfully
2024-12-09 14:13:43,898:INFO:Starting cross validation
2024-12-09 14:13:43,899:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:44,175:INFO:Calculating mean and std
2024-12-09 14:13:44,176:INFO:Creating metrics dataframe
2024-12-09 14:13:44,179:INFO:Uploading results into container
2024-12-09 14:13:44,180:INFO:Uploading model into container now
2024-12-09 14:13:44,180:INFO:_master_model_container: 3
2024-12-09 14:13:44,180:INFO:_display_container: 2
2024-12-09 14:13:44,180:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-09 14:13:44,180:INFO:create_model() successfully completed......................................
2024-12-09 14:13:44,280:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:44,280:INFO:Creating metrics dataframe
2024-12-09 14:13:44,293:INFO:Initializing Decision Tree Classifier
2024-12-09 14:13:44,293:INFO:Total runtime is 0.023472940921783446 minutes
2024-12-09 14:13:44,301:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:44,301:INFO:Initializing create_model()
2024-12-09 14:13:44,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C1371430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:44,302:INFO:Checking exceptions
2024-12-09 14:13:44,302:INFO:Importing libraries
2024-12-09 14:13:44,302:INFO:Copying training dataset
2024-12-09 14:13:44,307:INFO:Defining folds
2024-12-09 14:13:44,307:INFO:Declaring metric variables
2024-12-09 14:13:44,312:INFO:Importing untrained model
2024-12-09 14:13:44,318:INFO:Decision Tree Classifier Imported successfully
2024-12-09 14:13:44,327:INFO:Starting cross validation
2024-12-09 14:13:44,328:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:44,564:INFO:Calculating mean and std
2024-12-09 14:13:44,565:INFO:Creating metrics dataframe
2024-12-09 14:13:44,568:INFO:Uploading results into container
2024-12-09 14:13:44,569:INFO:Uploading model into container now
2024-12-09 14:13:44,569:INFO:_master_model_container: 4
2024-12-09 14:13:44,569:INFO:_display_container: 2
2024-12-09 14:13:44,570:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-12-09 14:13:44,570:INFO:create_model() successfully completed......................................
2024-12-09 14:13:44,647:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:44,647:INFO:Creating metrics dataframe
2024-12-09 14:13:44,656:INFO:Initializing SVM - Linear Kernel
2024-12-09 14:13:44,656:INFO:Total runtime is 0.02951499621073405 minutes
2024-12-09 14:13:44,660:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:44,661:INFO:Initializing create_model()
2024-12-09 14:13:44,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C1371430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:44,661:INFO:Checking exceptions
2024-12-09 14:13:44,661:INFO:Importing libraries
2024-12-09 14:13:44,661:INFO:Copying training dataset
2024-12-09 14:13:44,665:INFO:Defining folds
2024-12-09 14:13:44,665:INFO:Declaring metric variables
2024-12-09 14:13:44,669:INFO:Importing untrained model
2024-12-09 14:13:44,675:INFO:SVM - Linear Kernel Imported successfully
2024-12-09 14:13:44,684:INFO:Starting cross validation
2024-12-09 14:13:44,685:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:44,807:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:44,811:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:44,813:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:44,818:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:13:44,819:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:44,834:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:44,884:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:44,920:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:44,924:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:44,926:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:44,926:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:13:44,938:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-12-09 14:13:44,948:INFO:Calculating mean and std
2024-12-09 14:13:44,949:INFO:Creating metrics dataframe
2024-12-09 14:13:44,952:INFO:Uploading results into container
2024-12-09 14:13:44,953:INFO:Uploading model into container now
2024-12-09 14:13:44,954:INFO:_master_model_container: 5
2024-12-09 14:13:44,954:INFO:_display_container: 2
2024-12-09 14:13:44,955:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-09 14:13:44,955:INFO:create_model() successfully completed......................................
2024-12-09 14:13:45,063:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:45,063:INFO:Creating metrics dataframe
2024-12-09 14:13:45,073:INFO:Initializing Ridge Classifier
2024-12-09 14:13:45,073:INFO:Total runtime is 0.036462310949961343 minutes
2024-12-09 14:13:45,077:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:45,077:INFO:Initializing create_model()
2024-12-09 14:13:45,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C1371430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:45,077:INFO:Checking exceptions
2024-12-09 14:13:45,077:INFO:Importing libraries
2024-12-09 14:13:45,078:INFO:Copying training dataset
2024-12-09 14:13:45,082:INFO:Defining folds
2024-12-09 14:13:45,082:INFO:Declaring metric variables
2024-12-09 14:13:45,085:INFO:Importing untrained model
2024-12-09 14:13:45,089:INFO:Ridge Classifier Imported successfully
2024-12-09 14:13:45,098:INFO:Starting cross validation
2024-12-09 14:13:45,099:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:45,213:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:45,219:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:45,221:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:45,224:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:45,236:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:45,263:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:45,340:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:45,341:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:45,348:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:45,352:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-12-09 14:13:45,364:INFO:Calculating mean and std
2024-12-09 14:13:45,365:INFO:Creating metrics dataframe
2024-12-09 14:13:45,369:INFO:Uploading results into container
2024-12-09 14:13:45,369:INFO:Uploading model into container now
2024-12-09 14:13:45,370:INFO:_master_model_container: 6
2024-12-09 14:13:45,370:INFO:_display_container: 2
2024-12-09 14:13:45,370:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-12-09 14:13:45,370:INFO:create_model() successfully completed......................................
2024-12-09 14:13:45,486:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:45,486:INFO:Creating metrics dataframe
2024-12-09 14:13:45,499:INFO:Initializing Random Forest Classifier
2024-12-09 14:13:45,499:INFO:Total runtime is 0.0435661236445109 minutes
2024-12-09 14:13:45,503:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:45,503:INFO:Initializing create_model()
2024-12-09 14:13:45,503:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C1371430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:45,503:INFO:Checking exceptions
2024-12-09 14:13:45,503:INFO:Importing libraries
2024-12-09 14:13:45,503:INFO:Copying training dataset
2024-12-09 14:13:45,508:INFO:Defining folds
2024-12-09 14:13:45,509:INFO:Declaring metric variables
2024-12-09 14:13:45,515:INFO:Importing untrained model
2024-12-09 14:13:45,519:INFO:Random Forest Classifier Imported successfully
2024-12-09 14:13:45,528:INFO:Starting cross validation
2024-12-09 14:13:45,529:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:46,257:INFO:Calculating mean and std
2024-12-09 14:13:46,258:INFO:Creating metrics dataframe
2024-12-09 14:13:46,262:INFO:Uploading results into container
2024-12-09 14:13:46,262:INFO:Uploading model into container now
2024-12-09 14:13:46,263:INFO:_master_model_container: 7
2024-12-09 14:13:46,263:INFO:_display_container: 2
2024-12-09 14:13:46,264:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-12-09 14:13:46,264:INFO:create_model() successfully completed......................................
2024-12-09 14:13:46,341:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:46,342:INFO:Creating metrics dataframe
2024-12-09 14:13:46,353:INFO:Initializing Quadratic Discriminant Analysis
2024-12-09 14:13:46,353:INFO:Total runtime is 0.05779369672139485 minutes
2024-12-09 14:13:46,357:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:46,357:INFO:Initializing create_model()
2024-12-09 14:13:46,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C1371430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:46,357:INFO:Checking exceptions
2024-12-09 14:13:46,357:INFO:Importing libraries
2024-12-09 14:13:46,357:INFO:Copying training dataset
2024-12-09 14:13:46,362:INFO:Defining folds
2024-12-09 14:13:46,362:INFO:Declaring metric variables
2024-12-09 14:13:46,366:INFO:Importing untrained model
2024-12-09 14:13:46,371:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-09 14:13:46,381:INFO:Starting cross validation
2024-12-09 14:13:46,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:46,459:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:46,463:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:46,463:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:46,464:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:46,472:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:46,488:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:46,566:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:46,569:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:46,584:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:46,596:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-09 14:13:46,636:INFO:Calculating mean and std
2024-12-09 14:13:46,637:INFO:Creating metrics dataframe
2024-12-09 14:13:46,640:INFO:Uploading results into container
2024-12-09 14:13:46,641:INFO:Uploading model into container now
2024-12-09 14:13:46,641:INFO:_master_model_container: 8
2024-12-09 14:13:46,642:INFO:_display_container: 2
2024-12-09 14:13:46,642:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-09 14:13:46,642:INFO:create_model() successfully completed......................................
2024-12-09 14:13:46,724:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:46,724:INFO:Creating metrics dataframe
2024-12-09 14:13:46,735:INFO:Initializing Ada Boost Classifier
2024-12-09 14:13:46,735:INFO:Total runtime is 0.06417202949523926 minutes
2024-12-09 14:13:46,738:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:46,739:INFO:Initializing create_model()
2024-12-09 14:13:46,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C1371430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:46,739:INFO:Checking exceptions
2024-12-09 14:13:46,739:INFO:Importing libraries
2024-12-09 14:13:46,739:INFO:Copying training dataset
2024-12-09 14:13:46,744:INFO:Defining folds
2024-12-09 14:13:46,744:INFO:Declaring metric variables
2024-12-09 14:13:46,748:INFO:Importing untrained model
2024-12-09 14:13:46,753:INFO:Ada Boost Classifier Imported successfully
2024-12-09 14:13:46,761:INFO:Starting cross validation
2024-12-09 14:13:46,762:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:47,196:INFO:Calculating mean and std
2024-12-09 14:13:47,198:INFO:Creating metrics dataframe
2024-12-09 14:13:47,202:INFO:Uploading results into container
2024-12-09 14:13:47,202:INFO:Uploading model into container now
2024-12-09 14:13:47,202:INFO:_master_model_container: 9
2024-12-09 14:13:47,203:INFO:_display_container: 2
2024-12-09 14:13:47,203:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-12-09 14:13:47,203:INFO:create_model() successfully completed......................................
2024-12-09 14:13:47,283:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:47,283:INFO:Creating metrics dataframe
2024-12-09 14:13:47,295:INFO:Initializing Gradient Boosting Classifier
2024-12-09 14:13:47,295:INFO:Total runtime is 0.07350228627522787 minutes
2024-12-09 14:13:47,298:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:47,298:INFO:Initializing create_model()
2024-12-09 14:13:47,298:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C1371430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:47,298:INFO:Checking exceptions
2024-12-09 14:13:47,298:INFO:Importing libraries
2024-12-09 14:13:47,299:INFO:Copying training dataset
2024-12-09 14:13:47,303:INFO:Defining folds
2024-12-09 14:13:47,303:INFO:Declaring metric variables
2024-12-09 14:13:47,307:INFO:Importing untrained model
2024-12-09 14:13:47,311:INFO:Gradient Boosting Classifier Imported successfully
2024-12-09 14:13:47,319:INFO:Starting cross validation
2024-12-09 14:13:47,321:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:47,837:INFO:Calculating mean and std
2024-12-09 14:13:47,838:INFO:Creating metrics dataframe
2024-12-09 14:13:47,841:INFO:Uploading results into container
2024-12-09 14:13:47,841:INFO:Uploading model into container now
2024-12-09 14:13:47,842:INFO:_master_model_container: 10
2024-12-09 14:13:47,842:INFO:_display_container: 2
2024-12-09 14:13:47,842:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-09 14:13:47,843:INFO:create_model() successfully completed......................................
2024-12-09 14:13:47,920:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:47,920:INFO:Creating metrics dataframe
2024-12-09 14:13:47,931:INFO:Initializing Linear Discriminant Analysis
2024-12-09 14:13:47,931:INFO:Total runtime is 0.08409770727157594 minutes
2024-12-09 14:13:47,934:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:47,934:INFO:Initializing create_model()
2024-12-09 14:13:47,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C1371430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:47,934:INFO:Checking exceptions
2024-12-09 14:13:47,934:INFO:Importing libraries
2024-12-09 14:13:47,934:INFO:Copying training dataset
2024-12-09 14:13:47,940:INFO:Defining folds
2024-12-09 14:13:47,940:INFO:Declaring metric variables
2024-12-09 14:13:47,944:INFO:Importing untrained model
2024-12-09 14:13:47,949:INFO:Linear Discriminant Analysis Imported successfully
2024-12-09 14:13:47,955:INFO:Starting cross validation
2024-12-09 14:13:47,956:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:48,226:INFO:Calculating mean and std
2024-12-09 14:13:48,228:INFO:Creating metrics dataframe
2024-12-09 14:13:48,232:INFO:Uploading results into container
2024-12-09 14:13:48,232:INFO:Uploading model into container now
2024-12-09 14:13:48,233:INFO:_master_model_container: 11
2024-12-09 14:13:48,233:INFO:_display_container: 2
2024-12-09 14:13:48,233:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-09 14:13:48,233:INFO:create_model() successfully completed......................................
2024-12-09 14:13:48,314:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:48,314:INFO:Creating metrics dataframe
2024-12-09 14:13:48,327:INFO:Initializing Extra Trees Classifier
2024-12-09 14:13:48,327:INFO:Total runtime is 0.09069410165150961 minutes
2024-12-09 14:13:48,331:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:48,331:INFO:Initializing create_model()
2024-12-09 14:13:48,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C1371430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:48,331:INFO:Checking exceptions
2024-12-09 14:13:48,332:INFO:Importing libraries
2024-12-09 14:13:48,332:INFO:Copying training dataset
2024-12-09 14:13:48,336:INFO:Defining folds
2024-12-09 14:13:48,337:INFO:Declaring metric variables
2024-12-09 14:13:48,340:INFO:Importing untrained model
2024-12-09 14:13:48,344:INFO:Extra Trees Classifier Imported successfully
2024-12-09 14:13:48,358:INFO:Starting cross validation
2024-12-09 14:13:48,359:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:49,305:INFO:Calculating mean and std
2024-12-09 14:13:49,306:INFO:Creating metrics dataframe
2024-12-09 14:13:49,309:INFO:Uploading results into container
2024-12-09 14:13:49,309:INFO:Uploading model into container now
2024-12-09 14:13:49,310:INFO:_master_model_container: 12
2024-12-09 14:13:49,310:INFO:_display_container: 2
2024-12-09 14:13:49,310:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-12-09 14:13:49,310:INFO:create_model() successfully completed......................................
2024-12-09 14:13:49,388:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:49,388:INFO:Creating metrics dataframe
2024-12-09 14:13:49,402:INFO:Initializing Light Gradient Boosting Machine
2024-12-09 14:13:49,402:INFO:Total runtime is 0.1086152990659078 minutes
2024-12-09 14:13:49,406:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:49,406:INFO:Initializing create_model()
2024-12-09 14:13:49,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C1371430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:49,406:INFO:Checking exceptions
2024-12-09 14:13:49,407:INFO:Importing libraries
2024-12-09 14:13:49,407:INFO:Copying training dataset
2024-12-09 14:13:49,411:INFO:Defining folds
2024-12-09 14:13:49,411:INFO:Declaring metric variables
2024-12-09 14:13:49,415:INFO:Importing untrained model
2024-12-09 14:13:49,420:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:13:49,427:INFO:Starting cross validation
2024-12-09 14:13:49,428:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:50,292:INFO:Calculating mean and std
2024-12-09 14:13:50,293:INFO:Creating metrics dataframe
2024-12-09 14:13:50,297:INFO:Uploading results into container
2024-12-09 14:13:50,298:INFO:Uploading model into container now
2024-12-09 14:13:50,298:INFO:_master_model_container: 13
2024-12-09 14:13:50,299:INFO:_display_container: 2
2024-12-09 14:13:50,299:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:13:50,299:INFO:create_model() successfully completed......................................
2024-12-09 14:13:50,414:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:50,415:INFO:Creating metrics dataframe
2024-12-09 14:13:50,431:INFO:Initializing Dummy Classifier
2024-12-09 14:13:50,431:INFO:Total runtime is 0.12576197385787966 minutes
2024-12-09 14:13:50,436:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:50,437:INFO:Initializing create_model()
2024-12-09 14:13:50,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C1371430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:50,437:INFO:Checking exceptions
2024-12-09 14:13:50,437:INFO:Importing libraries
2024-12-09 14:13:50,437:INFO:Copying training dataset
2024-12-09 14:13:50,441:INFO:Defining folds
2024-12-09 14:13:50,442:INFO:Declaring metric variables
2024-12-09 14:13:50,445:INFO:Importing untrained model
2024-12-09 14:13:50,451:INFO:Dummy Classifier Imported successfully
2024-12-09 14:13:50,459:INFO:Starting cross validation
2024-12-09 14:13:50,460:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:50,574:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:13:50,574:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:13:50,577:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:13:50,578:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:13:50,584:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:13:50,600:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:13:50,667:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:13:50,669:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:13:50,671:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:13:50,675:WARNING:c:\Users\EE715\anaconda3\envs\gym-env\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-12-09 14:13:50,680:INFO:Calculating mean and std
2024-12-09 14:13:50,681:INFO:Creating metrics dataframe
2024-12-09 14:13:50,685:INFO:Uploading results into container
2024-12-09 14:13:50,685:INFO:Uploading model into container now
2024-12-09 14:13:50,686:INFO:_master_model_container: 14
2024-12-09 14:13:50,686:INFO:_display_container: 2
2024-12-09 14:13:50,686:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-12-09 14:13:50,686:INFO:create_model() successfully completed......................................
2024-12-09 14:13:50,762:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:50,762:INFO:Creating metrics dataframe
2024-12-09 14:13:50,783:INFO:Initializing create_model()
2024-12-09 14:13:50,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:50,783:INFO:Checking exceptions
2024-12-09 14:13:50,785:INFO:Importing libraries
2024-12-09 14:13:50,785:INFO:Copying training dataset
2024-12-09 14:13:50,788:INFO:Defining folds
2024-12-09 14:13:50,788:INFO:Declaring metric variables
2024-12-09 14:13:50,789:INFO:Importing untrained model
2024-12-09 14:13:50,789:INFO:Declaring custom model
2024-12-09 14:13:50,789:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:13:50,791:INFO:Cross validation set to False
2024-12-09 14:13:50,791:INFO:Fitting Model
2024-12-09 14:13:50,835:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 14:13:50,836:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.
2024-12-09 14:13:50,836:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 14:13:50,836:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 14:13:50,836:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 14:13:50,836:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 14:13:50,836:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 14:13:50,836:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 14:13:50,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:50,887:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:13:50,887:INFO:create_model() successfully completed......................................
2024-12-09 14:13:51,011:INFO:_master_model_container: 14
2024-12-09 14:13:51,011:INFO:_display_container: 2
2024-12-09 14:13:51,011:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:13:51,011:INFO:compare_models() successfully completed......................................
2024-12-09 14:13:51,012:INFO:Initializing tune_model()
2024-12-09 14:13:51,012:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>)
2024-12-09 14:13:51,012:INFO:Checking exceptions
2024-12-09 14:13:51,051:INFO:Copying training dataset
2024-12-09 14:13:51,055:INFO:Checking base model
2024-12-09 14:13:51,055:INFO:Base model : Light Gradient Boosting Machine
2024-12-09 14:13:51,059:INFO:Declaring metric variables
2024-12-09 14:13:51,075:INFO:Defining Hyperparameters
2024-12-09 14:13:51,205:INFO:Tuning with n_jobs=-1
2024-12-09 14:13:51,205:INFO:Initializing RandomizedSearchCV
2024-12-09 14:13:57,865:INFO:best_params: {'actual_estimator__reg_lambda': 0.4, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 60, 'actual_estimator__n_estimators': 80, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__feature_fraction': 0.7, 'actual_estimator__bagging_freq': 7, 'actual_estimator__bagging_fraction': 1.0}
2024-12-09 14:13:57,866:INFO:Hyperparameter search completed
2024-12-09 14:13:57,866:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:57,866:INFO:Initializing create_model()
2024-12-09 14:13:57,867:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6A2F244F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.4, 'reg_alpha': 0.0005, 'num_leaves': 60, 'n_estimators': 80, 'min_split_gain': 0.2, 'min_child_samples': 11, 'learning_rate': 0.01, 'feature_fraction': 0.7, 'bagging_freq': 7, 'bagging_fraction': 1.0})
2024-12-09 14:13:57,867:INFO:Checking exceptions
2024-12-09 14:13:57,868:INFO:Importing libraries
2024-12-09 14:13:57,868:INFO:Copying training dataset
2024-12-09 14:13:57,873:INFO:Defining folds
2024-12-09 14:13:57,873:INFO:Declaring metric variables
2024-12-09 14:13:57,877:INFO:Importing untrained model
2024-12-09 14:13:57,877:INFO:Declaring custom model
2024-12-09 14:13:57,881:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:13:57,890:INFO:Starting cross validation
2024-12-09 14:13:57,893:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:58,794:INFO:Calculating mean and std
2024-12-09 14:13:58,795:INFO:Creating metrics dataframe
2024-12-09 14:13:58,801:INFO:Finalizing model
2024-12-09 14:13:58,846:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2024-12-09 14:13:58,847:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-12-09 14:13:58,847:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-12-09 14:13:58,848:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2024-12-09 14:13:58,848:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-12-09 14:13:58,848:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-12-09 14:13:58,848:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 14:13:58,848:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000132 seconds.
2024-12-09 14:13:58,848:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 14:13:58,848:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 14:13:58,848:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 14:13:58,848:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 14:13:58,849:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 14:13:58,849:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 14:13:58,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:58,921:INFO:Uploading results into container
2024-12-09 14:13:58,924:INFO:Uploading model into container now
2024-12-09 14:13:58,924:INFO:_master_model_container: 15
2024-12-09 14:13:58,924:INFO:_display_container: 3
2024-12-09 14:13:58,925:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=80, n_jobs=-1, num_leaves=60, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.4,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:13:58,925:INFO:create_model() successfully completed......................................
2024-12-09 14:13:59,011:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:59,011:INFO:choose_better activated
2024-12-09 14:13:59,015:INFO:SubProcess create_model() called ==================================
2024-12-09 14:13:59,015:INFO:Initializing create_model()
2024-12-09 14:13:59,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:13:59,015:INFO:Checking exceptions
2024-12-09 14:13:59,018:INFO:Importing libraries
2024-12-09 14:13:59,018:INFO:Copying training dataset
2024-12-09 14:13:59,021:INFO:Defining folds
2024-12-09 14:13:59,021:INFO:Declaring metric variables
2024-12-09 14:13:59,021:INFO:Importing untrained model
2024-12-09 14:13:59,021:INFO:Declaring custom model
2024-12-09 14:13:59,022:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-09 14:13:59,022:INFO:Starting cross validation
2024-12-09 14:13:59,023:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:13:59,741:INFO:Calculating mean and std
2024-12-09 14:13:59,741:INFO:Creating metrics dataframe
2024-12-09 14:13:59,743:INFO:Finalizing model
2024-12-09 14:13:59,785:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 14:13:59,785:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000128 seconds.
2024-12-09 14:13:59,785:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 14:13:59,785:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 14:13:59,785:INFO:[LightGBM] [Info] Total Bins 191
2024-12-09 14:13:59,785:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-09 14:13:59,786:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 14:13:59,786:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 14:13:59,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:13:59,862:INFO:Uploading results into container
2024-12-09 14:13:59,862:INFO:Uploading model into container now
2024-12-09 14:13:59,863:INFO:_master_model_container: 16
2024-12-09 14:13:59,863:INFO:_display_container: 4
2024-12-09 14:13:59,863:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:13:59,863:INFO:create_model() successfully completed......................................
2024-12-09 14:13:59,944:INFO:SubProcess create_model() end ==================================
2024-12-09 14:13:59,945:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8169
2024-12-09 14:13:59,946:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=80, n_jobs=-1, num_leaves=60, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.4,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8153
2024-12-09 14:13:59,946:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-12-09 14:13:59,946:INFO:choose_better completed
2024-12-09 14:13:59,946:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-12-09 14:13:59,957:INFO:_master_model_container: 16
2024-12-09 14:13:59,958:INFO:_display_container: 3
2024-12-09 14:13:59,958:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-09 14:13:59,958:INFO:tune_model() successfully completed......................................
2024-12-09 14:14:00,065:INFO:Initializing blend_models()
2024-12-09 14:14:00,065:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-12-09 14:14:00,065:INFO:Checking exceptions
2024-12-09 14:14:00,081:INFO:Importing libraries
2024-12-09 14:14:00,082:INFO:Copying training dataset
2024-12-09 14:14:00,088:INFO:Getting model names
2024-12-09 14:14:00,095:INFO:SubProcess create_model() called ==================================
2024-12-09 14:14:00,097:INFO:Initializing create_model()
2024-12-09 14:14:00,097:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6C0C2EFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:14:00,097:INFO:Checking exceptions
2024-12-09 14:14:00,097:INFO:Importing libraries
2024-12-09 14:14:00,098:INFO:Copying training dataset
2024-12-09 14:14:00,102:INFO:Defining folds
2024-12-09 14:14:00,103:INFO:Declaring metric variables
2024-12-09 14:14:00,107:INFO:Importing untrained model
2024-12-09 14:14:00,108:INFO:Declaring custom model
2024-12-09 14:14:00,113:INFO:Voting Classifier Imported successfully
2024-12-09 14:14:00,124:INFO:Starting cross validation
2024-12-09 14:14:00,127:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:14:01,126:INFO:Calculating mean and std
2024-12-09 14:14:01,127:INFO:Creating metrics dataframe
2024-12-09 14:14:01,135:INFO:Finalizing model
2024-12-09 14:14:01,277:INFO:Uploading results into container
2024-12-09 14:14:01,278:INFO:Uploading model into container now
2024-12-09 14:14:01,280:INFO:_master_model_container: 17
2024-12-09 14:14:01,280:INFO:_display_container: 4
2024-12-09 14:14:01,282:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-12-09 14:14:01,282:INFO:create_model() successfully completed......................................
2024-12-09 14:14:01,370:INFO:SubProcess create_model() end ==================================
2024-12-09 14:14:01,380:INFO:_master_model_container: 17
2024-12-09 14:14:01,380:INFO:_display_container: 4
2024-12-09 14:14:01,383:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-12-09 14:14:01,383:INFO:blend_models() successfully completed......................................
2024-12-09 14:14:01,480:INFO:Initializing stack_models()
2024-12-09 14:14:01,480:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)], meta_model=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-12-09 14:14:01,481:INFO:Checking exceptions
2024-12-09 14:14:01,482:INFO:Defining meta model
2024-12-09 14:14:01,500:INFO:Getting model names
2024-12-09 14:14:01,501:INFO:[('Light Gradient Boosting Machine', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0))]
2024-12-09 14:14:01,507:INFO:SubProcess create_model() called ==================================
2024-12-09 14:14:01,511:INFO:Initializing create_model()
2024-12-09 14:14:01,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=123, reg_alpha=0.0,
                                               re...
                                                  colsample_bytree=1.0,
                                                  importance_type='split',
                                                  learning_rate=0.1,
                                                  max_depth=-1,
                                                  min_child_samples=20,
                                                  min_child_weight=0.001,
                                                  min_split_gain=0.0,
                                                  n_estimators=100, n_jobs=-1,
                                                  num_leaves=31, objective=None,
                                                  random_state=123,
                                                  reg_alpha=0.0, reg_lambda=0.0,
                                                  subsample=1.0,
                                                  subsample_for_bin=200000,
                                                  subsample_freq=0),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E6BE9DD6D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:14:01,511:INFO:Checking exceptions
2024-12-09 14:14:01,511:INFO:Importing libraries
2024-12-09 14:14:01,511:INFO:Copying training dataset
2024-12-09 14:14:01,517:INFO:Defining folds
2024-12-09 14:14:01,517:INFO:Declaring metric variables
2024-12-09 14:14:01,522:INFO:Importing untrained model
2024-12-09 14:14:01,522:INFO:Declaring custom model
2024-12-09 14:14:01,528:INFO:Stacking Classifier Imported successfully
2024-12-09 14:14:01,536:INFO:Starting cross validation
2024-12-09 14:14:01,538:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-09 14:14:05,192:INFO:Calculating mean and std
2024-12-09 14:14:05,193:INFO:Creating metrics dataframe
2024-12-09 14:14:05,203:INFO:Finalizing model
2024-12-09 14:14:05,538:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-09 14:14:05,539:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000201 seconds.
2024-12-09 14:14:05,539:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 14:14:05,539:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 14:14:05,539:INFO:[LightGBM] [Info] Total Bins 399
2024-12-09 14:14:05,539:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 10
2024-12-09 14:14:05,539:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-09 14:14:05,540:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-09 14:14:05,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-09 14:14:05,666:INFO:Uploading results into container
2024-12-09 14:14:05,667:INFO:Uploading model into container now
2024-12-09 14:14:05,668:INFO:_master_model_container: 18
2024-12-09 14:14:05,668:INFO:_display_container: 5
2024-12-09 14:14:05,670:INFO:StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=123, reg_alpha=0.0,
                                               re...
                                                  colsample_bytree=1.0,
                                                  importance_type='split',
                                                  learning_rate=0.1,
                                                  max_depth=-1,
                                                  min_child_samples=20,
                                                  min_child_weight=0.001,
                                                  min_split_gain=0.0,
                                                  n_estimators=100, n_jobs=-1,
                                                  num_leaves=31, objective=None,
                                                  random_state=123,
                                                  reg_alpha=0.0, reg_lambda=0.0,
                                                  subsample=1.0,
                                                  subsample_for_bin=200000,
                                                  subsample_freq=0),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-12-09 14:14:05,670:INFO:create_model() successfully completed......................................
2024-12-09 14:14:05,810:INFO:SubProcess create_model() end ==================================
2024-12-09 14:14:05,819:INFO:_master_model_container: 18
2024-12-09 14:14:05,819:INFO:_display_container: 5
2024-12-09 14:14:05,822:INFO:StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=123, reg_alpha=0.0,
                                               re...
                                                  colsample_bytree=1.0,
                                                  importance_type='split',
                                                  learning_rate=0.1,
                                                  max_depth=-1,
                                                  min_child_samples=20,
                                                  min_child_weight=0.001,
                                                  min_split_gain=0.0,
                                                  n_estimators=100, n_jobs=-1,
                                                  num_leaves=31, objective=None,
                                                  random_state=123,
                                                  reg_alpha=0.0, reg_lambda=0.0,
                                                  subsample=1.0,
                                                  subsample_for_bin=200000,
                                                  subsample_freq=0),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-12-09 14:14:05,822:INFO:stack_models() successfully completed......................................
2024-12-09 14:14:05,907:INFO:Initializing finalize_model()
2024-12-09 14:14:05,907:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=123, reg_alpha=0.0,
                                               re...
                                                  colsample_bytree=1.0,
                                                  importance_type='split',
                                                  learning_rate=0.1,
                                                  max_depth=-1,
                                                  min_child_samples=20,
                                                  min_child_weight=0.001,
                                                  min_split_gain=0.0,
                                                  n_estimators=100, n_jobs=-1,
                                                  num_leaves=31, objective=None,
                                                  random_state=123,
                                                  reg_alpha=0.0, reg_lambda=0.0,
                                                  subsample=1.0,
                                                  subsample_for_bin=200000,
                                                  subsample_freq=0),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-09 14:14:05,909:INFO:Finalizing StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=123, reg_alpha=0.0,
                                               re...
                                                  colsample_bytree=1.0,
                                                  importance_type='split',
                                                  learning_rate=0.1,
                                                  max_depth=-1,
                                                  min_child_samples=20,
                                                  min_child_weight=0.001,
                                                  min_split_gain=0.0,
                                                  n_estimators=100, n_jobs=-1,
                                                  num_leaves=31, objective=None,
                                                  random_state=123,
                                                  reg_alpha=0.0, reg_lambda=0.0,
                                                  subsample=1.0,
                                                  subsample_for_bin=200000,
                                                  subsample_freq=0),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-12-09 14:14:05,914:INFO:Initializing create_model()
2024-12-09 14:14:05,914:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=123, reg_alpha=0.0,
                                               re...
                                                  colsample_bytree=1.0,
                                                  importance_type='split',
                                                  learning_rate=0.1,
                                                  max_depth=-1,
                                                  min_child_samples=20,
                                                  min_child_weight=0.001,
                                                  min_split_gain=0.0,
                                                  n_estimators=100, n_jobs=-1,
                                                  num_leaves=31, objective=None,
                                                  random_state=123,
                                                  reg_alpha=0.0, reg_lambda=0.0,
                                                  subsample=1.0,
                                                  subsample_for_bin=200000,
                                                  subsample_freq=0),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-09 14:14:05,914:INFO:Checking exceptions
2024-12-09 14:14:05,915:INFO:Importing libraries
2024-12-09 14:14:05,915:INFO:Copying training dataset
2024-12-09 14:14:05,916:INFO:Defining folds
2024-12-09 14:14:05,916:INFO:Declaring metric variables
2024-12-09 14:14:05,916:INFO:Importing untrained model
2024-12-09 14:14:05,916:INFO:Declaring custom model
2024-12-09 14:14:05,917:INFO:Stacking Classifier Imported successfully
2024-12-09 14:14:05,918:INFO:Cross validation set to False
2024-12-09 14:14:05,918:INFO:Fitting Model
2024-12-09 14:14:06,337:INFO:[LightGBM] [Info] Number of positive: 342, number of negative: 549
2024-12-09 14:14:06,337:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000215 seconds.
2024-12-09 14:14:06,337:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-09 14:14:06,338:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-09 14:14:06,338:INFO:[LightGBM] [Info] Total Bins 479
2024-12-09 14:14:06,338:INFO:[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 10
2024-12-09 14:14:06,338:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288
2024-12-09 14:14:06,338:INFO:[LightGBM] [Info] Start training from score -0.473288
2024-12-09 14:14:06,479:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                                                                   importance_type='split',
                                                                   learning_rate=0.1,
                                                                   max_depth=-1,
                                                                   min_child_samples=20,
                                                                   min_child_weight=0.001,
                                                                   min_split_gain=0.0,
                                                                   n_estimators=100,
                                                                   n_jobs=-1,
                                                                   num_leaves=31,
                                                                   objective=None,
                                                                   random_state=123,
                                                                   reg_alpha=0.0,
                                                                   reg_lambda=0.0,
                                                                   subsample=1.0,
                                                                   subsample_for_bin=200000,
                                                                   subsample_freq=0),
                                    n_jobs=-1, passthrough=True,
                                    stack_method='auto', verbose=0))],
         verbose=False)
2024-12-09 14:14:06,479:INFO:create_model() successfully completed......................................
2024-12-09 14:14:06,555:INFO:_master_model_container: 18
2024-12-09 14:14:06,555:INFO:_display_container: 5
2024-12-09 14:14:06,579:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                                                                   importance_type='split',
                                                                   learning_rate=0.1,
                                                                   max_depth=-1,
                                                                   min_child_samples=20,
                                                                   min_child_weight=0.001,
                                                                   min_split_gain=0.0,
                                                                   n_estimators=100,
                                                                   n_jobs=-1,
                                                                   num_leaves=31,
                                                                   objective=None,
                                                                   random_state=123,
                                                                   reg_alpha=0.0,
                                                                   reg_lambda=0.0,
                                                                   subsample=1.0,
                                                                   subsample_for_bin=200000,
                                                                   subsample_freq=0),
                                    n_jobs=-1, passthrough=True,
                                    stack_method='auto', verbose=0))],
         verbose=False)
2024-12-09 14:14:06,579:INFO:finalize_model() successfully completed......................................
2024-12-09 14:14:06,676:INFO:Initializing predict_model()
2024-12-09 14:14:06,676:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E6C0C2EF40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclu...
                                                                   importance_type='split',
                                                                   learning_rate=0.1,
                                                                   max_depth=-1,
                                                                   min_child_samples=20,
                                                                   min_child_weight=0.001,
                                                                   min_split_gain=0.0,
                                                                   n_estimators=100,
                                                                   n_jobs=-1,
                                                                   num_leaves=31,
                                                                   objective=None,
                                                                   random_state=123,
                                                                   reg_alpha=0.0,
                                                                   reg_lambda=0.0,
                                                                   subsample=1.0,
                                                                   subsample_for_bin=200000,
                                                                   subsample_freq=0),
                                    n_jobs=-1, passthrough=True,
                                    stack_method='auto', verbose=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E6BEB8AF70>)
2024-12-09 14:14:06,676:INFO:Checking exceptions
2024-12-09 14:14:06,676:INFO:Preloading libraries
2024-12-09 14:14:06,678:INFO:Set up data.
2024-12-09 14:14:06,682:INFO:Set up index.
